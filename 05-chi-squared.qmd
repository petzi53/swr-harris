# Computing Chi-Squared {#sec-chap05}

```{r}
#| label: setup
#| include: false

base::source(file = "R/helper.R")
```

## Achievements to unlock

::: my-objectives
::: my-objectives-header
Objectives
:::

::: my-objectives-container
**SwR Achievements**

-   **Achievement 1**: Understanding the relationship between two
    categorical variables using bar charts, frequencies, and percentages (@sec-chap05-achievement1)
-   **Achievement 2**: Computing and comparing observed and expected
    values for the groups (@sec-chap05-achievement2)
-   **Achievement 3**: Calculating the chi-squared statistic for the
    test of independence (@sec-chap05-achievement3)
-   **Achievement 4**: Interpreting the chi-squared statistic and making
    a conclusion about whether or not there is a relationship (@sec-chap05-achievement4)
-   **Achievement 5**: Using Null Hypothesis Significance Testing to
    organize statistical testing (@sec-chap05-achievement5)
-   **Achievement 6**: Using standardized residuals to understand which
    groups contributed to significant relationships (@sec-chap05-achievement6)
-   **Achievement 7**: Computing and interpreting effect sizes to
    understand the strength of a significant chi-squared relationship (@sec-chap05-achievement7)
-   **Achievement 8**: Understanding the options for failed chi-squared
    assumptions (@sec-chap05-achievement8)
:::
:::

## The voter fraud problem

Information from studies suggests that voter fraud does happen but it
is rare. In contrast to these studies a great minority of people (20-30%) in
the US believe that voter fraud is a big problem. Many states are
building barriers to vote, and other states make voting more easily, for
instance with automatic voter registration bills.

## Resources & Chapter Outline

### Data, codebook, and R packages {#sec-chap05-data-codebook-packages}

::: my-resource
::: my-resource-header
Data, codebook, and R packages for learning about descriptive statistics
:::

::: my-resource-container
**Data**

Two options for assessing the data:

1.  Download the data set `pew_apr_19-23_2017_weekly_ch5.sav` from
    <https://edge.sagepub.com/harris1e>
2.  Download the data set from the `r glossary("Pew Research Center")`
    website
    (<https://www.people-press.org/2017/06/28/public-supports-aimof-making-it-easy-for-all-citizens-to-vote/>)

**Codebook**

Two options for assessing the documentation:

1.  Download the documentation files `pew_voting_april_2017_ch5.pdf`,
    `pew_voting_demographics_april_2017_ch5.docx`, and
    `pew_chap5_readme.txt` from <https://edge.sagepub.com/harris1e>
2.  Download the data set from the [Pew Research Center website](https://www.pewresearch.org/download-datasets/) and the
    documentation will be included with the zipped file.

**Packages**

1.  Packages used with the book (sorted alphabetically)

-   {**desc**}: @pak-descr (Jakson Alves de Aquino)
-   {**fmsb**}: @pak-fmsb (Minato Nakazawa)
-   {**haven**}: @pak-haven (Hadley Wickham)
-   {**lsr**}: @pak-lsr (Danielle Navarro[^05-chi-squared-1])
-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)

2.  My additional packages (sorted alphabetically)
:::
:::

[^05-chi-squared-1]: Not Daniel Navarro as mentioned in the book.
    Danielle has changed her gender.

### Get data

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-get-data}
: Get data for chapter 5
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Pew data

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-get-pew-data}
: Get pew data about public support for making it easy to vote
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: get-pew-data
#| eval: false

## run only once manually #########
vote <- haven::read_sav("data/chap05/pew_apr_19-23_2017_weekly_ch5.sav")

vote <- vote |> 
    labelled::remove_labels()
save_data_file("chap05", vote, "vote.rds")

```

***

(*For this R code chunk is no output available*)

:::::{.my-note}
:::{.my-note-header}
Removing labels
:::
::::{.my-note-container}
`haven::zap_labels()` as used in the book removes value labels and not variable labels. The correct function would be `haven::zap_label()`. I have used the {**labelled**} package where you can use `labelled::remove_labels()` to delete both (variable & value labels).
::::
:::::

::::
:::::

:::::{.my-watch-out}
:::{.my-watch-out-header}
Error message with labelled data
:::
::::{.my-watch-out-container}
I have removed the labelled data immediately, because I got an error message caused by summary statistics (e.g., `base::summary()`, `skimr::skim()`, `dplyr::summarize()`) whenever I rendered the file (but not when I compiled the code chunk.) 

I didn't have time to look into this issue --- and I had to remove the labels anyway. 

What follows is the error message:

```
Quitting from lines 180-186 [show-pew-raw-data] (05-chi-squared.qmd)
Error in `dplyr::summarize()`:
ℹ In argument: `skimmed = purrr::map2(...)`.
Caused by error in `purrr::map2()`:
ℹ In index: 1.
ℹ With name: character.
Caused by error in `dplyr::summarize()`:
ℹ In argument: `dplyr::across(tidyselect::any_of(variable_names),
  mangled_skimmers$funs)`.
Caused by error in `across()`:
! Can't compute column `state_~!@#$%^&*()-+character.empty`.
Caused by error in `as.character()`:
! Can't convert `x` <haven_labelled> to <character>.
Backtrace:
  1. skimr::skim(vote)
 28. skimr (local) `<fn>`(state)
 29. x %in% empty_strings
 31. base::mtfrm.default(`<hvn_lbll>`)
 33. vctrs:::as.character.vctrs_vctr(x)
 ```
::::
:::::





###### header2

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-code-name-b}
: Numbered R Code Title (Tidyverse)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: text-bxx

1 + 1
```

::::
:::::

:::

::::
:::::

***

### Show raw data

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-show-data}
: Show raw data for chapter 5
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Vote

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-show-pew-raw-data}
: Get pew data about public support for making it easy to vote
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: show-pew-raw-data
#| results: hold
#| cache: true

vote <-  base::readRDS("data/chap05/vote.rds")
skimr::skim(vote)
```

::::
:::::


###### header2

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-code-name-b}
: Numbered R Code Title (Tidyverse)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: text-byyyy

1 + 1
```

::::
:::::

:::

::::
:::::

***

### Recode data for chapter 5

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-recode-data}
: Numbered Example Title
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Pew data

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-recode-pew-data}
: Select some columns from the pew data set
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: recode-pew-data
#| results: hold

vote <-  base::readRDS("data/chap05/vote.rds")

## create vote_clean #############
vote_clean <-  vote |> 
    dplyr::select(pew1a, pew1b, race, sex, 
                  mstatus, ownhome, employ, polparty) |> 
    labelled::remove_labels() |> 
    dplyr::mutate(dplyr::across(1:8, forcats::as_factor)) |> 
    naniar::replace_with_na(replace = list(
        pew1a = c(5, 9),
        pew1b = c(5, 9),
        race = 99,
        ownhome = c(8, 9)
    )) |> 
    dplyr::mutate(pew1a = forcats::fct_recode(pew1a,
             "Register to vote" = "1",
             "Make easy to vote" = "2",
             )) |> 
    dplyr::mutate(pew1b = forcats::fct_recode(pew1b,
             "Require to vote" = "1",
             "Choose to vote" = "2",
             )) |> 
    dplyr::mutate(race = forcats::fct_recode(race,
             "White non-Hispanic" = "1",
             "Black non-Hispanic" = "2",
             )) |> 
    dplyr::mutate(race = forcats::fct_collapse(race,
             "Hispanic" = c("3", "4", "5"),
             "Other" = c("6", "7", "8", "9", "10")
    )) |> 
    dplyr::mutate(sex = forcats::fct_recode(sex,
             "Male" = "1",
             "Female" = "2",
             )) |> 
    dplyr::mutate(ownhome = forcats::fct_recode(ownhome,
             "Owned" = "1",
             "Rented" = "2",
             )) |> 
    dplyr::mutate(dplyr::across(1:8, forcats::fct_drop)) |> 
    dplyr::rename(ease_vote = "pew1a",
                  require_vote = "pew1b")

save_data_file("chap05", vote_clean, "vote_clean.rds")
    
skimr::skim(vote_clean)
```

***
I have used in this recoding R chunk several functions for the first time:

- I turned all character columns into factor variables with just one line of code using `dplyr::across()` in combination with `forcats::as_factor()`.
- I replaced missing values (NAs) with the `replace_with_na()` function of the {**naniar**} package (see @pak-naniar).
- I combined several levels with `forcats::fct_collapse()`.
- And finally I dropped all unused levels in the whole data.frame using `dplyr::across()` in conjunction with `forcats::fct_drop()`.


::::
:::::


###### header2

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-code-name-b}
: Numbered R Code Title (Tidyverse)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: text-bzzzz
#| results: hold

```

::::
:::::

:::

::::
:::::

***

## Achievement 1: Relationship of two categorical variables {#sec-chap05-achievement1}

### Descriptive statistics

For better display I have reversed the order of the variables: Instead of grouping y ease of vote I will group by race/ethnicity. This will give a smaller table with only two columns instead of four that will not fit on the sceen without horizontal scrolling.


:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-stats-voting-data}
: Frequencies between two categorical variables
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### summarize()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-summarize-ease-voting}
: Summarize relationship ease of vote and race/ethnicity
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: summarize-ease-voting
#| results: hold
#| cache: true

## load vote_clean ##########
vote_clean <-  base::readRDS("data/chap05/vote_clean.rds")

ease_vote_sum <- vote_clean |> 
    tidyr::drop_na(ease_vote) |> 
    tidyr::drop_na(race) |> 
    dplyr::group_by(race, ease_vote) |> 
    ## either summarize
    dplyr::summarize(n = dplyr::n(),
                     .groups = "keep")
    ## or count the observation in each group
    # dplyr::count()
ease_vote_sum
```
***
Here I used "standard" tidyverse code to count frequencies. Instead of the somewhat complex last code line I could have used just `dplyr::count()` with the same result.



::::
:::::

:::::{.my-watch-out}
:::{.my-watch-out-header}
WATCH OUT! Prevent warning with `.groups` argument
:::
::::{.my-watch-out-container}
By using two variables inside `dplyr::group_by()` I got a warning message:

> `summarise()` has grouped output by 'ease_vote'. 
> You can override using the `.groups` argument.

At first I had to set the chunk option `warning: false` to turn off this warning. But finally I managed to prevent the warning with R code. See the [summarize help page](https://dplyr.tidyverse.org/reference/summarise.html) under arguments `.groups`. Another option to suppress the warning would have been `options(dplyr.summarise.inform = FALSE)`. See also the two [comments in StackOverflow](https://stackoverflow.com/questions/71914704/override-using-groups-argument) and [r-stats-tips](https://rstats-tips.net/2020/07/31/get-rid-of-info-of-dplyr-when-grouping-summarise-regrouping-output-by-species-override-with-groups-argument/).
::::
:::::


###### pivot_wider()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-pivot-wider-ease-voting}
: Summarize by converting data from long to wide with `pivot_wider()` from {**tidyr**}
::::::
:::
::::{.my-r-code-container}

:::{#lst-chap05-pivot-wider-ease-voting}
```{r}
#| label: pivot-wider-ease-voting
#| cache: true

ease_vote_wider <- vote_clean |> 
    tidyr::drop_na(ease_vote) |> 
    tidyr::drop_na(race) |> 
    dplyr::group_by(race, ease_vote) |> 
    dplyr::summarize(
        n = dplyr::n(),
        .groups = "keep") |> 
    tidyr::pivot_wider(
        names_from = ease_vote,
        values_from = n
    )
ease_vote_wider
```
Summarizing and converting data from long to wide with `pivot_wider()` from {**tidyr**}
:::

***

We get with `dplyr::pivot_wider()` a more neatly arranged table.
::::
:::::

###### table()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-base-table-ease-voting}
: Summarize with `base::table()`
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: base-table-ease-voting
#| results: hold

ease_vote_table <- base::table(vote_clean$race, vote_clean$ease_vote)
ease_vote_table
```
***

Note that NA's are automatically excluded from the table.





::::
:::::

With the simple `base::table()` we will get a very similar result as in the more complex `dplyr::pivot_wider()` code variant in @lst-chap05-pivot-wider-ease-voting. 

But I prefer in any case the tidyverse version for several reasons:

:::::{.my-note}
:::{.my-note-header}
Some deficiencies of `base::table()` 
:::
::::{.my-note-container}

- `table()` does not accept data.frame as input and you can't therefore chain several commands together with the ` |> ` pipe.
- `table()` does not output data.frames
- `table()` is very difficult to format and to make it print ready.
::::
:::::

###### xtabs()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-base-xtabs-ease-voting}
: Summarize with a `stats::xtabs()`
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: base-xtabs-ease-voting

ease_vote_xtabs <- stats::xtabs(n ~ race + ease_vote, data = ease_vote_sum)
ease_vote_xtabs
```

::::
:::::


###### tabyl()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-tabyl-voting-data}
: Frequencies with `tabyl()` from {**janitor**}
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: tabyl-voting-data
#| results: hold

vote_clean |> 
    janitor::tabyl(race, ease_vote, show_na = FALSE)
```
***

`janitor::tabyl()` prevents the weaknesses of the `base::table()` function. It works with data.frames, is tidyverse compatible and has many `adorn_*` functions (`adorn_` stands for "adornment") to format the output values.
::::
:::::

###### prop.table()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-contingency-prop-table-voting-data}
: Summarize with a base R proportion contingency table 
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: prop-contingency-table-voting-data
#| results: hold

base::prop.table(
    base::table(`Race / Ethnicity` = vote_clean$race,
          `Ease of voting` = vote_clean$ease_vote), margin = 1)
```
***
All was I said about flaws for `base::table()` is of course valid for the `base::prop.table()` function as well.

::::
:::::

###### tabyl() formatted

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-janitor-voting-data}
: Frequencies with `tabyl()` from {**janitor**} formatted
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: janitor-voting-data
#| results: hold

vote_clean |> 
    janitor::tabyl(race, ease_vote, show_na = FALSE) |> 
    janitor::adorn_percentages("row")  |> 
    janitor::adorn_pct_formatting(digits = 2)  |> 
    janitor::adorn_ns() |> 
    janitor::adorn_title(row_name = "Race / Ethnicity",
                         col_name = "Ease of voting")
```
***

In this example you can see the power of the {**janitor**} package. The main purpose of the {**janitor**} is data cleaning, but because counting is such a fundamental part of data cleaning and exploration the `tabyl()` and `adorn_*()` has been included in this package.
::::
:::::

###### Ease of voting

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-ease-voting-data}
: Ease of voting by race / ethnicity
::::::
:::
::::{.my-r-code-container}

::: {#lst-chap05-ease-voting}
```{r}
#| label: ease-voting-data
#| results: hold

vote_clean |> 
    janitor::tabyl(race, ease_vote, show_na = FALSE) |> 
    janitor::adorn_percentages("row")  |> 
    janitor::adorn_pct_formatting(digits = 2)  |> 
    janitor::adorn_ns() |> 
    janitor::adorn_title(row_name = "Race / Ethnicity",
                         col_name = "Ease of voting")
```

Ease of voting by race / ethnicity
:::

***

::: {.callout-tip}
The voting registration policy a person favors differed by race/ethnicity.

- White non-Hispanic participants were fairly evenly divided between those who thought people should register if they want to vote and those who thought voting should be made as easy as possible.
- The other three race-ethnicity groups had larger percentages in favor of making it as easy as possible to vote.
- Black non-Hispanic participants have the highest percentage (77.78%) in favor of making it easy to vote.
:::


::::
:::::

###### Require to vote

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-require-voting-data}
: Voting as requirement or free choice by race /ethnicity
::::::
:::
::::{.my-r-code-container}

::: {#lst-chap05-require-voting}
```{r}
#| label: require-voting-data
#| results: hold

vote_clean |> 
    janitor::tabyl(race, require_vote, show_na = FALSE) |> 
    janitor::adorn_percentages("row")  |> 
    janitor::adorn_pct_formatting(digits = 2)  |> 
    janitor::adorn_ns() |> 
    janitor::adorn_title(row_name = "Race / Ethnicity",
                         col_name = "Voting as citizen duty or as a free choice?")
```
Voting as requirement or free choice by race /ethnicity

:::

***

::: {.callout-tip}
Different ethnicities have distinct opinions about the character of voting. 

- About one-third of Black non-Hispanic and Hispanic believe that voting should be a requirement. But this means on the other hand, that at least two-third of both groups see voting as a free choice. 
- In contrast to this proportion are white non-Hispanic and other non-Hispanic ethnicities: In those groups more than 80% favor voting as a free choice.

:::


::::
:::::

:::

::::
:::::

:::::{.my-resource}
:::{.my-resource-header}
Cross-Tabulation
:::
::::{.my-resource-container}

- [Working with Tables in R](https://bookdown.org/kdonovan125/ibis_data_analysis_r4/working-with-tables-in-r.html) in [@donovan2019a].
- [Cross-Tabulation in R](https://www.marsja.se/cross-tabulation-in-r-creating-interpreting-contingency-tables/): Creating & Interpreting Contingency Tables [@marsja2023].
- [Tables in R](https://cran.r-project.org/web/packages/DescTools/vignettes/TablesInR.pdf): A Quick Practical Overview [@signorell2021], see also [@pak-DescTools].
- [Introduction to Crosstable](https://cran.r-project.org/web/packages/crosstable/vignettes/crosstable.html) [@chalthiel2023], see also [@pak-crosstable].

::::
:::::


### Graphs

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-descriptive-graphs}
: Descriptive graphs
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### geom_col()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-pew-voting-geom-col-graph}
: Visualizing opinions about ease of voting by race / ethnicity 
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-pew-voting-geom-col-graph
#| fig-cap: "Opinion on ease of voting by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)"

p_ease_vote <- vote_clean |> 
    ## prepare data
    tidyr::drop_na(ease_vote) |>
    tidyr::drop_na(race) |>
    dplyr::group_by(race, ease_vote) |>
    dplyr::count() |>
    dplyr::group_by(race) |>
    dplyr::mutate(perc = n / base::sum(n)) |>
    
    ## draw graph
    ggplot2::ggplot(
        ggplot2::aes(
            x = race, 
            y = perc,
            fill = ease_vote)
    ) +
    ggplot2::geom_col(position = "dodge") +
    ggplot2::scale_y_continuous(labels = scales::percent) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Race / Ethnicity",
        y = "Percent"
    ) +
    ggplot2::scale_fill_viridis_d(
        name = "Ease of voting",
        alpha = .8, # here alpha works!!
        begin = .25,
         end = .75,
        direction = -1,
        option = "viridis"
    )

p_ease_vote
```
***

I had several difficulties by drawing this graph:

1. Most important: I did not know that the second variable `ease_vote` has to be included by the `fill` argument. That seems not logical but together with `position = dodge` it make sense.
2. I didn't know that I have to group by race again (the line after `dplyr::count()`)
3. I thought that I could calculate the percentages with `ggplot2::after_stat()`. The solution was more trivial: Creating a new column with the calculated percentages and using `geom_col()` instead of `geom_bar()`.

Instead of the last line I could have used with the same result: `ggplot2::geom_bar(position = "dodge", stat = "identity")`. `geom_bar()` uses as standard option `ggplot2::stat_count()`. It is however possible to override the default value as was done in the book code. But it easier here to use `geom_col()` because it uses as default `stat_identity()` e.g., it leaves the data as is.

::: {.callout-note}
**Two additional remarks**:

1. I have used here the percent scale from the {**scales**} package to get percent signs on the y-axis.
2. I practiced my learnings from @sec-chap03 about adding a color-friendly palette (see @sec-chap03-practice-test). (See also my color test in @cnj-chap05-color-test-bw.)
:::


::::
:::::

###### geom_bar()

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-pew-voting-geom-bar-graph}
: Visualizing opinions about ease of voting by race / ethnicity 
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-pew-voting-geom-bar-graph
#| fig-cap: "Opinion on ease of voting by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)"



vote_clean |> 
    tidyr::drop_na(ease_vote) |>
    tidyr::drop_na(race) |>
    ggplot2::ggplot(
        ggplot2::aes(
            x = race, 
            fill = ease_vote
        )
    ) +
    ggplot2::geom_bar(position = "dodge",
        ggplot2::aes(
            y = ggplot2::after_stat(count / base::sum(count))
        )) +
    ggplot2::scale_y_continuous(labels = scales::percent) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Race / Ethnicity",
        y = "Percent"
    ) +
    ggplot2::scale_fill_viridis_d(
        name = "Ease of voting",
        alpha = .8, # here alpha works!!
        begin = .25,
         end = .75,
        direction = -1,
        option = "viridis"
    )
```
***

Here I have used `geom_bar()` with the `after_stat()` calculation. It turned out that the function computes the percentages of the different race categories for the two `ease_vote` values. This was not was I had intended.

I tried for several hours to use `after_stat()` with the same result as in @cnj-chap05-pew-voting-geom-col-graph, but I didn't succeed. I do not know if the reason is my missing knowledge (for instance to generate another structure of the data.frame) or if you can't do that in general. 

::::
:::::

###### geom_col() with labels

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-pew-voting-geom-col-label-graph}
: Visualizing opinions about ease of voting by race / ethnicity 
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-pew-voting-geom-col-label-graph
#| fig-cap: "Opinion on ease of voting by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)"

vote_clean |> 
    tidyr::drop_na(ease_vote) |>
    tidyr::drop_na(race) |>
    dplyr::group_by(race, ease_vote) |>
    dplyr::count() |>
    dplyr::group_by(race) |>
    dplyr::mutate(perc = n / base::sum(n)) |>
    ggplot2::ggplot(
        ggplot2::aes(
            x = race, 
            y = perc,
            fill = ease_vote)
    ) +
    ggplot2::geom_col(position = "dodge") +
    ggplot2::geom_label(
        ggplot2::aes(
            x = race,
            y = perc,
            label = paste0(round(100 * perc, 1),"%"),
            vjust = 1.5, hjust = -.035
        ),
        color = "white"
    ) +
    ggplot2::scale_y_continuous(labels = scales::percent) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Race / Ethnicity",
        y = "Percent"
    ) +
    ggplot2::scale_fill_viridis_d(
        name = "Ease of voting",
        alpha = .8, # here alpha works!!
        begin = .25,
         end = .75,
        direction = -1,
        option = "viridis"
    )
    
```
***

Here I have experimented with labels. It seems that with the argument `position = dodge` the labels can't appear on each of the appropriate bars.

::::
:::::

###### requirements

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-pew-voting-requirements-by-race}
: Visualizing opinions about requirements of voting by race / ethnicity 
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-pew-voting-requirements-by-race
#| fig-cap: "Opinion on voting requirements by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)"

p_require_vote <- vote_clean |> 
    ## prepare data
    tidyr::drop_na(require_vote) |>
    tidyr::drop_na(race) |>
    dplyr::group_by(race, require_vote) |>
    dplyr::count() |>
    dplyr::group_by(race) |>
    dplyr::mutate(perc = n / base::sum(n)) |>
    
    ## draw graph
    ggplot2::ggplot(
        ggplot2::aes(
            x = race, 
            y = perc,
            fill = require_vote)
    ) +
    ggplot2::geom_col(position = "dodge") +
    ggplot2::scale_y_continuous(labels = scales::percent) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Race / Ethnicity",
        y = "Percent"
    ) +
    ggplot2::scale_fill_viridis_d(
        name = "Requirements of voting",
        alpha = .8, # here alpha works!!
        begin = .25,
         end = .75,
        direction = -1,
        option = "viridis"
    )

p_require_vote
```



::::
:::::

###### Voting by race

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-voting-opinions-by-race}
: Visualizing opinions about voting by race / ethnicity 
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-pew-voting-by-race
#| fig-cap: "Opinion on ease of voting and voting requirements by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)"
#| fig-height: 6
#| warning: false

p_ease <- p_ease_vote +
    ggplot2::labs(
        x = "",
        y = "Percent within group"
    ) +
    ggplot2::scale_fill_viridis_d(
        name = "Opinion on\nvoter registration",
        alpha = .8, 
        begin = .25,
        end = .75,
        direction = -1,
        option = "viridis"
    ) +
    ggplot2::theme(axis.text.x = ggplot2::element_blank())

p_require <- p_require_vote +
    ggplot2::labs(y = "Percent within group") +
    ggplot2::scale_fill_viridis_d(
        name = "Opinion on\nvoting",
        alpha = .8,
        begin = .25,
        end = .75,
        direction = -1,
        option = "viridis"
    )

gridExtra::grid.arrange(p_ease, p_require, ncol = 1)

```

::::
:::::


###### Color test

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-color-test-bw}
: Test how the colors used for the graph race by ease of voting look for printing in black & white
::::::
:::
::::{.my-r-code-container}


::: {#lst-chap05-color-test-bw}

```{r}
#| label: fig-color-test-bw
#| fig-cap: "Test if used colors of my graph race by ease of voting look are also readable for black & white printing"
#| fig-height: 3
#| results: hold

pal_data <- list(names = c("Normal", "desaturated"),
    color = list(scales::viridis_pal(
                                alpha = .8, 
                                begin = .25, 
                                 end = .75, 
                                direction = -1, 
                                option = "viridis")(2),
    colorspace::desaturate(scales::viridis_pal(
                                alpha = .8, 
                                begin = .25, 
                                end = .75, 
                                direction = -1, 
                                option = "viridis")(2)))
    )
list_plotter(pal_data$color, pal_data$names, 
    "Colors and black & white of graph race by ease of voting")

```

Test how the colors I have used for my graphs about race by ease of voting look in black & white
:::

::::
:::::

:::

::::
:::::


## Achievement 2: Comparing groups {#sec-chap05-achievement2}

The `r glossary("chi-squared")` test is useful for testing to see if there may be a statistical relationship between two categorical variables. The chi-squared test is based on the observed values, and the values expected to occur if there were no relationship between the variables.

### Observed values

We will use the observed values from @lst-chap05-ease-voting and @lst-chap05-require-voting.

### Expected values

For each cell in the table, multiply the row total for that row by the column total for that column and divide by the overall total.

To prevent manually computing the values I have used `CrossTable()` from the {**descr**} package (see @pak-descr and [StackOverflow](https://stackoverflow.com/a/34214973/7322615)).

$$
\text{Expected Values} = \frac{rowTotal \times columnTotal}{Total}
$$ {#eq-expected-values}


:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-expected-values}
: Show observed and expected values
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Ease

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-expected-ease-vote}
: Ease of voting by race / ethnicity
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: expected-race-by-ease-vote
#| results: hold
#| cache: true

vote_clean <- base::readRDS("data/chap05/vote_clean.rds")

vote_opinions <- vote_clean |> 
    dplyr::select(race, ease_vote, require_vote) |>
    tidyr::drop_na()

ct_ease <- descr::CrossTable(
    x = vote_opinions$race,
    y = vote_opinions$ease_vote,
    dnn = c("Race", "Ease of voting"),
    prop.r = FALSE, 
    prop.c = FALSE, 
    prop.t = FALSE,
    prop.chisq = FALSE,
    expected = TRUE
    )
ct_ease
```

***

::: {.callout-tip}

- Some of the cells have observed and expected values that are very close to each other. For example, the observed number of Other race-ethnicity people who want to make it easy to vote is 46, while the expected is 43.3. 
- But other categories show bigger differences. For example, the observed number of Black non-Hispanics who think people should register to vote is 28, and the expected value is nearly twice as high at 51.3.
:::

::::
:::::

###### Require

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-exprected-race-by-require}
: Status of voting by race / ethnicity
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: expected-race-by-require
#| results: hold
#| cache: true

ct_require <- descr::CrossTable(
        x = vote_opinions$race,
        y = vote_opinions$require_vote,
        dnn = c("Race", "Status of voting"),
        prop.r = FALSE, 
        prop.c = FALSE, 
        prop.t = FALSE,
        prop.chisq = FALSE,
        expected = TRUE
    )
ct_require
```

***

::: {.callout-tip}
The cell "Other" has similar observed and expected values, but the rest have bigger differences.
:::

::::
:::::

###### Both

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-expected-voting-data}
: Computing ease and require of voting using the {**sjstats**} package
::::::
:::
::::{.my-r-code-container}



```{r}
#| label: expected-voting-data
#| results: hold
#| cache: true

## load vote_clean ##########
vote_clean <-  base::readRDS("data/chap05/vote_clean.rds")

vote_clean2 <- vote_clean |> 
    dplyr::select(race, ease_vote, require_vote) |> 
    tidyr::drop_na()

ease_vote_n <- vote_clean2 |> 
    dplyr::select(race, ease_vote) |> 
    dplyr::group_by(race, ease_vote) |> 
    dplyr::summarize(n_ease = dplyr::n(),
                     .groups = "keep")

ease_expected  <-  
    tibble::as_tibble(
        base::as.data.frame(
            sjstats::table_values(
                base::table(
                    vote_clean$race, 
                    vote_clean$ease_vote)
                )$expected,
                .name_repair = "unique")) |> 
    dplyr::arrange(Var1)

(
    ease_expected2 <- dplyr::bind_cols(
    ease_vote_n,
    exp_ease = ease_expected$Freq)
)

glue::glue(" ")
glue::glue("**********************************************************")
glue::glue(" ")

require_vote_n <- vote_clean2 |> 
    dplyr::select(race, require_vote) |> 
    dplyr::group_by(race, require_vote) |> 
    dplyr::summarize(n_require = dplyr::n(),
                     .groups = "keep")

require_expected  <-  
    tibble::as_tibble(
        base::as.data.frame(
            sjstats::table_values(
                base::table(
                    vote_clean$race, 
                    vote_clean$require_vote)
                )$expected,
                .name_repair = "unique")) |> 
    dplyr::arrange(Var1)

(
    require_expected2 <- dplyr::bind_cols(
    require_vote_n,
    exp_require = require_expected$Freq)
)
```

***

The `sjstats::table_values()` function has the advantage that it can be converted to a data.frame. We can therefore manipulate the data and --- for example --- combine expected data for different variables.


::::
:::::

###### Together

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-expected-vote-data}
: : Combining ease and require of voting
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: expacted-vote-data
#| results: hold

require_expected3 <- require_expected2 |> 
    dplyr::ungroup() |> 
    dplyr::select(-1)

vote_expected <- dplyr::bind_cols(
    ease_expected2,
    require_expected3
)

vote_expected
```

::::
:::::


:::

::::
:::::

:::::{.my-important}
:::{.my-important-header}
Differences between observed values and expected indicates that there may be a relationship between the variables. 
:::
:::::

### Assumptions of the chi-squared test of independence

***

::: {#bul-chap05-assumptions-chi-squared}
- **The variables must be nominal or ordinal (usually nominal)**. We have categorical data with no order, e.g., nominal data: *The assumption is met.*
- **The expected values should be 5 or higher in at least 80% of groups**. We have 8 cells with values. None of these cells are 5 or lower: *The assumption is met.*
- **The observations must be independent**. We have neither the same set of people asked before and after an intervention nor do are the respondents family members or other affiliated with each other: *The assumption is met. *

Assumptions for the chi-squared test

:::
------------------------------------------------------------------------

## Calculating the chi-squared statistic {#sec-chap05-achievement3}

The differences between observed values and expected values can be combined into an overall statistic. But adding (resp. subtracting) does not work as the result is always 0. So we will again --- like in the variance --- square the difference.

To prevent huge differences when observed and expected values are very large, there is an additional step in the computation of $\chi^2$: Divide the squared differences by the expected value of the appropriate cells.

$$
\chi^2 = \sum\frac{(observed - expected)^2}{expected}
$$ {#eq-chi-squared}

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-chi-squared-ease-voting}
: Compute chi-squared for race by ease of voting
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: chi-squared-ease-voting
#| cache: true

vote_clean <- base::readRDS("data/chap05/vote_clean.rds")

stats::chisq.test(
    x = vote_clean$ease_vote,
    y = vote_clean$race
)

```

::::
:::::

## Achievement 4: Interpreting the chi-squared statistic {#sec-chap05-achievement4}

In contrast to the binomial and normal distribution which both have two parameters (n and p, resp. $\mu$ and $\sigma$), the `r glossary("chi-squared")` distribution has only one `r glossary("parameter")`: the `r glossary("degrees of freedom")`. The `df` can be used to find the population `r glossary("standard deviation")` for the distribution:

$$
\sqrt{2df}
$$ {#eq-pop-sd-df}



:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap05-chi-squared-dist}
: Chi-square probability distributions with different degrees of freedom
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### 4 $\chi^2$ dist extra

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-chi-squared-separately}
: Four chi-square probability distributions with different degrees of freedom
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-chi-squared-dist
#| fig-cap: "Chi-square probability distributions with different degrees of freedom"

# Define sequence of x-values
tib <- tibble::tibble(x = seq(0, 30, length.out = 600))

tib <- tib |> 
# Compute density values
    dplyr::mutate(
        y1 = stats::dchisq(x, df = 1),
        y3 = stats::dchisq(x, df = 3),
        y5 = stats::dchisq(x, df = 5),
        y7 = stats::dchisq(x, df = 7)
    )  
chi_sq1 <- tib |> 
# Plot the Chi-square distribution: df = 1
    ggplot2::ggplot(ggplot2::aes(x = x, y = y1)) +
    ggplot2::geom_line(color = "blue") +
    ggplot2::labs(x = "x", y = "Density", 
      title = paste("Chi-square with 1 degree of freedom")) +
    ggplot2::theme_bw()

chi_sq3 <- tib |> 
# Plot the Chi-square distribution: df = 3
    ggplot2::ggplot(ggplot2::aes(x = x, y = y3)) +
    ggplot2::geom_line(color = "blue") +
    ggplot2::labs(x = "x", y = "Density", 
      title = paste("Chi-square with 3 degrees of freedom")) +
    ggplot2::theme_bw()

chi_sq5 <- tib |> 
# Plot the Chi-square distribution: df = 5
    ggplot2::ggplot(ggplot2::aes(x = x, y = y5)) +
    ggplot2::geom_line(color = "blue") +
    ggplot2::labs(x = "x", y = "Density", 
      title = paste("Chi-square with 5 degrees of freedom")) +
    ggplot2::theme_bw()

chi_sq7 <- tib |> 
# Plot the Chi-square distribution: df = 7
    ggplot2::ggplot(ggplot2::aes(x = x, y = y7)) +
    ggplot2::geom_line(color = "blue") +
    ggplot2::labs(x = "x", y = "Density", 
      title = paste("Chi-square with 7 degrees of freedom")) +
    ggplot2::theme_bw()

gridExtra::grid.arrange(chi_sq1, chi_sq3, chi_sq5, chi_sq7, ncol = 2)
```
***

:::::{.my-watch-out}
:::{.my-watch-out-header}
WATCH OUT! The graphs have different y scales!
:::
::::{.my-watch-out-container}
This is the replication of Figure 5.7 from the book.

Note: The first impression --- that all probability distributions have same height --- is wrong! All four graphs have very different density scales! 

We will see that all four distributions overlaid into one graphic will give a different impression.
::::
:::::




::::
:::::


###### 4 $\chi^2$ dist together

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap05-chi-squared-dist-together}
: Four chi-square probability distributions with different degrees of freedom in one graph
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-chi-squared-dist-together
#| fig-cap: "Four chi-square probability distributions with different degrees of freedom"

# Define sequence of x-values
tib_chisq <- tibble::tibble(x = seq(0, 30, length.out = 600))

tib_chisq |> 
# Compute density values
    dplyr::mutate(
        y1 = stats::dchisq(x, df = 1),
        y3 = stats::dchisq(x, df = 3),
        y5 = stats::dchisq(x, df = 5),
        y7 = stats::dchisq(x, df = 7)
    ) |> 

    ggplot2::ggplot() +
    ggplot2::geom_line(
        ggplot2::aes(x = x, y = y1),
        color = "blue"
    ) +
    ggplot2::geom_line(
        ggplot2::aes(x = x, y = y3),
        color = "red"
    ) +
    ggplot2::geom_line(
    ggplot2::aes(x = x, y = y5),
    color = "darkgreen"
    ) +
    ggplot2::geom_line(
    ggplot2::aes(x = x, y = y7),
    color = "black"
    ) +
    ggplot2::ylim(0, .3) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        y = "Density"
    )

# sjPlot::dist_chisq(deg.f = 4) +
# sjPlot::dist_chisq(deg.f = 6) +
#     ggplot2::theme_bw()
```

::::
:::::

:::

::::
:::::

***

## Exercises (empty)

## Packages introduced in this chapter 

### crosstable

:::::{.my-resource}
:::{.my-resource-header}
crosstable: Crosstables for Descriptive Analyses 
:::
::::{.my-resource-container}

***

::: {#pak-crosstable}

***

{**crosstable**}: [Crosstables for Descriptive Analyses](https://danchaltiel.github.io/crosstable/) [@crosstable]

::: {layout="[10, 30]" layout-valign="center"}
![](img/chap05/logoi/logo-crosstable-min.png){width="176"}


Crosstable is a package centered on a single function, crosstable, which easily computes descriptive statistics on datasets. It can use the {**tidyverse**} syntax and is interfaced with the package {**officer**} to create automatized reports.

:::

Create descriptive tables for continuous and categorical variables. Apply summary statistics and counting function, with or without a grouping variable, and create beautiful reports using {**rmarkdown**} or {**officer**}. You can also compute effect sizes and statistical tests if needed.

{**crosstable**}: Crosstables for Descriptive Analyses
:::


***
::::
:::::

### DescTools

:::::{.my-resource}
:::{.my-resource-header}
DescTools: Tools for Descriptive Statistics 
:::
::::{.my-resource-container}

***

::: {#pak-DescTools}

***

{**DescTools**}: [Tools for Descriptive Statistics](https://andrisignorell.github.io/DescTools/) [@DescTools]


(*There is no hexagon logo for {**DescTools**} available*)

:::

A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. 

The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.

{**DescTools**}: Tools for Descriptive Statistics
:::

***
::::
:::::



### fmsb

:::::{.my-resource}
:::{.my-resource-header}
fmsb: Functions for Medical Statistics Book with some Demographic Data 
:::
::::{.my-resource-container}

***

::: {#pak-fmsb}

***

{**fmsb**}: [Functions for Medical Statistics Book with some Demographic Data](https://cran.r-project.org/package=fmsb) [@fmsb]

(*There is no hexagon logo for {**fmsb**} available*)


Several utility functions for the book entitled "Practices of Medical and Health Data Analysis using R" (Pearson Education Japan, 2007) with Japanese demographic data and some demographic analysis related functions.

{**fmsb**}: Functions for Medical Statistics Book with some Demographic Data
:::

***
::::
:::::

### lsr

:::::{.my-resource}
:::{.my-resource-header}
lsr: Companion to "Learning Statistics with R" 
:::
::::{.my-resource-container}

***

::: {#pak-lsr}

***

{**lsr**}: [Companion to "Learning Statistics with R"](https://learningstatisticswithr.com/) [@lsr]

(*There is no hexagon logo for {**lsr**} available*)

A collection of tools intended to make introductory statistics easier to teach, including wrappers for common hypothesis tests and basic data manipulation. It accompanies Navarro, D. J. (2015). Learning Statistics with R: A Tutorial for Psychology Students and Other Beginners, Version 0.6. 


{**lsr**}: Companion to "Learning Statistics with R"
:::

***
::::
:::::

### naniar

:::::{.my-resource}
:::{.my-resource-header}
naniar: Data Structures, Summaries, and Visualisations for Missing Data 
:::
::::{.my-resource-container}

***

::: {#pak-naniar}

***

{**naniar**}: [https://github.com/njtierney/naniar](https://naniar.njtierney.com/) [@naniar]

::: {layout="[10, 30]" layout-valign="center"}
![](img/chap05/logoi/logo-naniar-min.png){width="176"}


{**naniar**} provides principled, tidy ways to summarise, visualise, and manipulate missing data with minimal deviations from the workflows in ggplot2 and tidy data.

:::

Missing values are ubiquitous in data and need to be explored and handled in the initial stages of analysis. {**naniar**} provides data structures and functions that facilitate the plotting of missing values and examination of imputations. This allows missing data dependencies to be  explored with minimal deviation from the common work patterns of 'ggplot2' and tidy data. The work is fully discussed in Tierney & Cook [-@tierney2023].

{**naniar**}: https://github.com/njtierney/naniar
:::


***
::::
:::::


## Glossary

```{r}
#| label: glossary-table
#| echo: false

glossary_table()
```

------------------------------------------------------------------------

## Session Info {.unnumbered}

::: my-r-code
::: my-r-code-header
Session Info
:::

::: my-r-code-container
```{r}
#| label: session-info

sessioninfo::session_info()
```
:::
:::
