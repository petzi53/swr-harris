# Analysis of variance {#sec-chap07}

```{r}
#| label: setup
#| include: false

base::source(file = "R/helper.R")
ggplot2::theme_set(ggplot2::theme_bw()) 
```

## Achievements to unlock

::: my-objectives
::: my-objectives-header
Objectives
:::

::: my-objectives-container
**SwR Achievements**

- **Achievement 1**: Exploring the data using graphics and descriptive statistics {@sec-chap07-achievement1}
- **Achievement 2**: Understanding and conducting one-way ANOVA {@sec-chap07-achievement2}
- **Achievement 3**: Choosing and using post hoc tests and contrasts {@sec-chap07-achievement3}
- **Achievement 4**: Computing and interpreting effect sizes for ANOVA {@sec-chap07-achievement4}
- **Achievement 5**: Testing ANOVA assumptions {@sec-chap07-achievement5}
- **Achievement 6**: Choosing and using alternative tests when ANOVA assumptions are not met {@sec-chap07-achievement6}
- **Achievement 7**: Understanding and conducting two-way ANOVA {@sec-chap07-achievement7}

:::
:::

`r glossary("ANOVA")` is the statistical method used for comparing means across three or more groups. 

- Like the `r glossary("student", "t-test")`, ANOVA has underlying assumptions.
- Similar to `r glossary("chi-squared")`, ANOVA is an `r glossary("omnibus")` test.
- Instead of using `r glossary("standardized residuals")`, ANOVA uses planned contrasts and post hoc tests.
- Instead of `r glossary("Cramér’s V")` or `r glossary("odds ratio", "odds ratios")` for chi-squared and `r glossary("Cohen’s d")` for t-tests, $η^2$ and $ω^2$ are often reported as `r glossary("effect size", "effect sizes")` for ANOVA.


## The technical difficulties problem (empty)

## Resources & Chapter Outline

### Data, codebook, and R packages {#sec-chap04-data-codebook-packages}

::: my-resource
::: my-resource-header
Data, codebook, and R packages for learning about descriptive statistics
:::

::: my-resource-container

**Data**


Two options:

1. Download the `gss2018.rda` data set from <https://edge.sagepub.com/harris1e>.
2. Use {**gssr**} to download the year 2018.

(As a direct download with the {**gssr**} package results in labelled data with different column names and the necessary transformation will not gain any additional knowledge for me, I will take the `gss2018.rda` data set from the book.)

**Codebook**

Two options:

1. Access variable documentation (not a full codebook) on the GSS Data Explorer website at <https://gssdataexplorer.norc.org/> 
2. Use the help pages from {**gssr**} package.


**Packages**

1. Packages used with this chapter (sorted alphabetically)

-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)
-   {**car**): @pak-car (John Fox)
-   {**dunn.test**} @pak-dunn.test (Alexis Dinno)

    
2. My additional packages (sorted alphabetically)



:::
:::



### Get data {#sec-chap07-get-data}

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-get-gss2018-book}
: Get book GSS data set `gss2018.rda` and save it as `gss_2018.rds`
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: get-gss2018-book
#| eval: false
#| cache: true
#| results: hold

## run only once (manually)
## load "GSS" data.frame into memory
base::load("data/chap07/gss2018.rda")

gss_2018 <- GSS
save_data_file("chap07", gss_2018, "gss_2018.rds")
```

(*For this R code chunk is no output available*)
::::
:::::


### Show raw data {#sec-chap07-show-data}

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-show-gss-2018-data}
: Show summary for some `gss_2018` data
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: show-gss-2018-data


gss_2018 <- base::readRDS("data/chap07/gss_2018.rds")
gss_2018 |> 
    dplyr::select(c("USETECH", "HAPPY", "SEX", "AGE", "DEGREE")) |> 
    base::summary()
```
***

- **USETECH**: During a typical week, about what percentage of your total time at work would you normally spend using different types of electronic technologies (such as computers, tablets, smart phones, cash registers, scanners, GPS devices, robotic devices, and so on)?
- **HAPPY**: Taken all together, how would you say things are these days -- would you say that you are very happy, pretty happy, or not too happy?
- **SEX**: Respondent’s sex
- **AGE**: Respondent’s age
- **DEGREE**: Respondent’s highest degree
- 
::::
:::::

:::::{.my-procedure}
:::{.my-procedure-header}
:::::: {#prp-chap07-gss-procedure}
: To get the full information for a variable in GSS
::::::
:::
::::{.my-procedure-container}
1. Go to <https://gssdataexplorer.norc.org/>
2. In the box "Access and Analyze GSS Data" click on the "SEARCH VARIABLES" button.
3. Click at "Select specific years", choose "2018" and confirm by pressing the "Apply"-button.
4. Input the name of the variable "USETECH" into the field and confirm with <enter>.
5. Open "Associated questions" by clicking the `>` symbol or by pressing the "Show Expanded View"-button.
6. Click on the green variable name in the result list to get more detailed information about the variable.
7. In contrast to the result in the book we get a slightly different coding scheme: We got four (not three) values outside the logical range of 0 to 100: -97, -98, -99, -100.

![Screenshot of GSS Data Explorer 2018 USETECH variable values outside logical range](img/chap07/gss-usetech-codes-min.png){#fig-gss-usetech-codebook
fig-alt="Table of the first 10 lines of GSS Data Explorer 2018 USETECH variable values"
fig-align="center"}

::::
:::::

:::::{.my-important}
:::{.my-important-header}
Recoding data exactly as in the book
:::
::::{.my-important-container}
As we are going to use the data set from the book and not the current data set as it is today (2024-03-25) saved at the GSS website, we will for instance USETECH recode -1, 998 and 999 as missing data in our data frame (and not the current values).  

Generally: There is nothing new for me in recoding the data. So I will apply all the necessary recoding in the next subsection in only one R code chunk.
::::
:::::



### Recode data {#sec-chap07-recode-data}

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-recode-gss2018}
: Clean `gss_2018` data
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: recode-gss2018
#| results: hold
#| cache: true


## run only once (manually) ############
gss_2018 <- base::readRDS("data/chap07/gss_2018.rds")

gss_2018_clean <- gss_2018 |> 
    dplyr::select(c("USETECH", "HAPPY", "SEX", "AGE", "DEGREE")) |> 
    dplyr::mutate(USETECH = dplyr::na_if(x = USETECH, y = -1)) |> 
    dplyr::mutate(USETECH = dplyr::na_if(x = USETECH, y = 998)) |>
    dplyr::mutate(USETECH = dplyr::na_if(x = USETECH, y = 999)) |>
    dplyr::mutate(AGE = dplyr::na_if(x = AGE, y = 98)) |>
    dplyr::mutate(AGE = dplyr::na_if(x = AGE, y = 99)) |>
    dplyr::mutate(DEGREE = dplyr::na_if(x = DEGREE, y = 8)) |>
    dplyr::mutate(DEGREE = dplyr::na_if(x = DEGREE, y = 9)) |>
    dplyr::mutate(HAPPY = dplyr::na_if(x = HAPPY, y = 8)) |>
    dplyr::mutate(HAPPY = dplyr::na_if(x = HAPPY, y = 9)) |>
    dplyr::mutate(HAPPY = dplyr::na_if(x = HAPPY, y = 0)) |> 
    
    dplyr::mutate(SEX = forcats::as_factor(SEX)) |> 
    dplyr::mutate(DEGREE = forcats::as_factor(DEGREE)) |> 
    dplyr::mutate(HAPPY = forcats::as_factor(HAPPY)) |> 
    
    dplyr::mutate(SEX = forcats::fct_recode(SEX, 
                                            male = "1", 
                                            female = "2")) |> 
    dplyr::mutate(DEGREE = forcats::fct_recode(DEGREE, 
                                            "< high school" = "0", 
                                            "high school" = "1",
                                            "junior college" = "2",
                                            "bachelor" = "3",
                                            "graduate" = "4")) |> 
    dplyr::mutate(HAPPY = forcats::fct_recode(HAPPY, 
                                        "very happy" = "1",
                                        "pretty happy" = "2",
                                        "not too happy" = "3"))

save_data_file("chap07", gss_2018_clean, "gss_2018_clean.rds")

base::summary(gss_2018_clean)
```

::::
:::::



## Achievement 1: Descriptive statistics {#sec-chap07-achievement1}

The work in this section is done in @sec-chap07-get-data, @sec-chap07-show-data and @sec-chap07-recode-data.

### Explorative Data Analysis (EDA)

**Question to explore**: Do people with higher educational degrees use technology at work more than people with lower degree?

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap07-eda}
: Explorative Data Analysis (EDA)
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### mean / sd

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-usetech-mean-sd}
: Mean and standard deviation of technology use by respondent’s highest degree
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-chap07-usetech-mean-sd
#| fig-cap: "Mean and standard deviation of technology use by respondent’s highest degree"

gss_2018_clean <- base::readRDS("data/chap07/gss_2018_clean.rds")

usetech_degree <- gss_2018_clean |> 
    tidyr::drop_na(USETECH, DEGREE) |>
    dplyr::group_by(DEGREE) |> 
    dplyr::summarize(mean_usetech = mean(USETECH),
                     sd_usetech = sd(USETECH))
usetech_degree

```
***
It seems that we could affirm our question. With higher degree the value of the mean (representing the percentage of technology usage) is rising. But we have a big standard deviation, especially in the lowest degree group ($sd \approx 1.5 mean$). This could indicate that we have not a normal distribution because of high `r glossary("kurtosis")`, e.g. we could have more observations in the tails than a normal distribution would have (`r glossary("platykurtic")`).

::::
:::::


###### replicate Figure 7.4

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-replicate-7-4}
: Distribution of work time spent using technology by educational attainment
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-replicate-7-4
#| fig-cap: "Distribution of work time spent using technology by educational attainment, using palette 'Spectral' of brewer scales"

gg_gss_2018 <- gss_2018_clean |> 
  tidyr::drop_na(USETECH) |> 
  ggplot2::ggplot(
      ggplot2::aes(
          x = DEGREE,
          y = USETECH
          )
      ) +
  ggplot2::geom_jitter(
      ggplot2::aes(color = DEGREE), alpha = .6
      ) +
  ggplot2::geom_boxplot(
      ggplot2::aes(fill = DEGREE), alpha = .4
      ) +
  ggplot2::scale_fill_brewer(
      palette = "Spectral", 
      guide = "none"
      ) +
  ggplot2::scale_color_brewer(
      palette = "Spectral", 
      guide = "none") +
  ggplot2::theme_bw() +
  ggplot2::labs(
      x = "Highest educational attainment", 
      y = "Percent of time spent using technology"
      )

gg_gss_2018
```
***

Harris uses with this graph (Figure 7.4 in her book) the color schemes from [ColorBrewer](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3). See for more details the [color palettes of RColorBrewer](https://renenyffenegger.ch/notes/development/languages/R/packages/RColorBrewer/index) and the [screenshot](https://renenyffenegger.ch/notes/development/languages/R/packages/tmaptools/index#r-tmaptools-palette_explorer) of the `tmaptools::palette_explorer()` function. 

But the chosen color palette is not appropriate for people with color vision deficiency (`r glossary("CVD")`). Mainly the yellow color is problematic as can be demonstrated with the following plot:


```{r}
#| label: fig-check-colorblind-save-gss_2018-plot
colorblindr::cvd_grid(gg_gss_2018)
```


::::
:::::

###### better colors

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-techuse-dist}
: Distribution of work time spent using technology by educational attainment (colorblind save)
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: techuse-dist
#| fig-cap: "Distribution of work time spent using technology by educational attainment, using the color save palette 'Okabe-Ito'"
#| results: hold

gg2_gss_2018 <- gss_2018_clean |> 
  tidyr::drop_na(USETECH) |> 
  ggplot2::ggplot(
      ggplot2::aes(
          x = DEGREE,
          y = USETECH
          )
      ) +
  ggplot2::geom_jitter(
      ggplot2::aes(color = DEGREE), alpha = .6
      ) +
  ggplot2::geom_boxplot(
      ggplot2::aes(fill = DEGREE), alpha = .4
      ) + 
  ggokabeito::scale_color_okabe_ito(guide = "none") +
  ggokabeito::scale_fill_okabe_ito(guide = "none") +
  ggplot2::theme_bw() +
  ggplot2::labs(
      x = "Highest educational attainment", 
      y = "Percent of time spent using technology"
  )

gg2_gss_2018
colorblindr::cvd_grid(gg2_gss_2018)
```

***

Although the color palette "Okabe-Ito" is also using a kind of yellow the result is much better in all CVD variants. Compare it with @fig-check-colorblind-save-gss_2018-plot.
::::
:::::


:::

::::
:::::

What we can see with the graph is that there are many observation at the bottom and at the top of the range of the variable `USETECH`.  

- Many people in the first two categories had selected 0% of their time at work is spent using technology (`r glossary("Floor", "Floor effect")`).
- For all but the first category, there were a lot of people who selected 100% of their time at work is spent using technology (`r glossary("Ceiling", "Ceiling effect")`).

:::::{.my-watch-out}
:::{.my-watch-out-header}
WATCH OUT! ANOVA with floor and ceiling effect
:::
::::{.my-watch-out-container}

When there are floor or ceiling effects, this often means that the variation in a measure is limited by its range. Since ANOVA is an analysis of variance, which examines central tendency and variation together, the limitations of floor and ceiling effects can result in not finding differences when there are differences.

Sometimes floor or ceiling effects are hints that the range of the variable is not chosen correctly. But this does not apply in our case, because the range of using technology from 0 to 100% is as wide as it can be. Besides I believe these extreme values do not relate to the true value of technology use in work. I think that today there is almost no work without some sort of technology support. On the other hand it is no very likely that 100% (every second of work) of technology use is realistic.
::::
:::::

## Achievement 2: Conducting one-way ANOVA {#sec-chap07-achievement2}

### Introduction

You can't apply the `r glossary("t-test")` as a number of different pairwise tests to compare categorical variables that have several levels (groups). The problem is that the `r glossary("Type-1", "Type I error")` piles ab with several tests. For example: With five groups in the `DEGREE` variable, pairwise comparisons with a t-test (i.e., conducting `r glossary("pairwise comparisons")`) would result in 10 t-tests. If each t-test had a p-value threshold of .05 for statistical significance, the probability of at least one Type I error is fairly high.

***

::: {#exp-chap07-type-1-2-errors}

- **Type I error**: A glossary("Type-1", "Type I error")`, also called $\alpha$, is when there is no relationship but the study detects one. The $\alpha$ for Type I error is also the threshold set for statistical significance. The threshold for statistical significance is the amount of uncertainty tolerated in concluding whether or not a result is statistically significant.
- **Type II error**: A `r glossary("Type-2", "Type II error")`, also called $\beta$, occurs when there is a relationship but the study did not detect it.
- **Statistical power**: The power of a statistical test is the probability that the results of the test are not a Type II error.

Definition of Type I and Type II errors
:::
***


:::::{.my-theorem}
:::{.my-theorem-header}
:::::: {#thm-chap07-familywise-type-1}
: Probability of a Type I error when there are multiple comparisons
::::::
:::
::::{.my-theorem-container}
$$
\begin{align*}
\alpha_{f} = 1 - (1 - \alpha_{i})^c \\
c = \frac{k(k-1)}{2}
\end{align*}
$$ {#eq-chap07-familywise-type-1}

***

- $\alpha_{f}$: `r glossary("familywise")` Type I error rate
- $\alpha_{i}$: the individual alpha set as the statistical significance threshold
- $c$: number of comparisons
- $k$: total number of groups

***

For a five-group `DEGREE` variable with $\alpha = .05$ for each pairwise comparison the familywise $\alpha_{f}$ would be:

$$
\begin{align*}
\alpha_{f} = 1-(1-0.05_{i})^\frac{5(5-1)}{2} = \\
\alpha_{f} = 1-(1-0.05_{i})^{10} = 0.4012631
\end{align*}
$$

::::
:::::

> With 10 pairwise comparisons, the familywise $\alpha_{f}$ indicated there would be a 40% probability of making a Type I error. To control this error rate, and for efficiency, use a single ANOVA test instead of 10 t-tests. ANOVA is useful for testing whether three or more means are equal. It can be used with two means, but the t-test is preferable because it is more straightforward.

:::::{.my-note}
:::{.my-note-header}
Running many tests
:::
::::{.my-note-container}
I believe that the problem of a rising Type I error with a growing number of pairwise comparisons is also valid for other type of tests. Each test has the .05 threshold and a collection of many different tests with the same data rises the probability of making a Type I error. Using this strategy consciously is one form of `r glossary("p-hacking")`.
::::
:::::


### F-Test statistic for ANOVA

The F-statistic is a ratio where the variation between the groups is compared to the variation within the groups. The between-group variation is in the numerator to calculate F, while the within-group variation is in the denominator.

> Subtracting the grand mean from the group mean results in the difference between the group and the overall sample. The difference between the grand mean and the group mean can be positive or negative and so is squared for the sum to more accurately represent the total of the differences. This squared value is then multiplied by nj or the number of people in the group and divided by k – 1, where k is the number of groups. This results in a numerator that quantifies the difference between the group means and grand mean for all the participants in the sample.

> The denominator sums the squared difference between each individual observation yij and the mean of the individual’s group, quantifying how far the individuals in the group are from the mean of the group. This is divided by the number of individuals in the whole sample minus the number of groups.


:::::{.my-theorem}
:::{.my-theorem-header}
:::::: {#thm-chap07-f-statistic}
: F-Statistic
::::::
:::
::::{.my-theorem-container}

$$
\begin{align*}
F &= \frac{\text{between-group variability}}{\text{within-group variability}} \\
&= \frac{\text{explained variance}}{\text{unexplained variance}} \\
&= \frac{s_{between}^2}{s_{within}^2}
\end{align*}
$$ {#eq-chap07-f-statistic}

***

> The F-statistic, then, could be referred to as a ratio of explained to unexplained variance. That is, how much of the variability in the outcome does the model explain compared to how much it leaves unexplained? The larger the F-statistic, the more the model has explained compared to what it has left unexplained.

> The F-statistic can also be represented as the ratio of the variance between the groups to the variance within the groups.

::::
:::::

### Computing F-test for using technology at the work place

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap07-f-test}
: F-test for using technology at the work place
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### F-test

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-f-test-usetech-degree}
: Applying F-test `stats::oneway.test()`
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: f-test-usetech-degree

gss_2018_clean <- base::readRDS("data/chap07/gss_2018_clean.rds")

stats::oneway.test(
    formula = USETECH ~ DEGREE,
    data = gss_2018_clean,
    var.equal = TRUE
)
```

::::
:::::


###### grand & group means

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-replicate-figure7-5}
: Distribution of work time spent using technology by educational attainment, with grand mean and group means (Replication of book Figure 7.5)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: techuse-dist-grand-mean
#| fig-cap: "Distribution of work time spent using technology by educational attainment, with grand mean and group means"
#| results: hold

grand_mean <- 
    base::mean(gss_2018_clean$USETECH, na.rm = TRUE)

group_means <- gss_2018_clean |> 
    tidyr::drop_na(USETECH, DEGREE) |> 
    dplyr::group_by(DEGREE) |> 
    dplyr::summarize(mean = mean(USETECH))

gg3_gss_2018 <- gss_2018_clean |> 
  tidyr::drop_na(USETECH) |> 
  ggplot2::ggplot(
      ggplot2::aes(
          x = DEGREE,
          y = USETECH
          )
      ) +
  ggplot2::geom_jitter(
      ggplot2::aes(
          alpha = .6
      ),
      color = "darkgrey"
  ) +
  ggplot2::geom_hline(
      ggplot2::aes(
          yintercept = grand_mean,
          linetype = "solid"
      ),
      color = "steelblue",
      linewidth = 1
  ) +
  ggplot2::geom_point(
      data = group_means,
      ggplot2::aes(
          x = DEGREE,
          y = mean,
          size = 3
      ),
      color = "purple4",
      inherit.aes = FALSE
  ) +
  ggplot2::theme_bw() +
  ggplot2::labs(
      x = "Highest educational attainment", 
      y = "Percent of time spent using technology"
  ) +
  ggplot2::scale_size_continuous(
      name = "",
      labels = "Group mean"
  ) +
  ggplot2::scale_linetype_discrete(
      name = "",
      labels = "Grand mean"
  ) +
  ggplot2::scale_alpha_continuous(
      name = "",
      labels = "Observation"
  )

gg3_gss_2018
```

***
This R-Code junk replicates book’s Figure 7.5, which has no accompanying R code.

> For each group, the group mean does a better job than the `r glossary("grand", "overall mean")` of explaining tech use *for that group*. The difference between the group mean and the overall mean is *how much better* the group mean is at representing the data in the group. This difference is used to compute the numerator of the `r glossary("F-statistic")`.
::::
:::::

###### F-distributions

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-f-dist-examples}
: F-distribution examples
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-f-dist-examples
#| fig-cap: "F-distribution examples"

ggplot2::ggplot(
    tibble::tibble(x = c(0, 5)), 
    ggplot2::aes(x = x,
                 color = "text")
    ) +
    ggplot2::stat_function(fun = df, 
                           args = list(df1 = 4, df2 = 2000), 
                           ggplot2::aes(color = "4, 2000"),
                           linewidth = .7) +
    ggplot2::stat_function(fun = df, 
                           args = list(df1 = 4, df2 = 25), 
                           ggplot2::aes(color = "4, 25"),
                           linewidth = .7) +
    ggplot2::stat_function(fun = df, 
                           args = list(df1 = 2, df2 = 2000), 
                           ggplot2::aes(color = "2, 2000"),
                           linewidth = .7) +
    ggplot2::stat_function(fun = df, 
                           args = list(df1 = 2, df2 = 25), 
                           ggplot2::aes(color = "2, 25"),
                           linewidth = .7) +
    ggplot2::scale_color_manual(
        name = "Degress of freedom\n(num, denom)",
        values = c("purple4", "purple", "green", "seagreen"),
        breaks = c("4, 2000","4, 25","2, 2000", "2, 25")
    )

```

::::
:::::

###### Technology use (ANOVA)

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-f-statistic-tech-use}
: F-distribution for the technology use by degree ANOVA (df = 4 and 1404)
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-f-statistic-tech-use
#| fig-cap: "F-distribution for the technology use by degree ANOVA (df = 4 and 1404)"

ggplot2::ggplot(
    tibble::tibble(x = c(0, 5)), 
    ggplot2::aes(x = x)
    ) +
    ggplot2::stat_function(fun = df, 
                           args = list(df1 = 4, df2 = 1404), 
                           linewidth = .7)
```
***

> The F-distribution in @fig-f-statistic-tech-use suggested the F-statistic of 43.30 was far to the right in the tail of the distribution. The probability of an F-statistic this large or larger if the null were true was reported in the output as < 2.2e-16, which is < .001. With a p-value this tiny, the F-statistic would be considered statistically significant.



::::
:::::


:::

::::
:::::

::: {.callout-tip}
> The mean time spent on technology use was significantly different across degree groups [F(4, 1404) = 43.3; p < .05], indicating that these groups likely came from a population with different mean time spent on technology use by educational attainment. The highest mean was the percent of time used for technology by those with graduate degrees. The lowest mean was the percent of time used for technology by those with less than a high school diploma.
:::


## Achievement 3: Post hoc tests & contrasts {#sec-chap07-achievement3}

`r glossary("ANOVA")` is --- similar as the `r glossary("chi-squared", "chi-squared test")` --- an `r glossary("omnibus")` test: iIt identifies whether there are any differences, but doesn’t give any information about what is driving the significant results.

There are two main ways to determine where significant differences among groups are following a significant omnibus test:

- **Post hoc tests**: Examining each pair of means to determine which means are the most different from each other.
- **Planned contrasts**: Comparing specified subsets of means or groups of means.

### Post hoc tests

#### Bonferroni

There are several different types of post hoc tests, and one of the more commonly used is the `r glossary("Bonferroni", "Bonferroni post hoc test")`.

The Bonferroni adjustment multiplies each `r glossary("p-value")` from each `r glossary("t-test")` by the overall number of t-tests conducted. There were 10 pairwise comparisons (5 groups each pairwise = 5 * 2), so these p-values have been multiplied by 10. Higher p-values will not reach the threshold for statistical significance as often. Sometimes there are resulting p-values of 1.0000. As the p-value cannot be over 1, so for p-values that are over 1 when adjusted by the multiplication, they are rounded to exactly 1.0000.

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-bonferroni-test}
: Bonferroni post hoc test
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: bonferroni-test

stats::pairwise.t.test(
    x = gss_2018_clean$USETECH,
    g = gss_2018_clean$DEGREE,
    p.adjust.method = "bonferroni"
)

```
***

The output is different from previous statistical testing. Instead of a test statistic like t or F, the output is a matrix of p-values.

The adjusted p-values for seven of the t-tests fall below .05 and so indicate that the difference in mean time using technology between two groups is statistically significant.

- There are significant differences in mean time between less than high school and all of the other groups (p < .05); 
- Likewise, there are significant differences in mean time using technology between high school and all other groups. 
- There are no significant differences among the means of the three college groups (junior college, bachelor, graduate).


::::
:::::

For the report it would be more informative if one could add the group means for the interpretation:

```{r}
#| label: group-means-usetech-degree

gss_2018_clean |> 
    tidyr::drop_na(USETECH, DEGREE) |> 
    dplyr::group_by(DEGREE) |> 
    dplyr::summarize(
        group_means = base::round(base::mean(USETECH), 1)
    )
```

::: {.callout-tip}
> Mean percentage of time using technology at work was statistically significantly (p < .05) lower for people with less educational attainment than a high school diploma (m = 24.8) compared to each of the other groups, where the mean percentage of time using technology ranged from 49.6 to 68.7.
:::

#### Tukey’s Honestly Significance Difference (HSD)

Tukey’s HSD post hoc test is a modified `r glossary("t-test")` with the test statistic, `q`. The `q` test statistic formula is the same as some versions of `t`, but the q-distribution is different from the t-distribution, raising the critical value necessary to reach statistical significance. Even with the same test statistic, it is more difficult to reach statistical significance with a Tukey’s `r glossary("HSD")` q-statistic compared to a t-test.

$$
q = \frac{m_{1} - m_{2}}{se}
$$ {#eq-chap07-hsd}

The `stats::TukeyHSD()` function does not work well with the `stats::oneway.test()` output from earlier, so the entire ANOVA model has to be re-estimated. The `stats:aov()` function works and takes similar arguments to the `stats::oneway.test()` function, so nesting the `stats::aov()` inside the `stats::TukeyHSD()` is one way to go.

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-hsd}
: Compute Tukey’s Honestly Significance Difference (HSD)
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: chap07-hsd

stats::TukeyHSD(
    stats::aov(
    formula = USETECH ~ DEGREE,
    data = gss_2018_clean
    )
)

```

The number of significant results of the 10 test are the same, although the Bonferroni test is more conservative. For example the p-value of the pairwise test between junior college and bachelor are 0.58 in HSD but 1.0 in Bonferroni.

::::
:::::

::: {.callout-tip}
The mean time spent on technology use was significantly different across education groups [F(4, 1404) = 43.3; p < .05], indicating that these groups likely came from a population with different mean time spent on technology use depending on educational attainment. The highest mean was 68.7% of time used for technology for those with graduate degrees. The lowest mean was 24.8% of the time for those with less than a high school diploma. Mean percentage of time using technology was statistically significantly (p < .05) *lower* for people with less than a high school diploma (m = 24.8) compared to each of the other groups where the mean percentage of time using technology ranged from 49.6 to 68.7.
:::


### Planned comparisons

#### Introduction

`r glossary("Planned comparisons")` are computed by developing `r glossary("contrasts")` that specify which means to compare to which other means.

::: {#bul-planned-contrasts}

- The order of the factor variable is the exact order that should be used in the contrast.
- A contrast is a group of numbers used to group categories. 
- The categories grouped together should all be represented by the same number in the contrast. 
- The numbers in the contrast should all add to zero. 
- Any category not included in the contrast should be represented by a zero.

Rules for planned contrasts 
:::

For example, to compare all the college groups to the high school group, the contrast would omit the less than high school group and compare the mean for everyone in the high school group to the mean of the combined three college groups: junior college, bachelor, and graduate.

- 0 (< high school: do not include) 
- 3 (high school) 
- –1 (junior college) 
- –1 (bachelor) 
- –1 (graduate)

The three categories represented by –1 will be grouped together because they are all represented by the same number.

#### Compute planned contrasts

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap07-planned-constrasts}
: Planned contrasts of using technology by degree
::::::
:::
::::{.my-example-container}


::: {.panel-tabset}

###### high school & colleges

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-contrast-high-school-colleges}
: Planned contrasts of using technology for the college groups to high school group
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: contrast-high-school-colleges
#| results: hold

## 1. put the contrast into a vector
contrast1 <- c(0, 3, -1, -1, -1)

## 2. link the contrast to the categorical variable using contrasts()
stats::contrasts(x = gss_2018_clean$DEGREE) <- contrast1

## 2a. view the structure of the DEGREE variable with contrast
glue::glue("************** View the structure of DEGREE variable *****************")
utils::str(object = gss_2018_clean$DEGREE)

## 3. re-run the model using aov()
usetech_degree_aov <- stats::aov(
    formula = USETECH ~ DEGREE,
    data = gss_2018_clean
)

## 4. apply the contrasts to the aov object
glue::glue(" ")
glue::glue("******************* Summarize the aov object ****************************")
stats::summary.aov(
    object = usetech_degree_aov,
    split = list(DEGREE = 
            list("high school vs. all college" = 1)))

```

***

The output showed that mean technology use for those who finished high school was statistically significantly different from mean technology use for the three college groups combined [F(1, 1404) = 50.41; p < .001].

To understand more of what was happening we need to lookat the means being compared with this contrast.

::::
:::::


###### recode high school & colleges

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-contrast-no-high-school-colleges}
: Using technology for the recoded planned contrast between college groups to high school group
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: contrast-no-high-school-colleges

gss_2018_clean |> 
    dplyr::mutate(DEGREE =
          forcats::fct_collapse(DEGREE,
                `all college` = c(
                    "junior college",
                    "bachelor",
                    "graduate"
                    ) 
                )
          ) |> 
    dplyr::group_by(DEGREE) |> 
    dplyr::summarize(mean_usetech = mean(USETECH, na.rm = TRUE),
                     sd_usetech = sd(USETECH, na.rm = TRUE))
```
***

I have used here the first time the `forcats::fct_collaps()` function. This is more understandable as the option in the book, where (a) all factors are recoded and the thre highest factors with the same name "all college".

The difference between the mean technology use time for high school (m = 49.61) compared to all college groups combined (m = 66.97) is pretty large.

::::
:::::

###### Plot hs & colleges

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-graph-contrast-no-high-school-colleges}
: Plot of using technology for the recoded planned contrast between college groups to high school group
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-graph-contrast-no-high-school-colleges
#| fig-cap: "Contrast between time using technology for the high school group to the three college groups (junior college, beachelor, graduate)"

gss_2018_clean |> 
    dplyr::mutate(DEGREE =
          forcats::fct_collapse(DEGREE,
                `all college` = c(
                    "junior college",
                    "bachelor",
                    "graduate"
                    ) 
                )
          ) |> 
    dplyr::filter(DEGREE == "high school" | DEGREE == "all college") |> 
    
    ggplot2::ggplot(
        ggplot2::aes(
            y = USETECH, 
            x = DEGREE, 
            fill = DEGREE, 
            color = DEGREE
        )
    ) +
    ggplot2::geom_boxplot(
        alpha = .4,
        na.rm = TRUE
        ) + 
    ggplot2::geom_jitter(
        alpha = .6,
        na.rm = TRUE
        ) + 
    ggplot2::scale_fill_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::scale_color_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::labs(
        x = "Educational attainment", 
        y = "Percent of time spent using technology"
        )
```
***
It is clear that the means of these two groups are different. The same probably would also be true for the less than high school group with the three college groups.
::::
:::::

###### < hs to colleges

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-contrast-less-hs-colleges}
: Planned contrasts of time using technology on the job between college groups to less than high school group
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: contrast-less-hs-colleges
#| results: hold

## 1. less than high school v. all college contrast
contrast2 <- base::c(3, 0, -1, -1, -1)

## 2. bind the two contrasts together (matrix required!)
my_contrasts <- 
    as.matrix(dplyr::bind_cols(
        contrast1 = contrast1, 
        contrast2 = contrast2))

## 3. connect the tibble with factor variable
stats::contrasts(gss_2018_clean$DEGREE) <-  my_contrasts

## 4. compute ANOVA with planned contrasts
stats::summary.aov(
    object = usetech_degree_aov,
    split = list(DEGREE = 
            list("high school vs. all college" = 1,
                 "< high school vs. all college" = 2)
            )
    )
```

::::
:::::

###### plot < hs & colleges

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-graph-less-than-hs-all-colleges}
: Plot of using technology for the recoded planned contrast between college groups to less than high school group
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-graph-less-than-hs-all-colleges
#| fig-cap: "Distribution of tech use at work by degree for contrast comparing all college groups combined to each of the other groups"

gss_2018_clean |> 
    dplyr::mutate(DEGREE =
          forcats::fct_collapse(DEGREE,
                `all college` = c(
                    "junior college",
                    "bachelor",
                    "graduate"
                    ) 
                )
          ) |> 
    
    ggplot2::ggplot(
        ggplot2::aes(
            x = DEGREE, 
            y = USETECH, 
            fill = DEGREE, 
            color = DEGREE
        )
    ) +
    ggplot2::geom_boxplot(
        alpha = .4,
        na.rm = TRUE
        ) + 
    ggplot2::geom_jitter(
        alpha = .6,
        na.rm = TRUE
        ) + 
    ggplot2::scale_fill_manual(
        values = c("gray70", "#7463AC", "dodgerblue"), 
        guide = "none"
        ) + 
    ggplot2::scale_color_manual(
        values = c("gray70", "#7463AC", "dodgerblue"), 
        guide = "none"
        ) + 
    ggplot2::labs(
        x = "Educational attainment", 
        y = "Percent of time spent using technology"
        )

```

::::
:::::

###### 4 contrasts

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-4-contrasts}
: Four planned comparisons
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: chap07-4-contrasts

## contrasts for ANOVA of tech time by degree 
c1 <- c(2, -1, -1, 0, 0) 
c2 <- c(0, 3, -1, -1, -1) 
c3 <- c(0, 0, 2, -1, -1) 
c4 <- c(0, 0, 0, -1, 1) 

## bind the contrasts into a matrix 
conts <- cbind(c1, c2, c3, c4) 
conts

```

***

:::::{.my-procedure}
:::{.my-procedure-header}
:::::: {#prp-chap07-check-contrasts}
: Check the values of the contrasts
::::::
:::
::::{.my-procedure-container}
1. Add up each contrast to make sure it adds to zero. 
2. Multiply each value in each contrast with the corresponding values in the other contrasts and add up the products; this should also add to zero.
::::
:::::

**ad 1**: The vectors are now columns. An example of a check is to sum the column c1: $2 + (-1) + (-1) + 0 + 0 = 0$. Columns c2, c3 and c4 also result to $0$. So the first check conditions was passed.

**ad 2**: Now we have to multiply the values row-wise: $2 \times 0 \times 0 \times 0 = 0$ It is easy to check: Whenever there is $0$ in one of the columns then the result is also $0$. Adding all these products together results in $0 + 0 + 0 + 0 + 0 = 0$, so the second requirement is also met.

::::
:::::

###### `aov()` 4 contrasts

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-aov-4-contrasts}
: Conncet the matrix with all levels of the factor variable
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: chap07-aov-4-contrasts

## connect the matrix with the factor variable 
stats::contrasts(x = gss_2018_clean$DEGREE) <- conts 

## estimate the ANOVA with 4 independent contrasts 
usetech_degree_4_contrasts <- 
    summary.aov(object = usetech_degree_aov, 
        split = list(DEGREE = 
             list("< high school vs. high school & jr college" = 1, 
                  "high school vs. all college" = 2, 
                  "jr college vs. bach or grad degree" = 3, 
                  "bachelor’s vs. graduate degree" = 4)
             )
        ) 
usetech_degree_4_contrasts
```


::::
:::::

###### Adjust p-values

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-adjust-p-values}
: Adjust p-values for multiple comparisons
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: adjust-p-values

adj_p_values <- stats::p.adjust(
    p = usetech_degree_4_contrasts[[1]][["Pr(>F)"]], 
    method = "bonferroni"
    )
adj_p_values
```
***

The adjusted p-values were still very small, so the conclusions about statistical significance did not change, even when using a conservative adjustment like `r glossary("Bonferroni")`.

::::
:::::

###### Violin plot

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-4-planned-comp-violin-plot}
: Visualizing the distribution of technology use at work by educational attainment for four planned comparisons
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-4-planned-comp-violin-plot
#| fig-cap: "Visualizing the distribution of technology use at work by educational attainment for four planned comparisons (violin plot)"
#| fig-height: 10
#| results: hold
#| cache: true

## < high school / hs & jr college ########
gg_violin1 <- gss_2018_clean |>
  dplyr::mutate(DEGREE = 
        dplyr::if_else(DEGREE == "< high school", "< high school",
        dplyr::if_else(DEGREE %in% c("high school", 
                                     "junior college"),
                                     "high school & jr college",
                                     NA))) |>
  dplyr::mutate(DEGREE = 
         base::factor(DEGREE, levels = c("< high school",
                                         "high school & jr college"),
                                         ordered = T)) |>
  dplyr::filter(DEGREE == "< high school" | 
                DEGREE == "high school & jr college") |> 

      ggplot2::ggplot(
        ggplot2::aes(
            y = USETECH, 
            x = DEGREE, 
            fill = DEGREE, 
            color = DEGREE
        )
    ) +
    ggplot2::geom_violin(
        alpha = .4,
        na.rm = TRUE
        ) + 
    ggplot2::geom_jitter(
        alpha = .6,
        na.rm = TRUE
        ) + 
    ggplot2::scale_fill_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::scale_color_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::labs(
        x = "Educational attainment", 
        y = "Percent of time spent using technology"
        )
    
    
## high school & three college groups##########
gg_violin2 <- gss_2018_clean |> 
    dplyr::mutate(DEGREE =
          forcats::fct_collapse(DEGREE,
                `all college` = c(
                    "junior college",
                    "bachelor",
                    "graduate"
                    ) 
                )
          ) |> 
    dplyr::filter(DEGREE == "high school" | DEGREE == "all college") |>
    ggplot2::ggplot(
        ggplot2::aes(
            y = USETECH, 
            x = DEGREE, 
            fill = DEGREE, 
            color = DEGREE
        )
    ) +
    ggplot2::geom_violin(
        alpha = .4,
        na.rm = TRUE
        ) + 
    ggplot2::geom_jitter(
        alpha = .6,
        na.rm = TRUE
        ) + 
    ggplot2::scale_fill_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::scale_color_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::labs(
        x = "Educational attainment", 
        y = "Percent of time spent using technology"
        )

## jr college & bachelor & graduate ##########
gg_violin3 <- gss_2018_clean |> 
    dplyr::mutate(DEGREE = 
    dplyr::if_else(DEGREE %in% c("< high school", "high school"), NA,
    dplyr::if_else(DEGREE == "junior college", "jr college",
    dplyr::if_else(DEGREE %in% c("bachelor", "graduate"),
                                 "bachelor or graduate", NA)))) |>
    dplyr::mutate(DEGREE = 
      base::factor(DEGREE, 
                   levels = c("jr college", 
                              "bachelor or graduate", 
                              ordered = T))) |>
    dplyr::filter(DEGREE == "jr college" | DEGREE == "bachelor or graduate") |>
    
    ggplot2::ggplot(
        ggplot2::aes(
            y = USETECH, 
            x = DEGREE, 
            fill = DEGREE, 
            color = DEGREE
        )
    ) +
    ggplot2::geom_violin(
        alpha = .4,
        na.rm = TRUE
        ) + 
    ggplot2::geom_jitter(
        alpha = .6,
        na.rm = TRUE
        ) + 
    ggplot2::scale_fill_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::scale_color_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::labs(
        x = "Educational attainment", 
        y = "Percent of time spent using technology"
        )

## bachelor & graduate ############
gg_violin4 <- gss_2018_clean |> 
    dplyr::mutate(DEGREE = 
        dplyr::if_else(DEGREE == "bachelor", "bachelor",
        dplyr::if_else(DEGREE == "graduate", "graduate", NA))) |>
      dplyr::mutate(DEGREE = 
        base::factor(DEGREE, 
                     levels = c("bachelor", 
                                "graduate", 
                                ordered = T))) |>
    dplyr::filter(DEGREE == "bachelor" | DEGREE == "graduate") |> 

    ggplot2::ggplot(
        ggplot2::aes(
            y = USETECH, 
            x = DEGREE, 
            fill = DEGREE, 
            color = DEGREE
        )
    ) +
    ggplot2::geom_violin(
        alpha = .4,
        na.rm = TRUE
        ) + 
    ggplot2::geom_jitter(
        alpha = .6,
        na.rm = TRUE
        ) + 
    ggplot2::scale_fill_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::scale_color_manual(
        values = c("gray70", "#7463AC"), 
        guide = "none"
        ) + 
    ggplot2::labs(
        x = "Educational attainment", 
        y = "Percent of time spent using technology"
        )

gridExtra::grid.arrange(
    gg_violin1, gg_violin2,
    gg_violin3, gg_violin4,
    ncol = 2)
```

***
This is the replication of book’s Figure 7.10.
::::
:::::

###### final

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-planned-comp-final}
: Numbered R Code Title
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: planned-comp-final
#| cache: true
#| results: hold



## contrast 1 statistics ###########
glue::glue(" ")
glue::glue("#################### contrast 1 statistics ###################")
gss_2018_clean  |> 
  dplyr::mutate(DEGREE = 
        dplyr::if_else(DEGREE == "< high school", "< high school",
        dplyr::if_else(DEGREE %in% c("high school", 
                                     "junior college"),
                                     "high school & jr college",
                                     NA))) |>
  dplyr::mutate(DEGREE = 
         base::factor(DEGREE, levels = c("< high school",
                                         "high school & jr college"),
                                         ordered = T)) |>
  dplyr::group_by(DEGREE) |>
  dplyr::summarise(
      mean_usetech = base::mean(x = USETECH, na.rm = T),
      sd_usetech = stats::sd(x = USETECH, na.rm = T))



## contrast 2 statistics ##############
glue::glue(" ")
glue::glue("#################### contrast 2 statistics ###################")
gss_2018_clean |>
  dplyr::mutate(DEGREE = 
         base::factor(DEGREE, labels = c(NA,
               "high school", "all college",
               "all college", "all college"),
               ordered = T)) |>
  dplyr::group_by(DEGREE) |>
  dplyr::summarise(
      mean_usetech = mean(x = USETECH, na.rm = T),
      sd.usetech = sd(x = USETECH, na.rm = T)) 

## contrast 3 statistics ##############
glue::glue(" ")
glue::glue("#################### contrast 3 statistics ###################")
gss_2018_clean |>
  dplyr::mutate(DEGREE = 
    dplyr::if_else(DEGREE %in% c("< high school", "high school"), NA,
    dplyr::if_else(DEGREE == "junior college", "jr college",
    dplyr::if_else(DEGREE %in% c("bachelor", "graduate"),
                                 "bach or grad degree", NA)))) |>
    dplyr::mutate(DEGREE = 
      base::factor(DEGREE, 
                   levels = c("jr college", 
                              "bach or grad degree", 
                              ordered = T))) |>
  dplyr::group_by(DEGREE) |>
  dplyr::summarise(
      mean_usetech = mean(x = USETECH, na.rm = T),
      sd.usetech = sd(x = USETECH, na.rm = T))

# contrast 4 statistics ####################
glue::glue(" ")
glue::glue("#################### contrast 4 statistics ###################")
gss_2018_clean |>
  dplyr::mutate(DEGREE = 
    dplyr::if_else(DEGREE == "bachelor", "bachelor",
    dplyr::if_else(DEGREE == "graduate", "graduate", NA))) |>
  dplyr::mutate(DEGREE = 
    base::factor(DEGREE, 
                 levels = c("bachelor", 
                            "graduate", 
                            ordered = T))) |>
  dplyr::group_by(DEGREE) |>
  dplyr::summarise(
     mean_usetech = mean(x = USETECH, na.rm = T),
     sd_usetech = sd(x = USETECH, na.rm = T))

```

::::
:::::




:::

::::
:::::

::: {.callout-tip}
The mean time spent on technology use at work was significantly different across educational attainment groups [F(4, 1404) = 43.3; p < .05], indicating these groups likely came from populations with different mean time spent on technology use. The highest mean was percent of time used for technology for those with graduate degrees. The lowest mean was percent of time for those with less than a high school diploma. A set of planned comparisons found that the mean time spent using technology was statistically significantly (p < .05) lower for (a) those with < high school education (m = 24.8) compared to those with high school or junior college (m = 51.7), (b) those with a high school education (m = 49.61) compared to those with all college groups combined (m = 67.0), (c) those with a junior college degree (m = 62.4) compared to those with a bachelor’s or graduate degree (m = 68.2), and (d) those with a bachelor’s degree (m = 67.9) compared to those with a graduate degree (m = 68.7). Overall, the patterns show statistically significant increases in time spent using technology at work for those with more education.
:::

How many contrasts could be done and how all these statistical comparisons might be inflating the Type I error? --- In addition to each comparison comparing two things and each comparison adding to zero, the planned comparisons as a group should isolate each group (e.g., the high school group) *only one time*. This ensures that the contrasts are independent of each other since the variance for each group is only used by itself in a statistical comparison one time. Because each group is isolated one time, the total maximum number of contrasts allowable is one less than the number of groups.

> When you have hypotheses ahead of time about which groups are different from one another, use `r glossary("planned comparisons")`. When you do not have hypotheses ahead of time about which means are different from each other, use post hoc tests if the ANOVA has a statistically significant `r glossary("F-statistic")`. Good research practices suggest that having hypotheses ahead of time is a stronger strategy unless the research is truly exploratory.

::: {#bul-characeristic-contrast}

- Contrast values add to zero. 
- Each contrast compares two groups. 
- Each category is only isolated one time. 
- The maximum number of contrasts is one less than the number of categories.

Characteristics of contrasts

:::

## Achievement 4: Effect sizes for ANOVA {#sec-chap07-achievement4}

Similar as the effect size `r glossary("Cramér’s V")` for `r glossary("chi-squared")` tests and `r glossary("Cohen’s d")` for t-test, there are also effect size indices for ANOVA:

- **`r glossary("eta-squared")`**: It has a positive bias
- **`r glossary("omega-squared")`**: An unbiased modern alternative

:::::{.my-theorem}
:::{.my-theorem-header}
:::::: {#thm-chap07-omega-squared}
: Formula for omega-squared
::::::
:::
::::{.my-theorem-container}
$$
\omega^2 = \frac{F - 1}{f + \frac{n-k+1}{k-1}}
$$ {#eq-chap07-omega-squared}

- **F**: Statistics from the ANOVA result
- **n**: Number of observations
- **k**: Number of groups

::::
:::::



:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-omega-squared-manual}
: Manual computation of effect size omega-squared
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: omega-squared-manual
#| results: hold

gss_2018_clean <- base::readRDS("data/chap07/gss_2018_clean.rds")

usetech_degree_aov <- stats::aov(
    formula = USETECH ~ DEGREE,
    data = gss_2018_clean
)

glue::glue("############# ANOVA model USETECH ~ DEGREE ##################")
(
    usetech_degree_aov_summary <- base::summary(usetech_degree_aov)
)

F_value = usetech_degree_aov_summary[[1]][["F value"]][[1]]
n = base::nrow(usetech_degree_aov[["model"]])
k = usetech_degree_aov[["rank"]]


glue::glue(" ")
glue::glue("############# Omega-squared ##################")
omega_squared <- (F_value - 1) / (F_value + ((n - k + 1) / (k - 1)))
omega_squared
```
***

:::::{.my-watch-out}
:::{.my-watch-out-header}
WATCH OUT! Error in the book’s calculation
:::
::::{.my-watch-out-container}
In the first term in the book `-1` is missing! The formula is `F-1` that should be therefore `(summ.tech.anova[[1]][1, 4] -1)`. 

With this correction we get the same value as in the manual calculation: `r omega_squared`.
::::
:::::

::::
:::::

:::::{.my-assessment}
:::{.my-assessment-header}
:::::: {#cor-chap07-omega-squared}
: Interpretation of omega-squared effect size
::::::
:::
::::{.my-assessment-container}

- **Small**: $ω^2 = .01 \text{ to } ω^2 < .06$
- **Medium**: $ω^2 = .06 \text{ to } ω^2 < .14$
- **Large**: $ω^2 ≥ .14$

***
This is quite similar to the eta_squared ($\eta^2$) assessment as listed in [Computation of Effect Sizes](https://www.psychometrica.de/effect_size.html). 

::::
:::::

::: {.callout-tip}
The mean time spent on technology use at work was significantly different across educational attainment groups [F(4, 1404) = 43.3; p < .05], indicating these groups likely came from populations with different mean time spent on technology use. The highest mean was percent of time used for technology for those with graduate degrees. The lowest mean was percent of time for those with less than a high school diploma. A set of planned comparisons found that the mean time spent using technology was statistically significantly (p < .05) lower for (a) those with < high school education (m = 24.8) compared to those with high school or junior college (m = 51.7), (b) those with a high school education (m = 49.61) compared to those with all college groups combined (m = 67.0), (c) those with a junior college degree (m = 62.4) compared to those with a bachelor’s or graduate degree (m = 68.2), and (d) those with a bachelor’s degree (m = 67.9) compared to those with a graduate degree (m = 68.7). Overall, the patterns show statistically significant increases in time spent using technology at work for those with more education. The strength of the relationship between degree and time using technology at work was medium ($ω^2$ = .11).
:::

## Achievement 5: Testing ANOVA assumptions {#sec-chap07-achievement5}

0. **Continuous variable and independent groups**: This is the prerequisite for ANOVA.
1. **Normality**: Each sample was drawn from a normally distributed population.
2. **Equal Variances**: The variances of the populations that the samples come from are equal.
3. **Independence**: The observations in each group are independent of each other and the observations within groups were obtained by a random sample.

### Testing normality

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap07-testing-normality}
: Testing normality
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Density plot

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-testing-normality-density-plot}
: Testing normality with density plots
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-testing-normality-density-plot
#| fig-cap: "Density Plot: Testing normality of time spent with technology at the job diferentiated by highest educational attainment"

gss_2018_clean |> 
    tidyr::drop_na(USETECH) |> 
    ggplot2::ggplot(
        ggplot2::aes(x = USETECH)
    ) +
    ggplot2::geom_density(
        ggplot2::aes(
            fill = DEGREE
        )
    ) +
    ggplot2::facet_wrap(
        facets = ggplot2::vars(DEGREE),
        nrow = 2
    ) +
    ggokabeito::scale_fill_okabe_ito(guide = "none") +
    ggplot2::labs(
        x = "Percent of time using tech", 
        y = "Probability density")
```
***

None of these graphs looks normally distributed!
::::
:::::

###### Q-Q plot small

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-testing-normality-qq-plot1}
: Testing normality with Q-Q plots
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-testing-normality-qq-plot1
#| fig-cap: "Q-Q Plot: Testing normality of time spent with technology at the job diferentiated by highest educational attainment"
#| cache: true

gss_2018_clean  |> 
  tidyr::drop_na(USETECH) |>
  
  ggplot2::ggplot(
      ggplot2::aes(sample = USETECH)
      ) +
  ggplot2::geom_abline(
      ggplot2::aes(
          intercept = mean(USETECH), 
          slope = sd(USETECH), 
          linetype = "Normally distributed"),
          color = "gray60", 
          linewidth = 1
      ) +
  ggplot2::stat_qq(
      ggplot2::aes(color = DEGREE)
      ) +
  ggokabeito::scale_color_okabe_ito(guide = "none") +
  ggplot2::scale_linetype_manual(
      name = "",
      values = 1) +
  ggplot2::labs(
      x = "Theoretical normal distribution",
      y = "Observed values of percent time using tech"
      ) +
  ggplot2::facet_wrap(
      facets = ggplot2::vars(DEGREE), 
      nrow = 2
      )
```

***

The text in the books says that "none of the groups appeared to be normally distributed based on either type of plot." This is ok for me with the density plot. But for me with not so much experience it is difficult to decide with the small Q-Q plots.

The next tab display the Q-Q plots for each group much bigger.

::::
:::::

###### Q-Q plot big

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-testing-normality-qq-plot2}
: Testing normality with Q-Q plots
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-testing-normality-qq-plot2
#| fig-cap: "Q-Q Plot: Testing normality of time spent with technology at the job diferentiated by highest educational attainment"
#| fig-height: 12
#| cache: true

gss_2018_clean  |> 
  tidyr::drop_na(USETECH) |>
  
  ggplot2::ggplot(
      ggplot2::aes(sample = USETECH)
      ) +
  ggplot2::geom_abline(
      ggplot2::aes(
          intercept = mean(USETECH), 
          slope = sd(USETECH), 
          linetype = "Normally distributed"),
          color = "gray60", 
          linewidth = 1
      ) +
  ggplot2::stat_qq(
      ggplot2::aes(color = DEGREE)
      ) +
  ggokabeito::scale_color_okabe_ito(guide = "none") +
  ggplot2::scale_linetype_manual(
      name = "",
      values = 1) +
  ggplot2::theme(legend.position = "top") +
  ggplot2::labs(
      x = "Theoretical normal distribution",
      y = "Observed values of percent time using tech"
      ) +
  ggplot2::facet_wrap(
      facets = ggplot2::vars(DEGREE), 
      nrow = 5
      )
```
***

Now I can see it very clearly: All groups are not normally distributed. One can also observe that the floor and ceiling values are driving some of the non-normality.
::::
:::::

###### Shapiro-Wilk test

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-testing-normality-shapiro-wilk}
: Numbered R Code Title
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: testing-normality-shapiro-wilk
#| fig-cap: "Shapiro-Wilk: Testing normality of time spent with technology at the job diferentiated by highest educational attainment"
#| cache: true
#| results: hold

glue::glue("###### Test for the whole numeric USETECH vector #######")
stats::shapiro.test(gss_2018_clean$USETECH)

glue::glue(" ")
glue::glue("###### Test for DEGREE groups of USETECH vector #######")
gss_2018_clean |> 
    dplyr::select(USETECH, DEGREE) |> 
    tidyr::drop_na() |> 
    dplyr::group_by(DEGREE) |> 
    dplyr::summarize(
        shapiro_p_value = stats::shapiro.test(USETECH)$p.value
    )
```

***

In contrast with the systolic blood pressure data we have this time less than 5,000 observations and can therefore apply the `r glossary("Shapiro-Wilk", "Shapiro-Wilk test")`  (see @sec-chap06-omnibus-tests).

All five of the Shapiro-Wilk tests were statistically significant, indicating that the null hypothesis for this test (i.e., the data are normally distributed) has to be rejected for each group.
::::
:::::


:::

::::
:::::

### Testing homogeneity of variances

The data need to be not only normally distributed, but also spread out equally in each group, e.g. we need equal variances across groups.

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap07-testing-homogeneity-levine-test}
: Levine’s test: Testing homogeneity of variances
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: testing-homogeneity-levine-test

car::leveneTest(
    y = USETECH ~ DEGREE, 
    data = gss_2018_clean, 
    center = mean)
```
***
The p-value for the Levene’s test suggests that we need to reject the null hypothesis. The variances of the `USETECH` variable are statistically significantly different across groups (p < .05). The ANOVA fails the assumption of homogeneity of variances.
::::
:::::

## Achievement 6: Alternative tests for ANOVA (#sec-chap07-achivement6)

## Exercises (empty)

## Packages introduced in this chapter (empty)

### dunn.test

:::::{.my-resource}
:::{.my-resource-header}
dunn.test: Dunn's Test of Multiple Comparisons Using Rank Sums 
:::
::::{.my-resource-container}

***

::: {#pak-dunn.test}

***

{**dunn.test**}: [Dunn's Test of Multiple Comparisons Using Rank Sums](https://cran.r-project.org/package=dunn.test) [@dunn.test]

Computes Dunn's test [@dunn1964] for stochastic dominance and reports the results among multiple pairwise comparisons after a Kruskal-Wallis test for stochastic dominance among k groups [@kruskal1952. The interpretation of stochastic dominance requires an assumption that the CDF of one group does not cross the CDF of the other. 

{**dunn.test**} makes k(k-1)/2 multiple pairwise comparisons based on Dunn's z-test-statistic approximations to the actual rank statistics. The null hypothesis for each pairwise comparison is that the probability of observing a randomly selected value from the first group that is larger than a randomly selected value from the second group equals one half; this null hypothesis corresponds to that of the `r glossary("Mann-Whitney", "Wilcoxon-Mann-Whitney rank-sum test")`. Like the rank-sum test, if the data can be assumed to be continuous, and the distributions are assumed identical except for a difference in location, Dunn's test may be understood as a test for median difference. {**dunn.test**} accounts for tied ranks.

{**dunn.test**}: Dunn's Test of Multiple Comparisons Using Rank Sums
:::

***
::::
:::::


## Glossary

```{r}
#| label: glossary-table
#| echo: false

glossary_table()
```

------------------------------------------------------------------------


## Session Info {.unnumbered}

:::::{.my-r-code}
:::{.my-r-code-header}
Session Info
:::
::::{.my-r-code-container}

```{r}
#| label: session-info

sessioninfo::session_info()
```


::::
:::::
