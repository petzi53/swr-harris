# Probability distribution {#sec-chap04}

```{r}
#| label: setup
#| include: false

base::source(file = "R/helper.R")
```

## Achievements to unlock

::: my-objectives
::: my-objectives-header
Objectives
:::

::: my-objectives-container
**SwR Achievements**

- **Achievement 1**: Defining and using probability distributions to infer from a sample (@sec-chap04-achievement1)
- **Achievement 2**: Understanding the characteristics and uses of a binomial distribution of a binary variable (@sec-chap04-achievement2)
- **Achievement 3**: Understanding the characteristics and uses of the normal distribution of a continuous variable (@sec-chap04-achievement3)
- **Achievement 4**: Computing and interpreting z-scores to compare observations to groups (@sec-chap04-achievement4)
- **Achievement 5**: Estimating population means from sample means using the normal distribution (@sec-chap04-achievement5)
- **Achievement 6**: Computing and interpreting confidence intervals around means and proportions (@sec-chap04-achievement6)

:::
:::


## The opioid overdose problem

There is an alarming increases in drug overdoses in the United States in recent years (see [County Health Rankings & Roadmaps website](https://https://www.countyhealthrankings.org/findings-and-insights/2023-county-health-rankings-national-findings-report) and [Data & Documentation](https://www.countyhealthrankings.org/health-data/methodology-and-sources/rankings-data-documentation#main)).

The `r glossary("CDC")` Wonder website has data on the underlying cause of each death in the United States. For drug deaths, the CDC WONDER data include the drug implicated in each death, if available. 

States had begun to adopt policies to try to combat the opioid epidemic. Some of the state-level policy solutions to addressing the increasing number of opioid overdoses: 

- Imposition of quantity limits 
- Required prior authorization for opioids 
- Use of clinical criteria for prescribing opioids 
- Step therapy requirements 
- Required use of prescription drug monitoring programs.

The Kaiser Family Foundation (`r glossary("KFF")`) keeps track of the adoption of these policies across all 50 states and the District of Columbia.

Treatment programs as well as policies depend partly on the distance people have to travel to the nearest health facility. `r glossary("amfAR")`, the Foundation for AIDS Research, which has an Opioid & Health Indicators Database (https://opioid.amfar.org). The data in amfAR’s database includes distance to the nearest substance abuse treatment facility that has medication assisted therapies (MAT).

## Resources & Chapter Outline

### Data, codebook, and R packages {#sec-chap04-data-codebook-packages}

::: my-resource
::: my-resource-header
Data, codebook, and R packages for learning about descriptive statistics
:::

::: my-resource-container

**Data**

1.  Download clean data sets `pdmp_2017_kff_ch4.csv` and `opioid_dist_to_facility_2017_ch4.csv` from
    <https://edge.sagepub.com/harris1e>.
2.  Download the county-level distance data files directly from the amfAR website (https://opioid.amfar.org/indicator/dist_MAT)
3.  Import and clean the data for 2017 from Table 19 in the online report on the [KFF website](https://www.kff.org/report-section/implementing-coverage-and-payment-initiatives-benefits-and-pharmacy/)

**Codebook**

Two options:

1.  Download the codebook file `opioid_county_codebook.xlsx` from
    <https://edge.sagepub.com/harris1e>.
2.  Use the online version of the codebook from the amfAR Opioid & Health Indicators Database website (https://opioid.amfar.org)



**Packages**

1. Packages used with the book (sorted alphabetically)

-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)

    
2. My additional packages (sorted alphabetically)



:::
:::

### Get data

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-get-data}
: Get data for chapter 4
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### PDMP

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-get-pdmp-book}
: Get the cleaned PDMP data from the book `.csv` file
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: get-pdmp-book
#| reslts: hold
#| eval: false

## run code only once manually ##########

## get pdmp data from .csv file of the book
pdmp_2017_book <- readr::read_csv("data/chap04/pdmp_2017_kff_ch4.csv")
save_data_file("chap04", pdmp_2017_book, "pdmp_2017_book.rds")

```

***

(*For this R code chunk is no output available*)

::::
:::::





###### anfAR

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-amfAR}
: Numbered R Code Title (Tidyverse)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: get-amfar-data
#| eval: false

## run only once, manually ############
amfar_file <- "data/chap04/opioid_dist_to_facility_2017_ch4.csv"

dist_mat <- readr::read_csv(amfar_file)
save_data_file("chap04", dist_mat, "dist_mat.rds")
```

***

(*For this R code chunk is no output available*)

::::
:::::

:::

::::
:::::

***


### Show raw data

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-show-data}
: Show raw data for chapter 4
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### PDMP

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-show-pdmp-data}
: Show data for the prescription drug monitoring programs (PDMPs)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: show-pdmp-data
#| results: hold

pdmp_2017_book <- base::readRDS("data/chap04/pdmp_2017_book.rds")

glue::glue("********************* Show summary *******************")
base::summary(pdmp_2017_book)

glue::glue("")
glue::glue("****************** Show selected data ****************")
glance_data(pdmp_2017_book)
```

::::
:::::


###### dist-mat

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-show-dist-mat}
: Show the distances to nearest substance abuse facility providing medication assisted treatment (MAT)
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: show-dist-mat
#| results: hold

dist_mat <- base::readRDS("data/chap04/dist_mat.rds")

glue::glue("********************* Show summary *******************")
base::summary(dist_mat)

glue::glue("")
glue::glue("****************** Show selected data ****************")
glance_data(dist_mat)

```

::::
:::::

:::

::::
:::::

***

### Recode data

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-recode}
: Recode data for chapter 4
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Transform

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-code-name-a}
: Extend amfAR data with transformed values
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: transform-amfar-distances
#| results: hold
#| cache: true

dist_mat_clean <- dist_mat |> 
    dplyr::mutate(square_root = sqrt(VALUE),
                  cube_root = VALUE^(1/3),
                  log = log(VALUE),
                  inverse = 1/VALUE
    )

save_data_file("chap04", dist_mat_clean, "dist_mat_clean.rds")

base::summary(dist_mat_clean)
glance_data(dist_mat_clean)
```

::::
:::::


###### Rename `VALUE`

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-rename-amfar-distance}
: Rename amfAR `VALUE` to `distance`
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: rename-amfar-distance
#| cache: true

dist_mat_clean2 <- dist_mat |> 
    dplyr::rename(distance = VALUE) 

save_data_file("chap04", dist_mat_clean2, "dist_mat_clean2.rds")
```

***

(*For this R code chunk is no output available*)

::::
:::::

:::

::::
:::::

***


## Achievement 1: Probability distributions to infer from a sample {#sec-chap04-achievement1}

A `r glossary("probability distribution")` is the set of probabilities that each possible value (or range of values) of a variable occurs.

Probability distributions have two characteristics:

1. The probability of each real value of some variable is non-negative; it is either zero or positive. 2. The sum of the probabilities of all possible values of a variable is 1.

There are two categories of probability distributions:

1. Discrete probability distributions: An example is the binomial distribution.
2. Continuous probability distributions: An example is the normal distribution.


## Achievement 2: Binomial distribution of a binary variable {#sec-chap04-achievement2}

### Characteristics of binomial random variables

:::{#bul-chap04-binomial-random-variable}
- A variable is measured in the same way n times. 
- There are only two possible values of the variable, often called “success” and “failure.” 
- Each observation is independent of the others. 
- The probability of “success” is the same for each observation. 
- The random variable is the number of successes in n measurements.

The binomial distribution is defined by two things: 

- **n**, which is the number of observations (e.g., coin flips, people surveyed, states selected) 
- **p**, which is the probability of success (e.g., 50% chance of heads for a coin flip, 51% chance of a state having a PDMP)

Characteristics of binomial random variables
:::
***

### dbinomial() & pbinomial()

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-binomial-distributions}
: Statistical properties of binomial distributions
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### `dbinomial()` with exact `n`

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-comp-dbinomial-exact}
: Compute binomial probability with exact number of success
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: comp-dbinomial-exact

## exact 5 successes from 20 selections 
## with 51% probability of success 
stats::dbinom(x = 5, size = 20, prob = .51) * 100
```
***

Computed the probability given 

- the number of successes (`x`), 
- the sample size (`size =`), and 
- the probability of success (`prob =`).

The probabilities are very small for scenarios of getting *exactly* 10 states with PDMPs in a sample.
::::
:::::

The probabilities are very small for scenarios of getting *exactly* 10 states with `r glossary("PDMP")`s in a sample. The `r glossary("cumulative distribution function")` for the binomial distribution can determine the probability of getting some range of values, which is often more useful than finding the probability of one specific number of successes.


###### `pbinomial()` with range

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-comp-dbinomial-range}
: Compute binomial probability of getting some range of values
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: comp-pbinomial-range
#| results: hold
#| cache: true

base::options(scipen = 999)



## 5 or less successes from 20 selections 
## with 51% probability of success 
pbinom(q = 5, size = 20, prob = .51) * 100

## 10 or more successes from 20 selections 
### with 51% probability of success 
pbinom(q = 5, size = 20, prob = .51, lower.tail = FALSE) * 100


base::options(scipen = 0)
```

- **Exactly 5** successes with a success probability of 51% = `base::round(dbinom(x = 5, size = 20, prob = .51) * 100, 3)` : `r base::round(dbinom(x = 5, size = 20, prob = .51) * 100, 3)`%.
- **5 or fewer** successes with a success probability of 51% = `base::round(pbinom(q = 5, size = 20, prob = .51) * 100, 3)`: `r base::round(pbinom(q = 5, size = 20, prob = .51) * 100, 3)`%.
- **6 or more** successes with a success probability of 51% = `base::round(pbinom(q = 5, size = 20, prob = .51, lower.tail = FALSE) * 100, 3)`: 
`r base::round(pbinom(q = 5, size = 20, prob = .51, lower.tail = FALSE) * 100, 3)`%.

:::::{.my-important}
:::{.my-important-header}
For probabilities `q and more` you have to take `q - 1` and add `lower.tail = FALSE`.
:::
:::::

::::
:::::

###### Sample PDMPs from data

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-sample-pdmp}
: Sample 25 states from population data (n = 51)
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: sample-25-pmpd

pdmp_2017_book <- base::readRDS("data/chap04/pdmp_2017_book.rds")

## set a starting value for sampling 
set.seed(seed = 10) 

## sample 25 states and check 
pdmp_2017_book |>  
    dplyr::select(`Required Use of Prescription Drug Monitoring Programs`) |> 
    dplyr::mutate(`Required Use of Prescription Drug Monitoring Programs` =
          forcats::as_factor(`Required Use of Prescription Drug Monitoring Programs`)) |> 
    dplyr::slice_sample(n = 25) |> 
    base::summary()
```
***

The book features a lengthy explication of the `set.seed()` function and their revised working after R version 3.6. But this important detail is now --- several years after 3.6.0 appeared in April 2019 --- not so relevant anymore.

I had to recode the character variable to a factor and I used `dplyr::slice_sample()` instead of the superseded `dplyr::sample_n()` function.
::::
:::::


:::

::::
:::::

### Visualizing the binomial distribution

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-visualize-binomial-dist}
: Visualizing the binomial distribution
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Distribution only

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-binomial-dist-only}
: Binomial distribution of 20 selected states when 51% have PDMPs
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-binomial-dist-only
#| fig-cap: "Probability mass function plot showing probability of number of selected states \nwith PDMPs out of 20 total selected when 51% have PDMPs overall"


base::set.seed(42)

binomial_data <- tibble::tibble(stats::rbinom(1000, 20, .51)) |> 
    dplyr::rename(data = 1) |> 
    dplyr::mutate(my_color = 
                dplyr::if_else(data <= 5, "purple", "grey")
    )


binomial_data |> 
    ggplot2::ggplot() +
    ggplot2::aes(x = data,
                 y = ggplot2::after_stat(count) / 
                     base::sum(count)
                 ) +
    ggplot2::geom_histogram(
        color = "black", 
        fill = "grey",
        binwidth = 1
        ) +
    ggplot2::theme_bw() +
    ggplot2::scale_x_continuous(
        breaks = base::seq(0, 20, 2)) +
    ggplot2::labs(x = 'States with monitoring programs',
       y = 'Probability exactly this many selected')
```


::::
:::::

:::::{.my-resource}
:::{.my-resource-header}
Helpful code snippet at "ECON 41 Lab"
:::
::::{.my-resource-container}
I got help for the code from [15 Tutorial 4: The Binomial Distribution](https://bookdown.org/gabriel_butler/ECON41Labs/tutorial-4-the-binomial-distribution.html) [@butler2019].

::::
:::::


###### Distribution with marker

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-binomial-dist-marker}
: Probability of 5 or fewer selected states with PDMPs out of 20 total selected \nwhen 51% have PDMPs overall
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-binomial-dist-marker
#| fig-cap: "Probability of 5 or fewer selected states with PDMPs out of 20 total selected when 51% have PDMPs overall"

base::set.seed(42)

colors <- c(rep("purple", 2), rep("grey", 13))

binomial_data <- tibble::tibble(stats::rbinom(1000, 20, .51)) |> 
    dplyr::rename(data = 1) |> 
    dplyr::mutate(my_color = 
                dplyr::if_else(data <= 5, "purple", "grey")
    )


binomial_data |> 
    ggplot2::ggplot() +
    ggplot2::aes(x = data,
                 y = ggplot2::after_stat(count) / 
                     base::sum(count)
                 ) +
    ggplot2::geom_histogram(
        color = "black", 
        fill = colors,
        binwidth = 1
        ) +
    ggplot2::geom_vline(xintercept = 5, 
             linewidth = 1, 
             linetype = 'dashed',
             color = 'red') +
    ggplot2::theme_bw() +
    ggplot2::scale_x_continuous(breaks = base::seq(0, 20, 2)) +
    ggplot2::labs(x = 'States with monitoring programs',
       y = 'Probability exactly this many selected') 
```

::::
:::::

###### Histogram colorized

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-binomial-dist-color}
: Probability of 5 or fewer selected states with PDMPs out of 20 total selected \nwhen 51% have PDMPs overall
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-binomial-dist-color
#| fig-cap: "Probability of 5 or fewer selected states with PDMPs out of 20 total selected when 51% have PDMPs overall"

base::set.seed(42)

binomial_data <- tibble::tibble(stats::rbinom(1000, 20, .51)) |> 
    dplyr::rename(data = 1) |> 
    dplyr::mutate(my_color = 
            dplyr::if_else(data <= 5, "purple", "grey")
    ) |> 
    dplyr::mutate(my_color =
            forcats::as_factor(my_color))


binomial_data |> 
    ggplot2::ggplot() +
    ggplot2::aes(x = data,
                 y = ggplot2::after_stat(count) / 
                     base::sum(count),
                 fill = my_color
                 ) +
    ggplot2::geom_histogram(
        binwidth = 1,
        color = "black"
    ) +
    ggplot2::geom_vline(xintercept = 5, 
             linewidth = 1, 
             linetype = 'dashed',
             color = 'red') +
    ggplot2::theme_bw() +
    ggplot2::scale_x_continuous(breaks = base::seq(0, 20, 2)) +
    ggplot2::scale_fill_manual(name = "Number of states\nwith PDMP",
                               values = c("grey" = "grey",
                               "purple" = "purple"),
                               labels = c("> 5", "5 or fewer")) +
    ggplot2::labs(x = 'States with monitoring programs',
       y = 'Probability exactly this many selected') 
```

::::
:::::

:::

::::
:::::

***

## Achievement 3: Normal distribution of a continuous variable {#sec-chap04-achievement3}

### Working with normal distributions

Binomial data in social sciences are only one type of data. Many data are continuous variables. Just as the shape of the binomial distribution is determined by `n` and `p`, the shape of the normal distribution for a variable in a sample is determined by `$mu$` and `$sigma$`.

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-dist-mat-dist}
: Distribution of the distances to nearest facility providing MAT
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Distances

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-dist-mat-normal}
: Distribution of the original distance variable
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-dist-mat-normal
#| fig-cap: "Distribution of the distance to the nearest facility with MAT"

dist_mat <- base::readRDS("data/chap04/dist_mat.rds")

dist_mat |> 
    ggplot2::ggplot(
        ggplot2::aes(x = VALUE) 
    ) +
    ggplot2::geom_histogram(
        bins = 30,
        fill = "grey",
        color = "black"
        ) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Distance in miles",
        y = "Number of counties"
    )
```

::::
:::::


###### Distances transformed

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-dist-mat-transformed}
: Distribution of the distance variable transformed by various factors
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: fig-dist-mat-transformed
#| fig-cap: "Distribution of the distance variable transformed by various factors"
#| warning: false

## using the extended data frame 
## with square root, cube root, inverse $ log values

p_cube_root <- dist_mat_clean |>
    ggplot2::ggplot(
        ggplot2::aes(x = cube_root)
    ) +
    ggplot2::geom_density(
        color = "black",
        fill = "grey"
    ) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Cube root of miles to nearest facility",
        y = "Density"
    )


p_square_root <- dist_mat_clean |>
    ggplot2::ggplot(
        ggplot2::aes(x = square_root)
    ) +
    ggplot2::geom_density(
        color = "black",
        fill = "grey"
    ) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Distance in square root of miles",
        y = "Density"
    )

p_inverse <- dist_mat_clean |>
    ggplot2::ggplot(
        ggplot2::aes(x = inverse)
    ) +
    ggplot2::geom_density(
        color = "black",
        fill = "grey"
    ) +
    ggplot2::theme_bw() +
    ggplot2::xlim(0, 1) +
    ggplot2::labs(
        x = "Inverse of miles to nearest facility",
        y = "Density"
    )

p_log <- dist_mat_clean |>
    ggplot2::ggplot(
        ggplot2::aes(x = log)
    ) +
    ggplot2::geom_density(
        color = "black",
        fill = "grey"
    ) +
    ggplot2::theme_bw() +
    ggplot2::labs(
        x = "Log of miles to nearest facility",
        y = "Density"
    )
gridExtra::grid.arrange(grobs = list(p_cube_root,
                                     p_square_root,
                                     p_inverse,
                                     p_log),
                        ncol = 2)
```

***

The best result of these transformation was with cube root.

I tried to write a function for these four graphs, but it was not easy to pass the dataframe and column to the function. I finally succeeded with passing the column name as character string and using `[[` inside the function to select the column. (See [StackOverflow](https://stackoverflow.com/a/36015931/7322615)) But I gave up with `xlim()` parameter for the inverse transformation.
::::
:::::

###### Mean and sd

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-mean-sd-distance-transformed}
: Mean and standard deviation for cube root of mile transformation
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: mean-sd-distance-transformed

dist_mat_clean |> 
    dplyr::summarize(mean = mean(cube_root),
                  sd = sd(cube_root))

```

::::
:::::

###### Probability distribution

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-prob-distance-dist}
: Probability density function for a variable with a mean of 2.66 and a standard deviation of .79
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-prob-distance-dist
#| fig-cap: "Probability density function for a variable with a mean of 2.66 and a standard deviation of .79"
#| cache: true

base::set.seed(42)
normal_data <- tibble::tibble(stats::rnorm(
    n = 1e3, 
    mean = 2.66, 
    sd = .79)) |> 
    dplyr::rename(data = 1) 

normal_data |> 
    ggplot2::ggplot() +
    ggplot2::aes(x = data,
                 y = ggplot2::after_stat(count) / 
                     base::sum(count)
                 ) +
    ggplot2::geom_density() +
    ggplot2::theme_bw() +
    ggplot2::labs(x = 'Cube root of miles to the nearest facility with MAT',
       y = 'Probability density')
```
***

In this plot I draw the probability density function with randomly generated data. The above curve will smooth out when I will take a bigger sample (for instance 1e5 instead 1e3).
::::
:::::

###### with shaded area

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-prob-shaded}
: Probability density function of the cube root transformation for 64 miles distance to a treatment facility
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-chap04-prob-shaded
#| fig-cap: "Probability density function of the cube root transformation for 64 miles distance to a treatment facility"
#| cache: true

normal_data |> 
    ggplot2::ggplot(
        ggplot2::aes(x = data)
    ) +
    ggplot2::stat_function(
        fun = dnorm, 
        n = 1e3, 
        args = list(mean = 2.66, 
                    sd = .79),
        linewidth = .5) +
    ggplot2::geom_area(stat = 'function',
            fun = dnorm,
            fill = 'blue',
            args = list(mean = 2.66, 
                    sd = .79),
            xlim = c(4, 6),
            alpha = 0.3) +
    ggplot2::theme_bw() +
    ggplot2::labs(x = 'Cube root of miles to the nearest facility with MAT',
       y = 'Probability density')

```
***

For this plot I have used the `dnorm()` function. Therefore this normal distribution curve is smooth.

The shaded area is the probability for counties that are $4^3 = 64$ miles from a facility that provides medical assisted treatment (MAT) 
::::
:::::

###### Compute shaded area

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-comp-shaded-area}
: Compute shaded area: Percentage of counties where the nearest facility with MAT is 64 miles or more far away
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: comp-shaded-area

stats::pnorm(4, 2.66, .79, lower.tail = FALSE)

```
***

If you want to calculate the right part of the distribution then you need to change the default value from `lower.tail = TRUE` to `lower.tail = FALSE`.
::::
:::::

4.49% of observations were in the shaded part of this distribution and therefore had a value for the distance variable of 4 or greater. Reversing the transformation, this indicated that residents of 4.49% of counties have to travel 43 or 64 miles or more to get to the nearest substance abuse facility providing medication-assisted treatment.

:::

::::
:::::

### Check understanding

Shows shading for the part of the distribution that is less than 2. Estimate (without computing the answer) the percentage of counties in the shaded area.

:::::{.my-exercise}
:::{.my-exercise-header}
:::::: {#exr-chap04-check-achievement3}
: Achievement 3: Check understanding
::::::
:::
::::{.my-exercise-container}

::: {.panel-tabset}

###### Show shaded graph

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-achievement3-graph}
: Shows shading for the part of the distribution that is less than 2
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: fig-chap04-achievement3-graph
#| fig-cap: "Probability density function for a variable with a mean of 2.66 and a standard deviation of .79 with the shaded area for counties that are 16 miles or less from the nearest facility with MAT"


dist_mat_clean |> 
    ggplot2::ggplot(
        ggplot2::aes(x = cube_root)
    ) +
    ggplot2::stat_function(
            fun = dnorm, 
            n = 1e3, 
            args = list(mean = 2.66,
                        sd = .79),
            linewidth = .5) +
    ggplot2::geom_area(stat = 'function',
            fun = dnorm,
            fill = 'blue',
            args = list(mean = 2.66, 
                    sd = .79),
            xlim = c(0, 2),
            alpha = 0.3) +
    ggplot2::theme_bw() +
    ggplot2::labs(x = 'Cube root of miles to the nearest facility with MAT',
       y = 'Probability density')


```

::::
:::::

###### Computation shaded area

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-achievement3-computation}
: Compute area of the shading for the part of the distribution that is 8 miles or less from the nearest facility with MAT
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: achievement3-computation

stats::pnorm(2, mean = 2.66, sd = .79)

```
***

About 20% of the counties are 8 miles or less from the nearest facility with MAT. My estimation of the shaded area without computation would have been much more (about 30-35%).
::::
:::::


:::

::::
:::::


## Achievement 4: z-scores {#sec-chap04-achievement4}

:::::{.my-important}
:::{.my-important-header}
Values of normally distributed variables
:::
::::{.my-important-container}
Regardless of what the mean and standard deviation are, a normally distributed variable has approximately 

- 68% of values within one standard deviation of the mean 
- 95% of values within two standard deviations of the mean 
- 99.7% of values within three standard deviations of the mean

These characteristics of the normal distribution can be used to describe and compare how far individual observations are from a mean value.

::::
:::::

### Defining z-score

:::::{.my-theorem}
:::{.my-theorem-header}
:::::: {#thm-chap04-z-score}
: Z-Score formula
::::::
:::
::::{.my-theorem-container}
$$
z_{i} = \frac{x_{i} - m_{x}}{s_{x}}
$$ {#eq-z-score}

The `r glossary("z-score")` for an observation is the number of standard deviations it is from the mean.

::::
:::::

### z-score calculation & interpretation

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-calc-z-scores}
: Calculation and interpretation of z-scores
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Example 1

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-z-score1}
: Z-score for a county with residents who have to travel 50 miles to the nearest facility
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: z-score1
#| results: hold

cube_miles <- 50^(1/3)
mean = 2.66
sd = .79

(cube_miles - mean) / sd
```
***

This example county is farther than the mean away from the nearest facility with MAT.
::::
:::::


###### Example 2

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-code-name-b}
: Z-score for a county with residents who have to travel 10 miles to the nearest facility
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: z-score2

cube_miles <- 10^(1/3)
mean = 2.66
sd = .79

(cube_miles - mean) / sd
```
***

This example county is less than the mean away from the nearest facility with MAT.

::::
:::::

###### Achievement 4

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-z-score3}
: Z-score for a county where you have to drive 15 miles to the nearest facility with MAT.
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: z-score3

cube_miles <- 15^(1/3)
mean = 2.66
sd = .79

(cube_miles - mean) / sd

```

This example county is less than the mean away from the nearest facility with MAT. (The mean of our transformed data is $2.66^3$ miles = `r 2.66^3`).
::::
:::::


:::

::::
:::::

## Achievement 5: Estimating population means {#sec-chap04-achievement5}

### Samples and populations

:::::{.my-example}
:::{.my-example-header}
:::::: {#exm-chap04-sample-and-population}
: Estimating population means
::::::
:::
::::{.my-example-container}

::: {.panel-tabset}

###### Summarize all

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-summarize-all-distances}
: Summarize distances from the `r glossary("amfAR")` database 
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: summarize-all-distances

## load data with renamed `VALUE` column to `distance`
dist_mat_clean2 <- base::readRDS("data/chap04/dist_mat_clean2.rds")

dist_mat_clean2 |> 
    dplyr::summarize(
        mean_distance = base::mean(distance),
        sd_distance = stats::sd(distance),
        n = dplyr::n()
    )
```

***

These are the value for the population of (almost all) counties of the US (n = 3214). We are going now to get a sample of 500 counties to see how near we will come with the sample summaries to mean and sd of the population .
::::
:::::


###### Summarize sample

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-summarize-sample-distances}
: Draw a sample of 500 counties and compute the summaries
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: summarize-sample-distances
#| results: hold
#| cache: true

set.seed(seed = 1945)
dist_mat_clean2 |> 
    dplyr::slice_sample(n = 500, replace = TRUE) |> 
    dplyr::summarize(
    mean_distance = base::mean(distance),
    sd_distance = stats::sd(distance),
    n = dplyr::n()
    )

set.seed(seed = 48)
dist_mat_clean2 |> 
    dplyr::slice_sample(n = 500, replace = TRUE) |> 
    dplyr::summarize(
    mean_distance = base::mean(distance),
    sd_distance = stats::sd(distance),
    n = dplyr::n()
    )
```

***

One sample is somewhat higher, the other a little lower than the population mean.
::::
:::::

###### Sample of 20 samples

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-sample-of-20-samples}
: Examining a sample of 20 samples from a population
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: sample-of-20-samples
#| results: hold
#| cache: true

## get 20 samples 
## each sample has 500 counties 
## put samples in a data frame with each sample 
## having a unique id called "sample_num"

base::set.seed(111)
dist_mat_sample_20 <- 
    dplyr::bind_rows(
        base::replicate(n = 20, dist_mat_clean2 |> 
                        dplyr::slice_sample(n = 500, replace = TRUE),
                        simplify = FALSE),
        .id = "sample_num")

## find the mean for each sample 
dist_mat_sample_20_means <- dist_mat_sample_20 |> 
    dplyr::group_by(sample_num) |> 
    dplyr::summarize(
        mean_distance = mean(x = distance, na.rm = TRUE))

dist_mat_sample_20_means

## find the mean of the 20 sample means
dist_mat_sample_20_means |> 
    dplyr::summarize(mean_20_means = mean(mean_distance))
```

::::
:::::

###### Sample 100 samples

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-sample-100-samples}
: Examining a sample of 100 samples from a population
::::::
:::
::::{.my-r-code-container}
```{r}
#| label: sample-100-samples
#| results: hold
#| cache: true

## get 100 samples 
## each sample has 500 counties 
## put samples in a data frame with each sample 
## having a unique id called "sample_num"

base::set.seed(143)
dist_mat_sample_100 <- 
    dplyr::bind_rows(
        base::replicate(n = 100, dist_mat_clean2 |> 
                        dplyr::slice_sample(n = 500, replace = TRUE),
                        simplify = FALSE),
        .id = "sample_num")

## find the mean for each sample 
dist_mat_sample_100_means <- dist_mat_sample_100 |> 
    dplyr::group_by(sample_num) |> 
    dplyr::summarize(
        mean_distance = mean(x = distance, na.rm = TRUE))

dist_mat_sample_100_means

## find the mean of the 100 sample means
dist_mat_sample_100_means |> 
    dplyr::summarize(mean_100_means = mean(mean_distance))

dist_mat_sample_100_means |> 
    ggplot2::ggplot(
        ggplot2::aes(x = mean_distance)
    ) +
    ggplot2::geom_histogram(
        bins = 30,
        color = "black",
        fill = "grey") +
    ggplot2::theme_bw()
```


***

Even if the mean of the 100 sample means is already very near from the population value (`r dist_mat_sample_100_means |> dplyr::summarize(mean_100_means = mean(mean_distance)) |> dplyr::pull()` versus `r dist_mat_clean2 |> dplyr::summarize(mean_distance = base::mean(distance)) |> dplyr::pull()`, difference = `r dist_mat_sample_100_means |> dplyr::summarize(mean_100_means = mean(mean_distance)) |> dplyr::pull() - dist_mat_clean2 |> dplyr::summarize(mean_distance = base::mean(distance)) |> dplyr::pull()`) the sampling distribution is still far from a nice normal distribution. This will change if we are going to generate 1000 sample means.
::::
:::::

###### Sample 1000 samples

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-sample-1000-distribution}
: Plot the sample distribution of 1000 samples
::::::
:::
::::{.my-r-code-container}

::: {#lst-sample-distributions}
```{r}
#| label: fig-sample-1000-distribution
#| fig-cap: "Sample distribution of 1000 samples"
#| results: hold
#| cache: true

## get 1000 samples 
## each sample has 500 counties 
## put samples in a data frame with each sample 
## having a unique id called "sample_num"

base::set.seed(159)
dist_mat_sample_1000 <- 
    dplyr::bind_rows(
        base::replicate(n = 1000, dist_mat_clean2 |> 
                        dplyr::slice_sample(n = 500, replace = TRUE),
                        simplify = FALSE),
        .id = "sample_num")

## find the mean for each sample 
dist_mat_sample_1000_means <- dist_mat_sample_1000 |> 
    dplyr::group_by(sample_num) |> 
    dplyr::summarize(
        mean_distance = mean(x = distance, na.rm = TRUE))

dist_mat_sample_1000_means

## find the mean of the 100 sample means
dist_mat_sample_1000_means |> 
    dplyr::summarize(mean_1000_means = mean(mean_distance))

dist_mat_sample_1000_means |> 
    ggplot2::ggplot(
        ggplot2::aes(x = mean_distance)
    ) +
    ggplot2::geom_histogram(
        bins = 30,
        color = "black",
        fill = "grey") +
    ggplot2::theme_bw()


```

Sample distribution of 1000 samples
:::

***

Taking a lot of large samples and graphing their means results in a `r glossary("sampling distribution")` that looks like a normal distribution, and, more importantly, the mean of the sample means is nearly the same as the population mean (`r dist_mat_sample_1000_means |> dplyr::summarize(mean_1000_means = mean(mean_distance)) |> dplyr::pull()` versus `r dist_mat_clean2 |> dplyr::summarize(mean_distance = base::mean(distance)) |> dplyr::pull()`, difference = `r dist_mat_sample_1000_means |> dplyr::summarize(mean_1000_means = mean(mean_distance)) |> dplyr::pull() - dist_mat_clean2 |> dplyr::summarize(mean_distance = base::mean(distance)) |> dplyr::pull()`).

::::
:::::


:::

::::
:::::

### Central Limit Theorem

The fact that the mean of the sample distribution of many samples approximates the population mean is called `r glossary("Central Limit Theorem")`. It holds true for continuous variables that both are and are not normally distributed.

Another characteristic of the Central Limit Theorem is that the standard deviation of the sample means can be estimated using the population standard deviation and the size of the samples that make up the distribution:

$$
s_{sample\space distribution} = \frac{\sigma}{\sqrt{n}}
$$ {#eq-sd-sample-means}

If we want to calculate the standard deviation of the population we cannot use the `stats::sd()`. The reason is that `stats::sd()` uses the `r glossary("Bessel’s correction")` for samples which is not correct for the standard deviation of the population.

Instead to apply the rather complex procedure in the book, I recommend to use the `sd_pop()` function from the {**sjstats**} package (see @pak-sjstats).

### Standard deviation (sd)

The standard deviation of the sampling distribution shows how much we expect sample means to vary from the population mean.


:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-estimated-sd}
: Compute estimated standard deviation of the sampling distributions
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: estimated-sd
#| results: hold

## compute estimated standard dev of sampling dist
dist_mat_clean2  |>  
    tidyr::drop_na(distance) |> # not necessary - no NAs
    dplyr::summarize(n = dplyr::n(), 
                     pop.var = sjstats::var_pop(distance),
                     pop.sd = sjstats::sd_pop(distance),
                     samp_dist_est = pop.sd / base::sqrt(x = 500)
    )

## computing the sample dist standard deviation 
## directly from the 1000 sample means

sd(x = dist_mat_sample_1000_means$mean_distance, 
   na.rm = T)
```

::::
:::::

### Standard error (se)

Since it is unusual to have the entire population for computing the population `r glossary("standard deviation")`, and it is also unusual to have a large number of samples from one population, a close approximation to this value is called the `r glossary("standard error")` of the mean (often referred to simply as the “standard error”). The standard error is computed by dividing the standard deviation of a variable by the square root of the sample size.

$$
se = \frac{s}{\sqrt{n}}
$$ {#eq-chap04-se}


:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-compute-se}
: Compute standard error of the mean
::::::
:::
::::{.my-r-code-container}

```{r}
#| label: compute-se
#| results: hold

## mean, sd, se for first sample of 500 counties
set.seed(seed = 1945)
dist_mat_clean2 |> 
    dplyr::slice_sample(n = 500, replace = TRUE) |> 
    dplyr::summarize(
    mean_distance = base::mean(distance),
    sd_distance = stats::sd(distance),
    se.dist = stats::sd(x = distance) /
        base::sqrt(x = base::length(x = distance)),
    n = dplyr::n()
    )

set.seed(seed = 48)
dist_mat_clean2 |> 
    dplyr::slice_sample(n = 500, replace = TRUE) |> 
    dplyr::summarize(
    mean_distance = base::mean(distance),
    se.dist = stats::sd(x = distance) /
        base::sqrt(x = base::length(x = distance)),
    sd_distance = stats::sd(distance),
    n = dplyr::n()
    )
```
***

Both of the standard error (se) values are close to the sampling distribution standard deviation of 1.05, but they are not exactly the same. The first sample standard error of 1.06 was a little above and the second sample standard error of .90 was a little below.

::::
:::::

::: {.callout-note}
**Summary**

- The standard deviation of the sampling distribution is 1.05. 
- The standard error from the first sample is 1.06. 
- The standard error from the second sample is 0.90.

Most of the time researchers have a single sample and so the only feasible way to determine the `r glossary("standard deviation")` of the `r glossary("sampling distribution")` is by computing the `r glossary("standard error")` of the single sample. This value tends to be a good estimate of the standard deviation of sample means.

**The sample standard error is a good estimate of the sampling distribution standard deviation!**
:::

:::::{.my-important}
:::{.my-important-header}
Difference between standard deviation and standard error
:::
::::{.my-important-container}

The `r glossary("standard deviation")` is a measure of the variability in the sample, while the `r glossary("standard error")` is an estimate of how closely the sample represents the population.
::::
:::::

## Achievement 6: Confidence intervals {#sec-chap04-achievement6}



## Experiments

### Get PDMP data



:::::{.my-experiment}
:::{.my-experiment-header}
:::::: {#def-chap04-get-pdmp-data}
: Get Prescription Drug Monitory Program (PMDP) data 
::::::
:::
::::{.my-experiment-container}

::: {.panel-tabset}

###### book

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-pdmp-book}
: Get the cleaned PDMP data from the book `.csv` file
::::::
:::
::::{.my-r-code-container}


```{r}
#| label: pdmp-book
#| lst-label: lst-chap04-pdmp-book
#| lst-cap: "Get the cleaned PDMP data from the book `.csv` file"
#| results: hold
#| eval: false

## run code only once manually ##########

## get pdmp data from books .csv
pdmp_2017_book <- readr::read_csv("data/chap04/pdmp_2017_kff_ch4.csv")
save_data_file("chap04", pdmp_2017_book, "pdmp_2017_book.rds")

```


***

(*For this R code chunk is no output available*)

::::
:::::


###### tabulizer

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-pdmp-tabulizer}
: Get PDMP data with {**tabulizer**}
::::::
:::
::::{.my-r-code-container}


```{r}
#| label: pdmp-tabulizer
#| lst-label: lst-chap04-pdmp-tabulizer
#| lst-cap: "Get PDMP data with {**tabulizer**}"
#| results: hold
#| eval: false

## run only once (manually) ##########

## get pdmp table via tabulizer
pdmp_2017_temp <- tabulizer::extract_tables(
    "data/chap04/PDMPs-2017.pdf")
pdmp_2017_tabulizer <- pdmp_2017_temp[[1]]

save_data_file("chap04", pdmp_2017_tabulizer, "pdmp_2017_tabulizer.rds")
```

***
(*For this R code chunk is no output available*)


::::
:::::

###### Clipboard

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-pdmp-clipboard}
: Get PDMP data via clipboard
::::::
:::
::::{.my-r-code-container}


```{r}
#| label: pdmp-clipboard
#| lst-label: lst-chap04-pdmp-clipboard
#| lst-cap: "Get PDMP data via clipboard"
#| results: hold
#| eval: false

## run code only once manually ###########

## readr::read_delim("clipboard") # Windows

pdmp_2017_clipboard1 <- readr::read_table(pipe("pbpaste")) # normal copy & paste
pdmp_2017_clipboard2 <- readr::read_table(pipe("pbpaste")) # TextSniper
save_data_file("chap04", pdmp_2017_clipboard1, "pdmp_2017_clipboard1.rds")
save_data_file("chap04", pdmp_2017_clipboard2, "pdmp_2017_clipboard2.rds")
```

***

(*For this R code chunk is no output available*)

With this approach I have selected the table data and copied it into the clipboard. Be aware that here are two different functions for Windows and macOS.

::::
:::::


###### rvest 

:::::{.my-r-code}
:::{.my-r-code-header}
:::::: {#cnj-chap04-pdmp-rvest}
: Get the PDMP data with {**rvest**}
::::::
:::
::::{.my-r-code-container}


```{r}
#| label: pdmp-rvest
#| lst-label: lst-chap04-pdmp-rvest
#| lst-cap: "Get the PDMP data with {**rvest**}"
#| results: hold
#| eval: false

## run code only once manually

## 1. check if web scrapping is allowed
url <- paste0("https://www.kff.org/report-section/",
  "implementing-coverage-and-payment-initiatives-benefits-and-pharmacy/")
robotstxt::paths_allowed((url))

## 2. get the whole KFF page
pdmp_2017_page <- rvest::read_html(url)
save_data_file("chap04", pdmp_2017_page, "pdmp_2017_page.rds")

## 3. extract PDMP table
pdmp_2017_rvest <- pdmp_2017_page |> 
    rvest::html_nodes("table") |> 
    purrr::pluck(10) |> 
    rvest::html_table()

save_data_file("chap04", pdmp_2017_rvest, "pdmp_2017_rvest.rds")

```


***

(*For this R code chunk is no output available*)

::::
:::::



:::

::::
:::::

In @def-chap04-get-pdmp-data I have data imported in four different ways: 

1. @lst-chap04-pdmp-book: This is the reference data frame, imported form the `.csv` file of the book.
2. @lst-chap04-pdmp-tabulizer: The package {**tabulizer**} worked fine, but the PDF table 19 (a) did not separate several columns with a vertical line and (b) did not put entries if there was no PDMP in place, but left the place entry. {**tabulizer**} could therefore not detect which entries belong to which column.
3. @lst-chap04-pdmp-clipboard: Even if the web page has dividing vertical lines for all columns, the same problem (namely empty) prevents a correct data transfer.
4. @lst-chap04-pdmp-rvest: This is the best option of my experiment: After confirming that web scraping is allowed, I scrapped all tables from the `r glossary("KFF")` web page, because there was no unique selector for table 19 available. I received 10 tables. That was strange because on the web page I could only visible detect seven tables. But luckily the last one was the table I was interested.

Conclusion: If I would not have the data to work with, I would take for further recoding the table the data imported by web scparing with {**rvest**}.




## Exercises (empty)

## Packages introduced in this chapter

### rvest

:::::{.my-resource}
:::{.my-resource-header}
rvest: Easily Harvest (Scrape) Web Pages 
:::
::::{.my-resource-container}

***

::: {#pak-rvest}

***

{**rvest**}: [Easily Harvest (Scrape) Web Pages](https://rvest.tidyverse.org/) [@rvest]

::: {layout="[10, 30]" layout-valign="center"}
![](img/chap04/logoi/logo-rvest-min.png){width="176"}


Wrappers around the {**xml2**} and {**httr**} packages to make it easy to download, then manipulate, `r glossary("HTML")` and `r glossary("XML")`. --- {**rvest**} helps you scrape (or harvest) data from web pages. It is designed to work with {**magrittr**} to make it easy to express common web scraping tasks, inspired by libraries like [beautiful soup](https://www.crummy.com/software/BeautifulSoup/) and [RoboBrowser](https://robobrowser.readthedocs.io/en/latest/readme.html).

:::

If you’re scraping multiple pages, hadley Wickham highly recommends using {**rvest**} in concert with [{**polite**}](https://dmi3kno.github.io/polite/). The {**polite**} package ensures that you’re respecting the [robots.txt](https://en.wikipedia.org/wiki/Robots_exclusion_standard) and not hammering the site with too many requests.

{**rvest**}: A Package for Easily Harvest (Scrape) Web Pages
:::

It is important to read the introductory vignette [Web scraping 101](https://rvest.tidyverse.org/articles/rvest.html). It introduces you to the basics of web scraping with {**rvest**}. You’ll first learn the basics of HTML and how to use `r glossary("CSS")` selectors to refer to specific elements, then you’ll learn how to use {**rvest**} functions to get data out of `r glossary("HTML")` and into R.

A very important tool to get the appropriate CSS selector is SelectorGadget. To learn how to install and to use this tool read the [SelectorGadget help page]https://rvest.tidyverse.org/articles/selectorgadget.html) of {**rvest**}.

***



::::
:::::

### sjstats

:::::{.my-resource}
:::{.my-resource-header}
sjstats: Collection of Convenient Functions for Common Statistical Computations 
:::
::::{.my-resource-container}

***

::: {#pak-sjstats}

***

{**sjstats**}: [Collection of Convenient Functions for Common Statistical Computations](https://strengejacke.github.io/sjstats/) [@sjstats]

::: {layout="[10, 30]" layout-valign="center"}
![](img/chap04/logoi/logo-sjstats-min.png){width="176"}

Collection of convenient functions for common statistical computations, which are not directly provided by R’s base or stats packages.

:::

This package aims at providing, *first*, shortcuts for statistical measures, which otherwise could only be calculated with additional effort (like Cramer’s V, Phi, or effict size statistics like Eta or Omega squared), or for which currently no functions available.

*Second*, another focus lies on weighted variants of common statistical measures and tests like weighted standard error, mean, t-test, correlation, and more.

The comprised tools include:

- Especially for mixed models: design effect, sample size calculation
- Weighted statistics and tests for: mean, median, standard error, standard deviation, correlation, Chi-squared test, t-test, Mann-Whitney-U-test


{**sjstats**}: A Collection of Convenient Functions for Common Statistical Computations
:::


***
::::
:::::



## Glossary

```{r}
#| label: glossary-table
#| echo: false

glossary_table()
```

------------------------------------------------------------------------


## Session Info {.unnumbered}

:::::{.my-r-code}
:::{.my-r-code-header}
Session Info
:::
::::{.my-r-code-container}

```{r}
#| label: session-info

sessioninfo::session_info()
```


::::
:::::
