{
  "hash": "ff183d48e47c5a7e8ac92f9e42c6f2d6",
  "result": {
    "engine": "knitr",
    "markdown": "# Binary Logistic regression {#sec-chap10}\n\n\n\n\n\n## Achievements to unlock\n\n::: {#obj-chap10}\n::: my-objectives\n::: my-objectives-header\nObjectives for chapter 10\n:::\n\n::: my-objectives-container\n**SwR Achievements**\n\n-   **Achievement 1**: Using exploratory data analysis before developing\n    a logistic regression models (@sec-chap10-achievement1)\n-   **Achievement 2**: Understanding the binary logistic regression\n    statistical model (@sec-chap10-achievement2)\n-   **Achievement 3**: Estimating a simple logistic regression model and\n    interpreting predictor significance and interpretation (@sec-chap10-achievement3)\n-   **Achievement 4**: Computing and interpreting two measures of model\n    fit (@sec-chap10-achievement4)\n-   **Achievement 5**: Estimating a larger logistic regression model\n    with categorical and continuous predictors (@sec-chap10-achievement5)\n-   **Achievement 6**: Interpreting the results of a larger logistic\n    regression model (@sec-chap10-achievement6)\n-   **Achievement 7**: Checking logistic regression assumptions and\n    using diagnostics to identify outliers and influential values (@sec-chap10-achievement7)\n-   **Achievement 8**: Using the model to predict probabilities for\n    observations that are outside the data set (@sec-chap10-achievement8)\n-   **Achievement 9**: Adding and interpreting interaction terms in\n    logistic regression (@sec-chap10-achievement9)\n-   **Achievement 10**: Using the likelihood ratio test to compare two\n    nested logistic regression models (@sec-chap10-achievement10)\n:::\n:::\n\nAchievements for chapter 10\n:::\n\n## The perplexing libraries problem\n\nHarris defines <a class='glossary' title='The term “digital divide” refers to the gap between individuals, households, businesses and geographic areas at different socio-economic levels with regard to their opportunities to access information and communication technologies (ICTs). (OECD Library)'>digital divide</a> broader and includes both limited access\nto information and communication technologies (ICT) and a deficit in the\nability to use information gained through access to\nICTs[^10-logistic-regression-1]. \n\n[^10-logistic-regression-1]: My current research indicates that mostly\n    only the first problem (limited access) falls under the definition\n    ([@wikipedia2024; @oecd2001].\n\nPeople were more likely to fall into this digital divide if they were poor, a racial minority, had limited education, had a disability, or lived in an area with low population density. The digital divide often exacerbated other problems like finding an employment either by not searching relevant offers using the internet or not getting the job because of missing ICT skills.\n\nThe question this chapter tries to answer: \"Which characteristics are associated with library use?\"\n\n\n\n\n## Resources & Chapter Outline\n\n### Data, codebook, and R packages {#sec-chap10-data-codebook-packages}\n\n::: my-resource\n::: my-resource-header\nData, codebook, and R packages for learning about descriptive statistics\n:::\n\n::: my-resource-container\n**Data**\n\nTwo options for accessing the data:\n\n1. Download the cleaned data set `pew_libraries_2016_cleaned_ch10.csv` from <https://edge.sagepub.com/harris1e>. \n2. Follow the instructions in Box 10.1 to import and clean `pew_libraries_2016_ch10.csv` from <https://edge.sagepub.com/harris1e> or download from the original Internet data source and clean.\n\nI am using the first option because there is nothing new for me to import and clean data files.\n\n**Codebook**\n\nTwo options:\n\n1. Download the `pew_libraries_2016_codebook_ch10.docx` codebook file from <https://edge.sagepub.com/harris1e>.\n2. Use the version that comes with the raw data file from Pew Research Center (https://www.pewinternet.org/dataset/march2016-libraries/)\n\n**Packages**\n\n1.  Packages used with the book (sorted alphabetically)\n\n-   {**car**}: @pak-car (John Fox)\n-   {**lmtest**}: @pak-lmtest (Achim Zeileis) \n-   {**odds.n.ends**}: @pak-odds.n.ends (Jenine Harris) \n-   {**tableone**}: @pak-tableone (Kazuki Yoshida) \n-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)\n\n2.  My additional packages (sorted alphabetically)\n\n-   {**skimr**}: @pak-skimr (Elin Waring)\n\n:::\n:::\n\n## Achievement 1: EDA {#sec-chap10-achievement1}\n\n### Get, show, and recode data\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-eda}\n: EDA: Get, show and recode data\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Get data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-get-data}\n: Import data from .csv file\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-get-data}\n\n::: {.cell}\n\n```{.r .cell-code}\n## run only once (manually)\ntbl10 <- readr::read_csv(\n    \"data/chap10/pew_libraries_2016_cleaned_ch10.csv\",\n    col_types = \"nffffffff\"\n)\n\nsave_data_file(\"chap10\", tbl10, \"tbl10.rds\")\n```\n:::\n\nGet data for chapter 10\n:::\n\n(*For this R code chunk is no output available*)\n\n***\n\nIn my first import trial it turned out that all the factor variables are imported as character variables. So I had to add the columns specifications `col_types = \"nffffffff\"`.\n\n::::\n:::::\n\n\n###### Show data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-show-data}\n: Show raw data for chapter 10\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-show-data}    \n\n::: {.cell}\n\n```{.r .cell-code}\ntbl10 <- base::readRDS(\"data/chap10/tbl10.rds\")\n\nskimr::skim(tbl10)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |      |\n|:------------------------|:-----|\n|Name                     |tbl10 |\n|Number of rows           |1601  |\n|Number of columns        |9     |\n|_______________________  |      |\n|Column type frequency:   |      |\n|factor                   |8     |\n|numeric                  |1     |\n|________________________ |      |\n|Group variables          |None  |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                    |\n|:-------------|---------:|-------------:|:-------|--------:|:-----------------------------|\n|sex           |         0|          1.00|FALSE   |        2|mal: 833, fem: 768            |\n|parent        |         5|          1.00|FALSE   |        2|not: 1205, par: 391           |\n|disabled      |         8|          1.00|FALSE   |        2|no: 1340, yes: 253            |\n|uses.lib      |         0|          1.00|FALSE   |        2|no: 809, yes: 792             |\n|ses           |         0|          1.00|FALSE   |        3|med: 1197, low: 246, hig: 158 |\n|raceth        |       140|          0.91|FALSE   |        3|Non: 1097, His: 194, Non: 170 |\n|educ          |         0|          1.00|FALSE   |        3|HS : 772, Fou: 658, < H: 171  |\n|rurality      |        14|          0.99|FALSE   |        3|rur: 879, sub: 355, urb: 353  |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|    sd| p0| p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|-----:|-----:|--:|---:|---:|---:|----:|:-----|\n|age           |        30|          0.98| 49.31| 18.85| 16|  33|  51|  64|   95|▆▅▇▆▁ |\n\n\n:::\n:::\n\n\nSkim raw data for chapter 10\n:::\n\n***\n\n\n\nI have used the {**skimr**} package instead of {**tableone**}. It wouldn't be necessary to plot a histogram for `age` to decide if the mean or median has to be used. The tiny histogram at the right side of the `age` line already shows that age is not normally distributed. But for the sake of practice I will create the histogram in the next tab.\n\n::::\n:::::\n\n###### age\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-age-hist}\n: Show age distribution\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-age-dist}\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_hist_dnorm(tbl10, tbl10$age)\n```\n\n::: {.cell-output-display}\n![](10-logistic-regression_files/figure-html/age-dist-1.png){width=672}\n:::\n:::\n\n\nThe distribution of age in the 2016 Pew Research Center library use data set\n:::\n\n::::\n:::::\n\n###### {tableone}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-desc-stats}\n: Table of descriptive statistics\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-desc-stats}\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_desc <- tableone::CreateTableOne(\n    data = tbl10,\n    strata = 'uses.lib',\n    vars = c(\"age\", \"sex\", \"parent\", \"disabled\",\n             \"ses\", \"raceth\", \"educ\", \"rurality\"))\n\nprint(tab_desc,\n      nonnormal = 'age',\n      showAllLevels = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                     Stratified by uses.lib\n#>                      level                    yes                 \n#>   n                                             792               \n#>   age (median [IQR])                          49.00 [31.00, 62.00]\n#>   sex (%)            female                     438 (55.3)        \n#>                      male                       354 (44.7)        \n#>   parent (%)         parent                     222 (28.2)        \n#>                      not parent                 566 (71.8)        \n#>   disabled (%)       no                         679 (86.3)        \n#>                      yes                        108 (13.7)        \n#>   ses (%)            medium                     585 (73.9)        \n#>                      high                        91 (11.5)        \n#>                      low                        116 (14.6)        \n#>   raceth (%)         Non-Hispanic White         540 (75.6)        \n#>                      Hispanic                    83 (11.6)        \n#>                      Non-Hispanic Black          91 (12.7)        \n#>   educ (%)           HS to 2-year degree        341 (43.1)        \n#>                      Four-year degree or more   382 (48.2)        \n#>                      < HS                        69 ( 8.7)        \n#>   rurality (%)       suburban                   196 (24.9)        \n#>                      rural                      401 (51.0)        \n#>                      urban                      189 (24.0)        \n#>                     Stratified by uses.lib\n#>                      no                   p      test   \n#>   n                    809                              \n#>   age (median [IQR]) 53.00 [35.00, 65.00]  0.001 nonnorm\n#>   sex (%)              330 (40.8)         <0.001        \n#>                        479 (59.2)                       \n#>   parent (%)           169 (20.9)          0.001        \n#>                        639 (79.1)                       \n#>   disabled (%)         661 (82.0)          0.024        \n#>                        145 (18.0)                       \n#>   ses (%)              612 (75.6)          0.088        \n#>                         67 ( 8.3)                       \n#>                        130 (16.1)                       \n#>   raceth (%)           557 (74.6)          0.110        \n#>                        111 (14.9)                       \n#>                         79 (10.6)                       \n#>   educ (%)             431 (53.3)         <0.001        \n#>                        276 (34.1)                       \n#>                        102 (12.6)                       \n#>   rurality (%)         159 (19.9)          0.002        \n#>                        478 (59.7)                       \n#>                        164 (20.5)\n```\n\n\n:::\n:::\n\n\nDescriptive statistics with bivariate tests using {**tableone**}\n:::\n***\n\n:::::{.my-remark}\n:::{.my-remark-header}\n:::::: {#rem-chap10-test-all-variables-together}\n: Printing bivariate tests for all variables --- a <a class='glossary' title='Questionable Research Practice (QRP) is a research practice that introduces bias, usually in pursuit of statistical significance; an example of such practices might be dropping or recoding values or variables solely to improve a model fit statistic. (SwR, GLossary)'>QRP</a>\n::::::\n:::\n::::{.my-remark-container}\nI am not feeling comfortable to use {**tableone**} to print descriptive statistics with bivariate test for all variables. Besides the mentioned danger of a <a class='glossary' title='Questionable Research Practice (QRP) is a research practice that introduces bias, usually in pursuit of statistical significance; an example of such practices might be dropping or recoding values or variables solely to improve a model fit statistic. (SwR, GLossary)'>questionable research practice</a> (QRP) in looking for statistically significance I would like to inspect the relationships more slowly and to see more details. I think at a minimum one should examine plots of the bivariate correlations. \n\nI have the same skepticism about the advice to \"examine the frequencies and percentages in the table to identify some possible categories that may be driving the significant results for the bivariate tests\". I think one should be guided to inspect more in detail in the first instance by theoretical assumptions, an approach that is fairly well demonstrated with Bayesian model design in \"Statistical Rethinking\" [@mcelreath2020]. \n\nTo facilitate <a class='glossary' title='Explorative Data Analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling and thereby contrasts traditional hypothesis testing. (Wikipedia)'>exploratory data analysis</a> one could use packages that combine the analysis of different variables in one go, as my experiments with `GGally::ggpairs()` in @lst-chap09-plot-ggpairs or with `ggfortify::autoplot()` in @lst-chap09-test-ggfortify have shown. But this approach gets too overwhelming when there are more than 5-6 variables as I will demonstrate in @lst-chap10-bivariate-data with {**GGally**).\n\n\n::::\n:::::\n\n\n\n\n\n::::\n:::::\n\n###### {GGally}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-bivariate-eda}\n: Bivariate exploratory data analysis for variables of chapter 10\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-bivariate-data}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl10 |> \n    GGally::ggpairs()\n```\n\n::: {.cell-output-display}\n![](10-logistic-regression_files/figure-html/plot-ggpairs-1.png){width=960}\n:::\n:::\n\n\nBivariate exploratory data analysis for variables of chapter 10\n:::\n\n*** \n\nThere are too many plots (variables) in this example. I could divide easily the amount of variables into different patches as demonstrated in [Columns and Mapping](https://ggobi.github.io/ggally/articles/ggpairs.html#columns-and-mapping) and inspect these results in more details. But in order to get all variations I have to plan the approach systematically which destroys the advantage of automatic plotting.\n\n::::\n:::::\n\n\n\n:::\n\n::::\n:::::\n\n## Achievement 2: Understanding binary logistic regression {#sec-chap10-achievement2}\n\nBinary logistic regression follows a similar format and process as linear regression (@sec-chap09), but the outcome or dependent variable is binary. Because the outcome is binary, or categorical consisting of two categories, the model predicts the probability that a person is in one of the two categories. In this chapter we want to predict the library use `uses.lib`.\n\nBecause of the binary outcome the linear regression model would not work since it requires a continuous outcome. However, the <a class='glossary' title='Linear regression is used to predict the value of an outcome variable Y based on one or more input predictor variables X. The aim is to establish a linear relationship (a mathematical formula) between the predictor variable(s) and the response variable, so that, we can use this formula to estimate the value of the response Y, when only the predictors (Xs) values are known. (r-statistics.co) (Chap.4)'>linear regression</a> statistical model can be transformed using the <a class='glossary' title='Logit transformations are transformations that takes the log value of p/(1-p); this transformation is often used to normalize percentage data and is used in the logistic model to transform the outcome. (SwR, Glossary)'>logit transformation</a> in order to be useful for modeling binary outcomes.\n\n### Formula of the logistic model\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap10-logistic-model}\n: Formula for the statistical form of the logistic model\n::::::\n:::\n::::{.my-theorem-container}\n$$\n\\begin{align*}\np(y) = \\frac{1}{1+e^{-(b_{0}+b_{1}x_{1}+b_{2}x_{2})}}\n\\end{align*}\n$$ {#eq-chap10-logistic-model}\n\n***\n\n- $y$: binary outcome variable (e.g., library use) \n- $p(y)$: probability of the outcome (e.g., probability of library use) \n- $b_{0}$: y-intercept \n- $x_{1}$ and $x_{2}$: predictors of the outcome (e.g., age, rurality) \n- $b_{1}$ and $b_{2}$: coefficients for $x_{1}$ and $x_{2}$\n\n::::\n:::::\n\n### Logistic function\n\nThe logistic function has a <a class='glossary' title='A sigmoid function is any mathematical function whose graph has a characteristic S-shaped curve or sigmoid curve. (Wikipedia)'>sigmoid</a> shape that stretches from $–∞$ to $∞$ on the x-axis and from $0$ to $1$ on the y-axis. The function can take any value along the x-axis and give the corresponding value between $0$ and $1$ on the y-axis.\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap10-logistic-function}\n: Formula of the logistic function\n::::::\n:::\n::::{.my-theorem-container}\n$$\n\\begin{align*}\n\\sigma(t) &= \\frac{e^t}{1+e^t} =\\\\\n&= \\frac{1}{1 + e^{-t}}\n\\end{align*}\n$$ {#eq-chap10-logistic-function}\n\n***\n\n$t$: value along the $x$-axis of the function\n$\\sigma$: value of $y$ for a specific value of $t$, or the probability of $y$ given $t$.\n\nIn the case of logistic regression, the value of $t$ will be the right-hand side of the regression model, which looks something like $β_{0} + β_{1}x$, where $x$ is an independent variable, $β_{1}$ is the coefficient (rather than slope) for that variable, and $β_{0}$ is the constant (rather than $y$-intercept).\n\nSubstituting this regression model for $t$ in the logistic function:\n\n$$\n\\begin{align*}\np(y) = \\frac{1}{1 + e^{-(β_{0} + β_{1}x)}}\n\\end{align*}\n$$ {#eq-chap10-logistic-function}\n\n::::\n:::::\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap10-logistic-function}\n: Drawing shape of logistic function empty and with example data points\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Shape\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-logistic-function-shape}\n: Shape of the logistic function\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-logistic-function-shape}\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot(data = data.frame(x = c(-5, 5)), \n         ggplot2::aes(x)) +\n    ggplot2::stat_function(fun = \n           function(x) base::exp(x)/(1 + base::exp(x)), n = 100,\n           linewidth = 1,\n           ggplot2::aes(color = \"Logistic function\")\n           ) +\n    ggplot2::scale_x_continuous(\n        labels = seq.int(10, 35, length.out = 5)\n        ) +\n    ggplot2::scale_color_manual(\n        name = \"\",\n        values = \"hotpink2\"\n    ) +\n    ggplot2::labs(\n        x = \"Values of input\",\n        y = \"Value of outcome\"\n    )\n```\n\n::: {.cell-output-display}\n![](10-logistic-regression_files/figure-html/logistic-function-shape-1.png){width=672}\n:::\n:::\n\nShape of the logistic function\n:::\n\n::::\n:::::\n\n\n\n###### Example with data points\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-logistic-function-data}\n: Example of logistic function with data points\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-logistic-function-data}    \n\n::: {.cell}\n\n```{.r .cell-code}\n## generate fake data frame\nx1 = c(10.2, 13.0, 14.1, 14.3, 14.5, 14.7, 15.0, 15.5, \n      16.1, 17.3, 19.0, 19.2, 19.8, 21.0, 26.5)\ny1 = rep(0, 15)\nx2 = c(17.8, 18.2, 19.0, 21.4, 21.5, 22.7, 24.0, 27.2, 31.0, 32.4, 33.8)\ny2 = rep(1, 11)\ntbl <-  tibble::tibble(x = c(x1, x2),\n                     y = c(y1, y2)) |> \n    dplyr::arrange(x)\n\n## draw logistic function with faked data points\nggplot2::ggplot( \n        data = tbl,\n        ggplot2::aes(x = x, y = y,\n                 color = \"Logistic function\")\n    ) +\n    ggplot2::stat_smooth(\n        data = tbl,\n        formula = y ~ x,\n        method = \"glm\",\n        se = FALSE,\n        method.args = list(family = binomial)\n    ) +\n    ggplot2::geom_point(\n        ggplot2::aes(alpha = \"Observation\"),\n        color = \"grey41\"\n    ) +\n    ggplot2::labs(\n        x = \"Values of input\",\n        y = \"Value of outcome\"\n    ) +\n    ggplot2::scale_color_manual(\n        name = \"\",\n        values = \"hotpink2\"\n    ) +\n    ggplot2::scale_alpha_manual(\n        name = \"\",\n        values = 0.5\n    )\n```\n\n::: {.cell-output-display}\n![](10-logistic-regression_files/figure-html/logistic-function-data-1.png){width=672}\n:::\n:::\n\n\nExample of logistic function with data points\n:::\n\n***\n\n::::\n:::::\n\n###### Probability of outcome\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap10-logistic-function-data-annotated}\n: Example of logistic function showing probability of outcome for x = 20\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap10-logistic-function-data-annotated}    \n\n::: {.cell}\n\n```{.r .cell-code}\n## generate fake data frame\nx1 = c(10.2, 13.0, 14.1, 14.3, 14.5, 14.7, 15.0, 15.5, \n      16.1, 17.3, 19.0, 19.2, 19.8, 21.0, 26.5)\ny1 = rep(0, 15)\nx2 = c(17.8, 18.2, 19.0, 21.4, 21.5, 22.7, 24.0, 27.2, 31.0, 32.4, 33.8)\ny2 = rep(1, 11)\ntbl <-  tibble::tibble(x = c(x1, x2),\n                     y = c(y1, y2)) |> \n    dplyr::arrange(x)\n\n## draw logistic function with faked data points\nggplot2::ggplot( \n    data = tbl,\n    ggplot2::aes(x = x, y = y,\n                 color = \"Logistic function\")\n    ) +\n    ggplot2::stat_smooth(\n        data = tbl,\n        formula = y ~ x,\n        method = \"glm\",\n        se = FALSE,\n        method.args = list(family = binomial),\n        ggplot2::aes(linetype = \"predictor = 20 and\\noutcome = .44 example\")\n    ) +\n    ggplot2::geom_point(\n        ggplot2::aes(alpha = \"Observation\"),\n        color = \"grey41\"\n        ) +\n    ggplot2::geom_segment(\n        x = 20, xend = 20,\n        y = 0, yend = .44,\n        color = \"#1f6fca\",\n        linetype = \"dashed\"\n    ) +\n    ggplot2::geom_segment(\n        x = 10, xend = 20,\n        y = .44, yend = .44,\n        color = \"#1f6fca\",\n        linetype = \"dashed\"\n    ) +\n    ggplot2::labs(\n        x = \"Values of input\",\n        y = \"Value of outcome\"\n    ) +\n    ggplot2::scale_color_manual(\n        name = \"\",\n        values = \"hotpink2\"\n    ) +\n    ggplot2::scale_alpha_manual(\n        name = \"\",\n        values = 0.5\n    ) +\n    ggplot2::scale_linetype_manual(\n        name = \"\",\n        values = c(\"dashed\", \"dashed\")\n    ) +\n    ggplot2::annotate(\"text\", x = 10, y = .48, label = \"0.44\", color = \"#1f6fca\" ) +\n    ggplot2::annotate(\"text\", x = 20.5, y = -.02, label = \"20\", color = \"#1f6fca\" )\n```\n\n::: {.cell-output-display}\n![](10-logistic-regression_files/figure-html/logistic-function-data-annotated-1.png){width=672}\n:::\n:::\n\n\nExample of logistic function showing a probability of outcome for $x = 20$\n:::\n\n***\n\nLet's assume that the above graphic is a model for predicting library use from age. Then we can interpret it as a 44% probability of library use for a 20-year-old. Since 44% is lower than a 50% probability of the value of $y$, the model is predicting that the 20-year-old does not have the outcome. So, if the outcome is library use, the logistic model would predict this 20-year-old was not a library user. \n\n\n::::\n:::::\n\n:::\n\n\n\n\n\n::::\n:::::\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap10-odds}\n: Formula of odds related to probability\n::::::\n:::\n::::{.my-theorem-container}\n$$\n\\begin{align*}\nodds = \\frac{probability}{1-probability}\n\\end{align*}\n$$ {#eq-chap10-odds}\n\nSubstituting the logistic model from @eq-chap10-logistic-model:\n\n$$\n\\begin{align*}\nodds &= \\frac{\\frac{1}{1+e^{-(\\beta_{0}+\\beta_{1}x)}}}{1- \\frac{1}{1+e^{-(\\beta_{0}+\\beta_{1}x)}}} = \ne^{\\beta_{0} + \\beta_{1}x}\n\\end{align*}\n$$ {#eq-chap10-odds-logistic-model}\n\nTo be equivalent to the interpretation of the coefficients in linear regression, however, there is one more step. That is, what is the increase or decrease in the odds of the outcome with a one-unit increase in $x$?\n\n\n$$\n\\begin{align*}\nOR = \\frac{e^{b_0+b_{1}(x+1)}}{e^{b_0+b_{1}x}}\n\\end{align*}\n$$ {#eq-chap10-odds-ratio}\n\n::::\n:::::\n\n@eq-chap10-odds-ratio shows that for every one-unit increase in the independent variable $x$, the odds of the outcome increase or decrease by $e^{b_1}$. Taking $e$ to the power of $b_1$ is referred to as exponentiating $b_1.$ After a model is estimated, the analyst will usually exponentiate the b value(s) in order to report odds ratios describing the relationships between each predictor and the outcome.\n\n## Achievement 3: Interpreting a simple logistic regression {#sec-chap10-achievement3}\n\n\n## Exercises (empty)\n\n## Glossary\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Digital Divide </td>\n   <td style=\"text-align:left;\"> The term \"digital divide\" refers to the gap between individuals, households, businesses and geographic areas at different socio-economic levels with regard to their opportunities to access information and communication technologies (ICTs). (&lt;a href= \"https://www.oecd-ilibrary.org/science-and-technology/understanding-the-digital-divide_236405667766\"&gt;OECD Library&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ExDA </td>\n   <td style=\"text-align:left;\"> Explorative Data Analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling and thereby contrasts traditional hypothesis testing. (&lt;a href=\"https://en.wikipedia.org/wiki/Exploratory_data_analysis\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Linear Regression </td>\n   <td style=\"text-align:left;\"> Linear regression is used to predict the value of an outcome variable Y based on one or more input predictor variables X. The aim is to establish a linear relationship (a mathematical formula) between the predictor variable(s) and the response variable, so that, we can use this formula to estimate the value of the response Y, when only the predictors (Xs) values are known. ([r-statistics.co](https://r-statistics.co/Linear-Regression. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Logit Transformations </td>\n   <td style=\"text-align:left;\"> Logit transformations are transformations that takes the log value of p/(1-p); this transformation is often used to normalize percentage data and is used in the logistic model to transform the outcome. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> QRP </td>\n   <td style=\"text-align:left;\"> Questionable Research Practice (QRP) is a research practice that introduces bias, usually in pursuit of statistical significance; an example of such practices might be dropping or recoding values or variables solely to improve a model fit statistic. (SwR, GLossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sigmoid </td>\n   <td style=\"text-align:left;\"> A sigmoid function is any mathematical function whose graph has a characteristic S-shaped curve or sigmoid curve. (&lt;a href=\"https://en.wikipedia.org/wiki/Sigmoid_function\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Session Info {.unnumbered}\n\n::: my-r-code\n::: my-r-code-header\nSession Info\n:::\n\n::: my-r-code-container\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.3.3 (2024-02-29)\n#>  os       macOS Sonoma 14.4.1\n#>  system   x86_64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Europe/Vienna\n#>  date     2024-04-25\n#>  pandoc   3.1.13 @ /usr/local/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  package     * version    date (UTC) lib source\n#>  base64enc     0.1-3      2015-07-28 [1] CRAN (R 4.3.0)\n#>  cli           3.6.2      2023-12-11 [1] CRAN (R 4.3.0)\n#>  colorspace    2.1-1      2024-01-03 [1] R-Forge (R 4.3.2)\n#>  commonmark    1.9.1      2024-01-30 [1] CRAN (R 4.3.2)\n#>  curl          5.2.1      2024-03-01 [1] CRAN (R 4.3.2)\n#>  digest        0.6.35     2024-03-11 [1] CRAN (R 4.3.2)\n#>  dplyr         1.1.4      2023-11-17 [1] CRAN (R 4.3.0)\n#>  evaluate      0.23       2023-11-01 [1] CRAN (R 4.3.0)\n#>  fansi         1.0.6      2023-12-08 [1] CRAN (R 4.3.0)\n#>  farver        2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n#>  fastmap       1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n#>  generics      0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n#>  ggplot2       3.5.0      2024-02-23 [1] CRAN (R 4.3.2)\n#>  glossary    * 1.0.0.9000 2023-08-12 [1] Github (debruine/glossary@819e329)\n#>  glue          1.7.0      2024-01-09 [1] CRAN (R 4.3.0)\n#>  gtable        0.3.4      2023-08-21 [1] CRAN (R 4.3.0)\n#>  highr         0.10       2022-12-22 [1] CRAN (R 4.3.0)\n#>  htmltools     0.5.8.1    2024-04-04 [1] CRAN (R 4.3.2)\n#>  htmlwidgets   1.6.4      2023-12-06 [1] CRAN (R 4.3.0)\n#>  jsonlite      1.8.8      2023-12-04 [1] CRAN (R 4.3.0)\n#>  kableExtra    1.4.0      2024-01-24 [1] CRAN (R 4.3.2)\n#>  knitr         1.46       2024-04-06 [1] CRAN (R 4.3.3)\n#>  labeling      0.4.3      2023-08-29 [1] CRAN (R 4.3.0)\n#>  lattice       0.22-6     2024-03-20 [2] CRAN (R 4.3.2)\n#>  lifecycle     1.0.4      2023-11-07 [1] CRAN (R 4.3.0)\n#>  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n#>  markdown      1.12       2023-12-06 [1] CRAN (R 4.3.0)\n#>  Matrix        1.6-5      2024-01-11 [1] CRAN (R 4.3.0)\n#>  mgcv          1.9-1      2023-12-21 [1] CRAN (R 4.3.0)\n#>  munsell       0.5.1      2024-04-01 [1] CRAN (R 4.3.2)\n#>  nlme          3.1-164    2023-11-27 [1] CRAN (R 4.3.2)\n#>  pillar        1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n#>  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n#>  purrr         1.0.2      2023-08-10 [1] CRAN (R 4.3.0)\n#>  R6            2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n#>  repr          1.1.7      2024-03-22 [1] CRAN (R 4.3.3)\n#>  rlang         1.1.3      2024-01-10 [1] CRAN (R 4.3.0)\n#>  rmarkdown     2.26       2024-03-05 [1] CRAN (R 4.3.2)\n#>  rstudioapi    0.16.0     2024-03-24 [1] CRAN (R 4.3.2)\n#>  rversions     2.1.2      2022-08-31 [1] CRAN (R 4.3.0)\n#>  scales        1.3.0      2023-11-28 [1] CRAN (R 4.3.2)\n#>  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n#>  skimr         2.1.5      2022-12-23 [1] CRAN (R 4.3.0)\n#>  stringi       1.8.3      2023-12-11 [1] CRAN (R 4.3.0)\n#>  stringr       1.5.1      2023-11-14 [1] CRAN (R 4.3.0)\n#>  svglite       2.1.3      2023-12-08 [1] CRAN (R 4.3.0)\n#>  systemfonts   1.0.6      2024-03-07 [1] CRAN (R 4.3.2)\n#>  tibble        3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n#>  tidyr         1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n#>  tidyselect    1.2.1      2024-03-11 [1] CRAN (R 4.3.2)\n#>  utf8          1.2.4      2023-10-22 [1] CRAN (R 4.3.0)\n#>  vctrs         0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n#>  viridisLite   0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n#>  withr         3.0.0      2024-01-16 [1] CRAN (R 4.3.0)\n#>  xfun          0.43       2024-03-25 [1] CRAN (R 4.3.2)\n#>  xml2          1.3.6      2023-12-04 [1] CRAN (R 4.3.0)\n#>  yaml          2.3.8      2023-12-11 [1] CRAN (R 4.3.0)\n#> \n#>  [1] /Library/Frameworks/R.framework/Versions/4.3-x86_64/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}