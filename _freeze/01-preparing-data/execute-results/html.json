{
  "hash": "4ff9505d4fd569785933dcc9a1210f87",
  "result": {
    "engine": "knitr",
    "markdown": "# Preparing Data\n\n\n\n\n\n\n\n::: my-objectives\n::: my-objectives-header\nAchievements:\n:::\n\n::: my-objectives-container\n**SwR Achievements**\n\n-   (~~Observations and variables~~)\n-   Using reproducible research practices (@sec-chap01-reproducibility)\n-   (~~Understanding and changing data types~~)\n-   Entering or loading data into R (@sec-chap01-import-data)\n-   Identifying and treating missing values\n-   Building a basic bar chart\n\nI will skip the crossed out learning objectives in parenthesis as I know\nalready these procedures. However I will elaborate some of these\nachievements. Especially the section about the import of a GSS dataset\nis enriched by different downloading strategies. Additionally I will add\nanother personal objectives for this chapter.\n\n**My Additional Objective**\n\n-   Replicating book Figure 1.2\n:::\n:::\n\n## Using reproducible research practices {#sec-chap01-reproducibility}\n\n### Script files\n\nSWR explains writing script files, but I am using\n<a class='glossary' title='Literate programming is a methodology that combines a programming language with a documentation language, thereby making programs more robust, more portable, more easily maintained, and arguably more fun to write than programs that are written only in a high-level language. The main idea is to treat a program as a piece of literature, addressed to human beings rather than to a computer.(Donald Knuth)'>Literate Programming</a> with Quarto. This has the\nconsequence that in addition to short comments inside code cells I have\nthe possibility to write extensively in the other parts of the file\nabout approach, code, results etc.\n\nA practical advice for scripts is to include a <a class='glossary' title='A set of comments at the top of a code file that provides information about what is in the file (Harries, SWR)'>prolog</a>.\nPossible prolog sections:\n\n-   Project name\n-   Project purpose\n-   Name(s) of data set(s) used in the project\n-   Location(s) of data set(s) used in the project\n-   Code author name (you!)\n-   Date code created\n-   Date last time code was edited\n\nMost of these information are naturally occurring in the writing process\nof Quarto books.\n\n::: my-resource\n::: my-resource-header\nLiterate Statistical Programming\n:::\n\n::: my-resource-container\n-   Literate Programming:\n    ([Wikipedia](https://en.wikipedia.org/wiki/Literate_programming))\n-   Introduction to Literate Programming with Quarto ([Online\n    Slides](https://gesiscss.github.io/quarto-workshop/material/slides/01_introduction.html#/title-slide))\n-   Reproducibility and literate programming in R ([bookdown\n    course](https://exeter-data-analytics.github.io/LitProg/index.html))\n-   Introduction to Data Science in R for Biologists (Module on\n    [Literate Statistical Programming and\n    Quarto](https://mbutler808.github.io/rclass/posts/2023-01-26-intro-quarto/index.html))\n-   Let’s build a blog with Quarto [Literate programming in\n    Quarto](https://ivelasq.quarto.pub/building-a-blog-with-quarto/workflow/write-docs/))\n    by Isabella Velásquez. The site has other material (for Quarto\n    blogs) as well: [Migrate from R\n    Markdown](https://ivelasq.quarto.pub/building-a-blog-with-quarto/learn-more/migrate-blog/),\n    [Additional\n    resources](https://ivelasq.quarto.pub/building-a-blog-with-quarto/learn-more/resources/)\n-   Introduction to literate programming with Quarto and Markdown by\n    Gesis\n    ([Slides](https://gesiscss.github.io/quarto-workshop/material/slides/01_introduction.html#/title-slide))\n:::\n:::\n\n### Naming objects\n\nI am used to apply the [tidyverse style\nguide](https://style.tidyverse.org/). It requires to use underlines\n(\"snake_code\") as separators in object names. (In contrast to\n\"camelCase\" code style). But reading the book I thought it might be a\ngood idea to use special additional styles for certain specific objects.\n\n-   **Naming constants**: Prefix name of constants with `k_`.\n-   **Naming variables**: Standard snake code.\n-   **Naming functions**: Prefix name of private functions with a dot\n    `.`. I had already experienced that didn't know from which package a\n    function was. Only to learn after looking around for minutes that it\n    was a function I wrote myself!\n-   **Naming data frames**: Prefix name with `df_` for data.frame and\n    `dt_` for tibble. I might also use a suffix to refer to the status\n    e.g., `_raw` (raw data), `_clean` (cleaned data), `_v2` (version\n    number).\n-   **Naming files**: It could be helpful to add at the start the\n    chapter number e.g. `chap02_`. And maybe also --- as in naming data\n    frames --- the status as suffix.\n\n## Import data frames from outside resources {#sec-chap01-import-data}\n\nR has many possibilities to import data from other statistical packages.\n\n### Some common file extensions\n\n-   **.csv**: comma separated values\n-   **.txt**: text file\n-   **.xls or .xlsx**: Excel file\n-   **.sav**: SPSS file\n-   **.sasb7dat**: SAS file\n-   **.xpt**: SAS transfer file\n-   **.dta**: Stata file\n\n### Some packages for import data sources\n\n-   {**readr**}: Read Rectangular Text Data, part of {**tidyverse**}\n-   {**vroom**}: Read and Write Rectangular Text Data Quickly\n-   {**haven**}: Import and Export 'SPSS', 'Stata' and 'SAS' Files\n-   {**foreign**}: Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS',\n    'Stata', 'Systat', 'Weka', 'dBase', ...\n-   {**readxl**}: Read Excel Files\n-   {**openxslx**}: Read, Write and Edit xslx Files\n-   {**readODS**}: Read and Write ODS Files (e.g. LibreOffice)\n-   {**clipr**}: Read and Write from the System Clipboard\n\nI will not go into the import details of all the different packages\nhere, because my focus is on the GSS data.\n\n### Importing data from General Social Survey (GSS)\n\n> “While the GSS data can be read into R directly from the GSS website,\n> Kiara had experienced this and knew that it could be frustrating.”\n> ([Harris, 2020](zotero://select/groups/5254842/items/9N29QMJB))\n> ([pdf](zotero://open-pdf/groups/5254842/items/3NDRGBBW?page=107&annotation=SFD9FHQD))\n\nI am very interested how to get <a class='glossary' title='A large survey of a sample of people in the United States conducted regularly since 1972; the General Social Survey is abbreviated GSS and is conducted by the National Opinion Research Center at the University of Chicago. (Harris, Glossary)'>GSS</a> data directly from\nthe GSS website, so that I could work on interesting research questions\nmyself. \n\nI have found several resources helping to work with the\n<a class='glossary' title='A large survey of a sample of people in the United States conducted regularly since 1972; the General Social Survey is abbreviated GSS and is conducted by the National Opinion Research Center at the University of Chicago. (Harris, Glossary)'>GSS</a>.\n\n::: my-resource\n::: my-resource-header\nWorking with the GSS\n:::\n\n::: my-resource-container\n## gssr {.unnumbered}\n\n[GSSR Package](https://kjhealy.github.io/gssr/): The General Social\nSurvey Cumulative Data (1972-2022) and Panel Data files packaged for\neasy use in R. {**gssr**} is a data package, developed and maintained by\n[Kieran Healy](https://kieranhealy.org/), the author of [Data\nVisualization](https://kieranhealy.org/publications/dataviz/). The\npackage bundles several datasets into a convenient format. Because of\nits large size {**gssr**} is not hosted on CRAN but as a [GitHub\nrepository](https://github.com/kjhealy/gssr/).\n\nInstead of browsing and examining the complex dataset with the [GSS Data\nExplorer](https://gssdataexplorer.norc.org/) or [download datasets\ndirectly](https://gss.norc.org/Get-The-Data) from the The National\nOpinion Research Center ([NORC](http://norc.org/)) you can now just work\ninside R. The current package 0.4 (see: [gssr\nUpdate](https://kieranhealy.org/blog/archives/2023/12/02/gssr-update/))\nprovides the GSS Cumulative Data File (1972-2022), three GSS Three Wave\nPanel Data Files (for panels beginning in 2006, 2008, and 2010,\nrespectively), and the 2020 panel file.\n\nVersion 0.40 also integrates survey code book information about\nvariables directly into R’s help system, allowing them to be accessed\nvia the help browser or from the console with ?, as if they were\nfunctions or other documented objects.\n\n## asdfree {.unnumbered}\n\n[Analyze Survey Data for Free](http://asdfree.com/) is a bookdown\nwebsite by [Anthony\nDamico](https://www.youtube.com/@anthonyjosephdamico/playlists) with\ncurrently 64 locations to grab free survey data. As expected it features\nalso a [description of the\nGSS](http://asdfree.com/general-social-survey-gss.html) including\nanalysis examples with the {**survey**} package and --- especially\nimportant for my purpose here --- {**lodown**}, a [package on GitHub]()\nto facilitate data imports from many sites with survey data. (For\ndetails see the section\n[Prerequisites](http://asdfree.com/prerequisites.html))\n:::\n:::\n\n\n@exm-chap01-get-gss-data features six different strategies to\ndownload GSS data:\n\n0.  Download Excel file provided by the book’s companion website --- Tab: \"Book\"\n1.  Download extract by using the GSS Data Explorer --- Tab: \"Explorer\"\n2.  Download files manually --- Tab: \"by hand\"\n3.  Download files programmatically --- Tab: \"automated\"\n4.  Download via the {**lodown**} package --- Tab: \"lodown\"\n5.  Download via the {**gssr**} package --- Tab: \"gssr\"\n\n\n\n\n\n***\n\n::: my-example\n::: my-example-header\n::: {#exm-chap01-get-gss-data}\n: Get the General Social Survey (GSS) data\n:::\n:::\n::: my-example-container\n::: panel-tabset\n\n###### Book\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-import-csv-data}\n: Import the .csv file provided by book, summarize and glance at the data. \n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap01-import-csv-file}\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2016_book <- readr::read_csv(\n    file = \"data-harris/legal_weed_age_GSS2016_ch1.csv\",\n    show_col_types = FALSE)\n\nsummary(gss_2016_book)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>     grass               age           \n#>  Length:2867        Length:2867       \n#>  Class :character   Class :character  \n#>  Mode  :character   Mode  :character\n```\n\n\n:::\n\n```{.r .cell-code}\ngss_2016_book |>\n    dplyr::select(c(age, grass)) |> \n    glance_data(N = 8, seed = 2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10 × 3\n#>      obs age   grass    \n#>    <int> <chr> <chr>    \n#>  1     1 47    IAP      \n#>  2   172 27    LEGAL    \n#>  3   562 70    NOT LEGAL\n#>  4   898 60    NOT LEGAL\n#>  5  1019 30    LEGAL    \n#>  6  1176 80    NOT LEGAL\n#>  7  1505 53    IAP      \n#>  8  1911 54    NOT LEGAL\n#>  9  2622 62    IAP      \n#> 10  2867 72    NOT LEGAL\n```\n\n\n:::\n:::\n\n\nImport the .csv file provided by book and glance at the data. \n:::\n\n***\n**Some comments**\n\n1. In contrast to `base::read.csv()` in the book I used with `readr::read_csv()` a function from the {**tidyverse**} package collection.\n2. I added the `show_col_types = FALSE` argument to prevent a message about the column specification.\n3. In addition to the base::summary() command I developed a private function `glance_data()` to provide a first impression about the data.\n\n\n::::\n:::::\n\n\nIn @lst-chap01-import-csv-file I have used the function `glance_data()` that I wrote myself. It prints first and last row of the dataset and adds between randomly at the maximum 8 other rows. Additionally it provides the row number of the data (`obs`stands for \"observation\"). The idea of this function is to get a first impression of the dataset. Other printing methods show just the first (or last) rows. This could be misleading, giving a wrong impression about the typical data.\n\n::: {#lst-chap01-show-function-glance-data}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nglance_data <- function(df, N, seed){\n    df_temp <- first_and_last_row(df)\n    \n    set.seed(seed)\n    df |> \n    dplyr::mutate(obs = dplyr::row_number()) |> \n    dplyr::relocate(obs) |> \n    dplyr::slice_sample(n = N) |> \n    dplyr::bind_rows(df_temp) |> \n    dplyr::arrange(obs)\n} \n\nfirst_and_last_row <-  function(df) {\n    df |> \n    dplyr::mutate(obs = dplyr::row_number()) |>\n    dplyr::filter(dplyr::row_number() %in% base::c(1, dplyr::n()))\n}\n```\n:::\n\n\nMy private function `glance_date()`\n\n:::\n\n\n\n\n\n###### Explore\n\nTo use all the facilities of the GSS Data Explorer (tagging, tabulating,\ndata extracting) you need to register for a free account. The good thing\nis: This is a onetime procedure.\n\n\n::: my-procedure\n::: my-procedure-header\n::: {#prp-chap01-get-gss-data-explorer}\n: Downloading data extracts with the GSS Data Explorer\n:::\n:::\n\n::: my-procedure-container\n1.  Create a free account for the [GSS Data\n    Explorer](https://gssdataexplorer.norc.org/), a tool that allows to\n    browse the data that have been collected in the surveys.\n    -   Fill out the form\n    -   Wait for an email with the verification code\n    -   Confirm the registration with the verification code\n2.  Go for the tour to learn the interface (Link \"Tour Guide\")\n3.  Now you are ready to follow the advises in the slides. If you prefer you can view the slide show in a [standalone browser](https://petzi53.quarto.pub/gss-data-explorer/#/title-slide).\n\n:::\n:::\n\n\n<iframe \n width=\"650\"\n height= \"400\"\nclass=\"slide-deck\" src=\"https://petzi53.quarto.pub/gss-data-explorer/#/title-slide\"></iframe>\n\n\nAs one can see this is a somewhat cumbersome procedure to download the\ndesired data. Following the proposed strategies in the other tabs are much easier for importing GSS data. But using the GSS Data Explorer is very helpful to *explore* the\ndataset. Apply the first three steps of the above list to find the\ncorrect variable names, to read the exact wording of the question asked\nand to inspect the different codes that are used for the variable.\nOtherwise you have to skim the more than 700 pages of the GSS\ncodebook.😭\n\n###### by hand\n\nAnother approach is to download the complete dataset (or all variables\nof those years you are interested in) and manage the data in such a way that it can be easily used for your research question. (See @sec-chap01-data-wrangling)\n\n::: my-procedure\n::: my-procedure-header\n::: {#prp-chap01-get-gss-data-manually}\n: Download GSS individual year data sets (cross-section only)\n\n:::\n:::\n\n::: my-procedure-container\n1.  Visit <https://gss.norc.org/Get-The-Data> and choose under the\n    section \"Download the Data\" the \"STATA\" format. I read elsewhere\n    that this is the preferred format to convert the data into R with\n    the {**haven**} package.\n2.  From the [STATA-page](https://gss.norc.org/get-the-data/stata) \n    choose the appropriate link (`2016` in our case) under the section \"Individual Year Data Sets (cross-section only)\" and download the file `2016_stata.zip` (994 MB) into your preferred folder on your hard disk. After you extract the .zip file you will get the STAT file `GSS2016.dta` (4.4 MB).\n3.  You can now apply @cnj-chap01-import-stata-data. \n:::\n:::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-import-stata-data}\n: Import STATA GSS 2016 file into R using (**haven**)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n\n::: {#lst-chap01-import-stata-2016-file}\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2016_man <- haven::read_dta(\"data-raw/GSS2016.dta\")\nsaveRDS(gss_2016_man, file = \"data-raw/gss_2016_man.rds\" )\n\ngss_2016_man |>\n    dplyr::select(c(age, grass)) |> \n    glance_data(N = 8, seed = 2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10 × 3\n#>      obs age       grass                      \n#>    <int> <dbl+lbl> <dbl+lbl>                  \n#>  1     1 47        NA(i) [iap]                \n#>  2   172 27            1 [should be legal]    \n#>  3   562 70            2 [should not be legal]\n#>  4   898 60            2 [should not be legal]\n#>  5  1019 30            1 [should be legal]    \n#>  6  1176 80            2 [should not be legal]\n#>  7  1505 53        NA(i) [iap]                \n#>  8  1911 54            2 [should not be legal]\n#>  9  2622 62        NA(i) [iap]                \n#> 10  2867 72            2 [should not be legal]\n```\n\n\n:::\n:::\n\n\n\nImport STATA GSS 2016 file into R using (**haven**) and glance at the data\n\n:::\n\n:::::{.my-important}\n:::{.my-important-header}\n{**haven**} imports data as labelled vectors\n:::\n::::{.my-important-container}\nThe data structure we have found here is very different from the Excel data file provided with the book.\n::::\n:::::\n\n\nLabelled vectors is a completely new feature for me. I learned that value labels and other metadata tags that are commonly seen when working with other statistical software like SAS, STATA or SPSS (cf. [Survey Research and Datasets in R](https://socialresearchcentre.github.io/r_survey_datasets/), here section 3 [Labelled Data](https://socialresearchcentre.github.io/r_survey_datasets/labelled-data.html))\n\n> A labelled vector is a common data structure in other statistical environments, allowing you to assign text labels to specific values. This class makes it possible to import such labelled vectors in to R without loss of fidelity. ([Create a labelled vector](https://haven.tidyverse.org/reference/labelled.html))\n\nI will go into more details in @sec-chap01-data-wrangling. The important thing here is to notice that the variable `grass` has labelled values that explain the short code. Code `1` represents the respondent option that marijuana should be legalized and `2`\nthe opposite. We also learn that there is with `NA i` a special kind of `NA` value: \n\n> .i: Inapplicable (IAP). Respondents who are not asked to answer a specific question are assigned to IAP. (See [Alert on the STATA download page](https://gss.norc.org/get-the-data/stata))\n\nOn the website we see under the \"Alert\" section that there other kind of NA’s as well. And the 2022 GSS Codebook describes still other, less common missing values.\n\n\n::::\n:::::\n\n\n\n**Additional comments**\n\nI chose for file saving the `base::saveRDS()` option (and not `base::save()`)\n    because when later reading into R again with `base::readRDS()` it\n    does not overwrite a variable with the same name respectively I can\n    assign the file to another variable name. \n    \n\n###### automated\n\n::: my-r-code\n::: my-r-code-header\n::: {#cnj-chap01-get-gss2016-data}\n: Get year 2016 of GSS data set with `base::download.file()`\n:::\n:::\n\n::: my-r-code-container\n\n::: {#lst-chap01-get-gss2016-automated}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\n## run only once (manually)\ntemp <- base::tempfile()\nutils::download.file(\"https://gss.norc.org/documents/stata/2016_stata.zip\",temp)\ngss_2016_aut <- haven::read_dta(base::unz(temp, \"GSS2016.dta\"))\nbase::unlink(temp)\nbase::saveRDS(gss_2016_aut, file = \"data-raw/gss_2016_aut.rds\" )\n```\n:::\n\n\nGet year 2016 of GSS data set with `base::download.file()`\n\n:::\n\nThis time we have the file downloaded programmatically which is much better in term of reproducibility. We don't need now to import the data {**haven**} but can call base::readRDS().\n\n\n::: {#lst-chap01-read-rds-data}\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2016_aut <- base::readRDS(\"data-raw/gss_2016_aut.rds\")\n\ngss_2016_aut |> \n    dplyr::select(c(age, grass)) |> \n    glance_data(N = 8, seed = 2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10 × 3\n#>      obs        age      grass\n#>    <int> <hvn_lbll> <hvn_lbll>\n#>  1     1         47         NA\n#>  2   172         27          1\n#>  3   562         70          2\n#>  4   898         60          2\n#>  5  1019         30          1\n#>  6  1176         80          2\n#>  7  1505         53         NA\n#>  8  1911         54          2\n#>  9  2622         62         NA\n#> 10  2867         72          2\n```\n\n\n:::\n:::\n\n\nRead previously saved `.rds` file into R and glance at the data\n:::\n\n\n\n:::\n:::\n\nData now have a more R like appearance, even if the variable classes with <hvn_lbll> \"*haven_labelled, vctrs_vctr, double*\" are unfamiliar. But we have now lost some information, especially we have to consult the codebook to know what the codes `1` and `2` mean.\n\n\n###### lodown\n\nThe following strategy I have taken from the bookdown book [Analyze Survey Data for Free](http://asdfree.com/) (asdf.com) It gives step by step instructions to explore public <a class='glossary' title='Microdata are unit-level data obtained from sample surveys, censuses, and administrative systems. They provide information about characteristics of individual people or entities such as households, business enterprises, facilities, farms or even geographical areas such as villages or towns. They allow in-depth understanding of socio-economic issues by studying relationships and interactions among phenomena. Microdata are thus key to designing projects and formulating policies, targeting interventions and monitoring and measuring the impact and results of projects, interventions and policies. (The World Bank)'>Microdata</a>. Here I refer to the <a class='glossary' title='A large survey of a sample of people in the United States conducted regularly since 1972; the General Social Survey is abbreviated GSS and is conducted by the National Opinion Research Center at the University of Chicago. (Harris, Glossary)'>General Social Survey</a> (GSS) section of the book.\n\n:::::{.my-procedure}\n:::{.my-procedure-header}\n:::::: {#prp-chap01-get-gss2016-lodown}\n: Get the GSS data with the {**lodown**} package and glance at the data\n::::::\n:::\n::::{.my-procedure-container}\n\nWorking with {**lodown**} is a three step procedure:\n\n1. Retrieve a listing of all available extracts for the GSS data.\n2. Choose what files you want to download. In our case data for the year 2016.\n3. Download the specified dataset in the offered SPSS file format, but {**lodown**} produces with `.rds` a native R file format with the name `2016.rds`.\n\n::::\n:::::\n\nThe second step has to be done manually but I have the result of my inspection already integrated in @lst-chap01-get-gss2016-lodown.\n\nAs additional steps I renamed the downloaded file, so that I can it distinguish from similar files of the other approaches. Finally I glanced at the `grass` and `age` data.\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-get-gss2016-lodown}\n: Get GSS data via {**lodown**} package\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {#lst-chap01-get-gss2016-lodown}\n\n::: {.cell}\n\n```{.r .cell-code}\n## run only once (manually)\nmy_folder <- base::paste0(here::here(), \"/data-raw\")\n\n# (1) retrieve a listing of all available extracts for the GSS data\ngss_cat <- lodown::get_catalog(data_name = \"gss\",\n                               output_dir = my_folder,\n                               \"GSS\") |> \n## (2) choose the catalog part to download\n    dplyr::filter(\n        output_filename == base::paste0(my_folder, \"/2016.rds\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> building catalog for gss\n```\n\n\n:::\n\n```{.r .cell-code}\n## (3) download the GSS microdata as 2016.rds\nlodown::lodown(\"gss\" , gss_cat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> locally downloading gss\n#> \n#> 'http://gss.norc.org//Documents/spss/2016_spss.zip'\n#> cached in\n#> '/var/folders/sd/g6yc4rq1731__gh38rw8whvc0000gq/T//33ae817c3c2204f4bc040ba58bee1d81.Rcache'\n#> copying to\n#> '/var/folders/sd/g6yc4rq1731__gh38rw8whvc0000gq/T//RtmpiGqML2/file790b7b5a830d'\n#> \n#> gss catalog entry 1 of 1 stored at '/Users/petzi/Documents/Meine-Repos/swr-harris/data-raw/2016.rds'\n#> \n#> gss local download completed\n```\n\n\n:::\n\n```{.r .cell-code}\n## rename dataset to distinguish from other download approaches\nold_filename <- base::paste0(my_folder, \"/2016.rds\")\nnew_filename <- base::paste0(my_folder, \"/gss_2016_cat.rds\")\nbase::file.rename(from = old_filename, to = new_filename)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\n## load and glance at data\ngss_2016_cat <- base::readRDS(\"data-raw/gss_2016_cat.rds\")\ngss_2016_cat |> \n    dplyr::select(c(age, grass)) |> \n    glance_data(N = 8, seed = 2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>     obs age grass\n#> 1     1  47    NA\n#> 2   172  27     1\n#> 3   562  70     2\n#> 4   898  60     2\n#> 5  1019  30     1\n#> 6  1176  80     2\n#> 7  1505  53    NA\n#> 8  1911  54     2\n#> 9  2622  62    NA\n#> 10 2867  72     2\n```\n\n\n:::\n:::\n\n\nGet GSS data for the year 2016 via the {**lodown**} package\n:::\n::::\n:::::\n\nThe result is to a pure `.rds` file, but where the columns are still of class \"*haven_labelled, vctrs_vctr, double*\" as in @lst-chap01-read-rds-data.\n\n\n###### gssr\n\nFinally I will download the 2016 data with the help of the {**gssr**} package. This takes some minutes. At first I missed the vignette, so I had to download the package again with the additional argument `build_vignettes = TRUE`. Whereas the vignette explains how to analyse data the GitHub is very helpful how to get the desired data. \n\n> You can quickly get the data for any single GSS year by using `gssr::gss_get_yr()` to download the data file from NORC and put it directly into a tibble.\n\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap01-get-gss2016-gssr}\n: Get GSS 2016 Year Data Set (cross-section only)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap01-get-gss2016-gssr}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\n## run only once (manually)\ngss_2016_gssr <- gssr::gss_get_yr(year = 2016)\nbase::saveRDS(gss_2016_gssr, file = \"data-raw/gss_2016_gssr.rds\" )\n```\n:::\n\n\nGet GSS 2016 Year Data Set (cross-section only)\n\n:::\n\n\n::::\n:::::\n\nAfter downloaded the file we can --- as in the other tabs already done --- load the file and glance at the grass/age data.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-}\n: Glance at the 2016 grass/age data downloaded via {**gssr**}\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap01-glance-2016-gssr-data}\n\n::: {.cell}\n\n```{.r .cell-code}\n## load and glance at data\ngss_2016_gssr <- base::readRDS(\"data-raw/gss_2016_gssr.rds\")\ngss_2016_gssr |> \n    dplyr::select(c(age, grass)) |> \n    glance_data(N = 8, seed = 2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10 × 3\n#>      obs age       grass                      \n#>    <int> <dbl+lbl> <dbl+lbl>                  \n#>  1     1 47        NA(i) [iap]                \n#>  2   172 27            1 [should be legal]    \n#>  3   562 70            2 [should not be legal]\n#>  4   898 60            2 [should not be legal]\n#>  5  1019 30            1 [should be legal]    \n#>  6  1176 80            2 [should not be legal]\n#>  7  1505 53        NA(i) [iap]                \n#>  8  1911 54            2 [should not be legal]\n#>  9  2622 62        NA(i) [iap]                \n#> 10  2867 72            2 [should not be legal]\n```\n\n\n:::\n:::\n\n\nGlance at the 2016 grass/age data downloaded via {**gssr**}\n\n:::\n\nThis is exactly the same format as in listing @lst-chap01-import-stata-2016-file from the manual download. But it has now the advantages from the {**gssr**} package. For instance with the integrated help it is much easier to\n\n- find the variables \n- to read the question text of the variable\n- to see in which year the questions was asked\n- what the code - including the different types of NA’s mean\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n\n:::::{.my-important}\n:::{.my-important-header}\nSix different approaches to get the GSS data\n:::\n::::{.my-important-container}\nUsing the {**gssr**} packages seems to me by far the best approach.\n::::\n:::::\n\n\n# I STOPPED HERE\n\n## Data Wrangling {#sec-chap01-data-wrangling}\n\n::: my-r-code\n::: my-r-code-header\n\n: Get the data structure for the book Figure 1.2\n\n:::\n\n::: my-r-code-container\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_age_grass_2016_v2 <- gssr::gss_get_yr(year = 2016) |> \n    haven::zap_labels() |> \n    dplyr::select(grass, age) |>\n    tidyr::drop_na() |>\n    dplyr::mutate(grass = forcats::as_factor(grass)) |> \n    dplyr::mutate(grass = \n          forcats::fct_recode(grass, Yes = \"1\", No = \"2\")) |> \n    dplyr::mutate(age = base::as.numeric(age)) |> \n    dplyr::mutate(age_cut = cut(age,\n                  breaks = c(-Inf, 29, 59, 74, Inf),\n                  labels = c(\"< 30\", \"30 - 59\", \"60 - 74\", \"75+\")))\n\nbase::summary(gss_age_grass_2016_v2)\n```\n:::\n\n\n::::\n:::::\n\nAfter I have saved the data to do some data wrangling. To get the data\nstructure for the book Figure 1.2 I need to:\n\n-   filter the dataset to the year 2016\n-   select only the variables `age` and `grass`\n-   drop all NA’s\n-   convert `grass` into factor\n-   recode `grass` labels\n-   convert `age` from double to numeric\n-   divide `age` into appropriate age intervals and label them\n    accordingly\n\n::: my-r-code\n::: my-r-code-header\n::: {#cnj-chap01-age-grass-2016-v1}\n: Get the data structure for the book Figure 1.2\n:::\n:::\n\n::: my-r-code-container\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_age_grass_2016 <- base::readRDS(\"data-raw/gss_1972_2022_full.rds\")\n\ngss_age_grass_2016_v1  <- gss_age_grass_2016 |> \n    haven::zap_labels() |> \n    dplyr::filter(year == 2016) |> \n    dplyr::select(grass, age) |>\n    tidyr::drop_na() |>\n    dplyr::mutate(grass = forcats::as_factor(grass)) |> \n    dplyr::mutate(grass = \n          forcats::fct_recode(grass, Yes = \"1\", No = \"2\")) |> \n    dplyr::mutate(age = base::as.numeric(age)) |> \n    dplyr::mutate(age_cut = cut(age,\n                  breaks = c(-Inf, 29, 59, 74, Inf),\n                  labels = c(\"< 30\", \"30 - 59\", \"60 - 74\", \"75+\")))\n\nbase::summary(gss_age_grass_2016_v1)\n```\n:::\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2016_raw <- base::readRDS(\"data-raw/gss_2016_raw.rds\")\n\ngss_2016_clean <- gss_2016_raw |> \n    # haven::zap_labels() |> \n    dplyr::select(grass, age) |>\n    tidyr::drop_na() |>\n    dplyr::mutate(grass = forcats::as_factor(grass)) |> \n    dplyr::mutate(grass = forcats::fct_drop(grass)) |>\n    # base::droplevels() |> \n    # dplyr::mutate(grass = \n    #       forcats::fct_recode(grass, Yes = \"1\", No = \"2\")) |> \n    dplyr::mutate(age = base::as.numeric(age)) |> \n    dplyr::mutate(age_cut = cut(age,\n                  breaks = c(-Inf, 29, 59, 74, Inf),\n                  labels = c(\"< 30\", \"30 - 59\", \"60 - 74\", \"75+\")))\n\nbase::summary(gss_2016_clean)\n\n\nsaveRDS(gss_2016_clean, file = \"data-clean/gss_2016_clean.rds\" )\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_grass_age_2016 <- readxl::read_xlsx(\n    path = \"data-raw/gss_2016_exp.xlsx\"\n    )\n```\n:::\n\n\n::: {#lst-chap01-load-my-data}\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_marijuana_age <- readxl::read_xlsx(\n    path = \"data-raw/gss-marijuana-age.xlsx\"\n    )\n\nchap01_gss_marijuana_age_2016 <- \n    gss_marijuana_age |> \n    dplyr::filter(year == 2016) |> \n    dplyr::select(grass, age)\n\nset.seed(2016)\nbayr::as_tbl_obs(chap01_gss_marijuana_age_2016)\n```\n\n::: {.cell-output-display}\n\n\nTable: Data set with 3 variables, showing 8 of 2867 observations.\n\n|  Obs|grass               |age |\n|----:|:-------------------|:---|\n|  172|Should be legal     |27  |\n|  562|Should not be legal |70  |\n|  898|Should not be legal |60  |\n| 1019|Should be legal     |30  |\n| 1176|Should not be legal |80  |\n| 1505|.i:  Inapplicable   |53  |\n| 1911|Should not be legal |54  |\n| 2622|.i:  Inapplicable   |62  |\n\n\n\n:::\n:::\n\n\nLoad my version of marijuana data\n:::\n\n------------------------------------------------------------------------\n\n\n***\n\n\n\n# TEXTBAUSTEINE\n\nlocally downloading gss\n\n'http://gss.norc.org//Documents/spss/2016_spss.zip' cached in\n'/var/folders/sd/g6yc4rq1731\\_\\_gh38rw8whvc0000gq/T//33ae817c3c2204f4bc040ba58bee1d81.Rcache'\ncopying to\n'/var/folders/sd/g6yc4rq1731\\_\\_gh38rw8whvc0000gq/T//RtmpLdD3gJ/file11157926ddaf'\n\ngss catalog entry 1 of 1 stored at\n'/Users/petzi/Documents/Meine-Repos/swr-harris/data-raw/2016.rds'\n\ngss local download completed\n\n***\n\nThis action is often called \"data\nwrangling\" and all to frequent not taught in statistics. It is one of\nthe major virtues of \"Statistics with R\" the building up of these\nimportant skills are addressed.\n\n***\n\n\n::: {.cell}\n\n```{#lst-chap01-load-full-gss .r .cell-code  lst-cap=\"Load the full GSS Cumulative Data Set (cross-sectional samples 1972-2022)\"}\n## do not run\ngss_1972_2022_full <- haven::read_dta(\"data-raw/gss7222_r2.dta\")\nsaveRDS(gss_1972_2022_full, file = \"data-raw/gss_1972_2022_full.rds\" )\n```\n:::\n\n\n***\n\n: Import the Cumulative Data Set (cross-sectional samples from all\nyears) into R\n\n\n    \"Cumulative Data Set (cross-sectional samples\n    from all years)\". It was Release 2 from November 2023 and was\n    downloaded in about 5-10 seconds.\n3.  After I unzipped `GSS_stata.zip` (42.3MB) I received a folder\n    `GSS_stata` (557.9MB) with four files:\n    -   `GSS 2022 Codebook.pdf` with 759 page(!).\n    -   `gss722_r2.dta` (554.9MB). After loading into R I discovered\n        that it contains 72,390 rows with 6693 columns.\n    -   `ReadMe.txt` with the short message to read the documentation\n        carefully because of methodological changes in this round.\n    -   `Release Notes 7222.pdf` with some notes (5 pages) about issues\n        in the previous release (r1) and fixes in the current release\n        (r2).\n4.  It took my about 2-3 minutes to load the gigantic dataset into\n    `gss_1972_2022_full`. It used 3.6 GB of my computer memory.\n\nIt took me about 10-15\n    seconds to save a compressed version of the data file (38.7MB) and\n    about 5 second to load it via `base::readRDS()`.\n    \n    \n***\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# attributes(gss_2016_man$grass)\n# attributes(gss_2016_man$age)\n\ngss_2016_man |> \n    dplyr::select(c(age, grass)) |> \n    utils::str()\n\ngss_2016_man |> \n    dplyr::select(c(age, grass)) |> \n    base::summary()\n\ngss_2016_man |> \n    dplyr::select(c(age, grass)) |> \n    dplyr::glimpse()\n\nset.seed(2016)\ngss_2016_man |>   \n    dplyr::select(c(age, grass)) |> \n    bayr::as_tbl_obs() \n\n\ngss_2016_temp <- gss_2016_man |>   \n    dplyr::select(c(age, grass)) |>\n    dplyr::mutate(obs = dplyr::row_number()) |>\n    dplyr::filter(dplyr::row_number() %in% base::c(1, dplyr::n()))\n\nset.seed(2016)\ngss_2016_man |> \n    dplyr::select(c(age, grass)) |> \n    dplyr::mutate(obs = dplyr::row_number()) |> \n    dplyr::relocate(obs, age, grass) |> \n    dplyr::slice_sample(n = 8) |> \n    dplyr::bind_rows(gss_2016_temp) |> \n    dplyr::arrange(obs)\n\ngss_2016_man |> \n    dplyr::select(c(age, grass)) |>\n    utils::head()\n\ngss_2016_man |> \n    dplyr::select(c(age, grass)) |>\n    base::print()\n\ngss_2016_man |> \n    dplyr::count(grass)\n\n\nhead(gss_2016_man$age)\nhead(gss_2016_man$grass)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}