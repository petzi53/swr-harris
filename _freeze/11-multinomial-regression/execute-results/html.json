{
  "hash": "e7489e21fc95b40564d170b279b5b76e",
  "result": {
    "engine": "knitr",
    "markdown": "# Multinomial and ordinal logistic regression {#sec-chap11}\n\n\n\n\n\n## Achievements to unlock\n\n::: {#obj-chap11}\n::: my-objectives\n::: my-objectives-header\nObjectives for chapter 11\n:::\n\n::: my-objectives-container\n**SwR Achievements**\n\n-   **Achievement 1**: Using exploratory data analysis for multinomial\n    logistic regression (@sec-chap11-achievement1)\n-   **Achievement 2**: Estimating and interpreting a multinomial\n    logistic regression model (@sec-chap11-achievement2)\n-   **Achievement 3**: Checking assumptions for multinomial logistic\n    regression (@sec-chap11-achievement3)\n-   **Achievement 4**: Using exploratory data analysis for ordinal\n    logistic regression (@sec-chap11-achievement4)\n-   **Achievement 5**: Estimating and interpreting an ordinal logistic\n    regression models (@sec-chap11-achievement5)\n-   **Achievement 6**: Checking assumptions for ordinal logistic\n    regression (@sec-chap11-achievement6)\n:::\n:::\n\nAchievements for chapter 11\n:::\n\n## The diversity dilemma in STEM\n\nThere is a lack of diversity in the science, technology, engineering,\nand math (STEM) fields and specifically about the lack of women. There\nare fewer women college graduates in computer science and math jobs now\ncompared to 15 years ago.\n\nThere are three main reasons cited for fewer women in STEM:\n\n-   beliefs about natural ability,\n-   societal and cultural norms,\n-   and institutional barriers.\n\nOne thing that appeared to encourage women in STEM is the visibility of\nother women in STEM careers.\n\n## Resources & Chapter Outline\n\n### Data, codebook, and R packages {#sec-chap04-data-codebook-packages}\n\n::: my-resource\n::: my-resource-header\nData, codebook, and R packages for learning about descriptive statistics\n:::\n\n::: my-resource-container\n**Data**\n\nThree options for accessing the data:\n\n1.  Download and save the original SAS file `stem-nsf-2017-ch11.xpt`\n    from <https://edge.sagepub.com/harris1e> and run the code in the\n    first code chunk to clean the data.\n2.  Download and save the original SAS file `stem-nsf-2017-ch11.xpt`\n    from <https://edge.sagepub.com/harris1e> and follow the steps in Box\n    11.1 to clean the data.\n3.  Download and save the original 2017 National Survey of College\n    Graduates data from the National Science Foundation’s SESTAT Data\n    Tool (https://ncsesdata.nsf.gov/datadownload/) and follow Box 11.1\n    to clean the data.\n\nAs there is nothing new for me in the recoding procedures I will go for\nthe first option.\n\n**Codebook**\n\nTwo options for accessing the codebook:\n\n-   Download the `stem-nsf-2017-ch11-codebook.pdf` from\n    <https://edge.sagepub.com/harris1e>\n-   Use the version that comes when downloading the raw data file from\n    the National Science Foundation’s SESTAT Data Tool\n    (https://ncsesdata.nsf.gov/datadownload/)\n\n**Packages**\n\n1.  Packages used with the book (sorted alphabetically)\n\n-   {**Hmsic**}: @pak-Hmisc (Frank Harrell)\n-   {**MASS**}: @pak-MASS (Brian Ripley)\n-   {**mlogit**}: @pak-mlogit (Yves Croissant)\n-   {**nnet**}: @pak-nnet (Brian Ripley)\n-   {**ordinal**} @pak-ordinal (Rune Haubo Bojesen Christensen)\n-   {**tableone**} @pak-tableone (Kazuki Yoshida)\n-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)\n\n2.  My additional packages (sorted alphabetically)\n\n-   {**glue**}: @pak-glue (Jennifer Bryan)\n-   {**haven**}: @pak-haven (Hadley Wickham)\n-   {**skimr**}: @pak-skimr (Elin Waring)\n:::\n:::\n\n### Get & recode data\n\n::: my-r-code\n::: my-r-code-header\n::: {#cnj-chap11-get-data}\n: Get and recode data for chapter 11\n:::\n:::\n\n::: my-r-code-container\n::: {#lst-chap11-get-data}\n\n::: {.cell}\n\n```{.r .cell-code}\n## using zip file because of GitHub file limit of 100 MB\ntbl11 <- utils::unzip(\n    zipfile = \"data/chap11/stem-nsf-2017-ch11.xpt.zip\", \n    files = \"stem-nsf-2017-ch11.xpt\"\n    ) |> \n    Hmisc::sasxport.get()\n\n\n# function to recode the satisfaction variables\nRecSatis <- function(x){\n  return(base::as.ordered(forcats::fct_recode(x,\n                \"Very satisfied\" = \"1\" ,\n                \"Somewhat satisfied\" = \"2\",\n                \"Somewhat dissatisfied\" = \"3\",\n                \"Very dissatisfied\" = \"4\",\n                NULL = \"L\")\n            )\n    )\n}\n\n# recode and rename\ntbl11.1 <- tbl11  |> \n  dplyr::select(n2ocprmg, satadv, satsal, satsoc, gender, age)  |> \n  dplyr::mutate(job_cat = forcats::as_factor(\n                    forcats::fct_recode(.f = n2ocprmg,\n                          \"CS, Math, Eng\" = \"1\",\n                          \"Other Sciences\" = \"2\",\n                          \"Other Sciences\" = \"3\",\n                          \"Other Sciences\" = \"4\",\n                          \"CS, Math, Eng\" = \"5\",\n                          NULL = \"6\",\n                          \"Nonscience\" = \"7\",\n                          NULL  = \"8\"\n                          )\n                    )\n                ) |> \n  dplyr::mutate(satis_advance = RecSatis(x = satadv))  |> \n  dplyr::mutate(satis_salary = RecSatis(x = satsal))  |> \n  dplyr::mutate(satis_contrib = RecSatis(x = satsoc))  |> \n  dplyr::mutate(sex = dplyr::recode(.x = gender, \"M\" = \"Male\", \"F\"= \"Female\"))  |> \n  dplyr::mutate(sex = forcats::fct_relevel(.f = sex, c(\"Male\", \"Female\"))) |> \n  dplyr::mutate(age = as.numeric(x = age))  |> \n  dplyr::select(-n2ocprmg, -satadv, -satsal, -satsoc, -gender) |> \n  haven::zap_label()\n\n# # make sure the reordering worked\n# # re-order to have male first for ref group\n# print(levels(x = tbl11.1$sex))\n\nsave_data_file(\"chap11\", tbl11.1, \"tbl11.1.rds\")\n```\n:::\n\n\nGet and recode data for chapter 11\n:::\n\n(*For this R code chunk is no output available*)\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nAt first I thought that there are no new things in recoding the data for\nchapter 11. But it turned out that there are some issues to report:\n\n1.  **Using `haven::read_xpt()` instead of `Hmisc::sasxport.get()`**\n\nThis was an error in two respects:\n\n-   The variable names were not converted to lower case. So I had to\n    change all variable names in the following recoding.\n-   The {**haven**} function was *extremely* slow! In contrast to\n    `sasxport.get()` with 3.94 seconds the file export took 104.12\n    second, e.g. more than 26 times longer!\n\nI therefore returned to the much fast solution with\n`Hmisc::sasxport.get()`.\n\n------------------------------------------------------------------------\n\n2.  **Labelled data**\n\nI got with the export of a SAS transport file a labelled data frame with\nvery long labels. After the recoding I lost many of these labels except\nof two columns. Therefore I used `haven::zap_label()` to remove all\nvariable labels.\n\n------------------------------------------------------------------------\n\n3.  **The original data file is too big for GitHub**\n\nAfter I committed to GitHub I got an error, because the file\n`stem-nsf-2017-ch11.xpt` was too large. I compressed it as `.zip`-file\nand changed the import code slightly to adapt this change. After testing\nthat it worked I deleted the uncompressed file.\n\n------------------------------------------------------------------------\n\n4.  **Likert-scale as ordered factors**\n\nI changed the factor levels in the `RecSatis()` function with the\n{**forcats**} package. Additionally I changed all Likert-scale factors\nto ordered factors.\n\nWith this change I had some troubles, because I haven't had any\nexperience how to do and also to check if the levels are ordered or not.\nThe function `base::levels()` reports the sequence (chronological order)\nbut not the order of the factor levels.\n\n::: {#imp-chap11-ordered-factor-levels .callout-important}\n##### No possibility found in {forcats} to create factor with ordered levels\n\nI could manipulate the (chronological) *appearance* of levels in many\nways but I did not find an option to create the class\n`\"ordered\" \"factor\"`.\n\nTherefore I have to use one of the following base R options options:\n\n-   `base::as.ordered()`\n-   `base::factor(x = c(\"A\", \"Z\", \"M\"), levels = c(\"A\", \"B\", \"M\", \"Z\"), ordered = TRUE)`\n-   `base::ordered(c(\"A\", \"Z\", \"M\"), level = c(\"Z\", \"M\", \"A\"))`\n:::\n\nThe following examples uses in the first line with\n`tbl11.1$satis_advance` an ordered factor, and with the second line\n(after the '---' line) with `tbl11.1$sex` a factor without order.\n\n::: my-r-code\n::: my-r-code-header\n::: {#cnj-chap11-checking-levels-order}\n: How to check the order of factor levels?\n:::\n:::\n\n::: my-r-code-container\n::: {#lst-chap11-checking-levels-orderD}\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl11.1 <- base::readRDS(\"data/chap11/tbl11.1.rds\")\n\nglue::glue(\"##########################################################################\")\nglue::glue(\"base::levels() does not reveal if theres is an order in the factor levels\")\nbase::levels(tbl11.1$satis_advance)\nglue::glue(\"--------------------------------------------------------------------------\")\nbase::levels(tbl11.1$sex)\n\nglue::glue(\" \")\nglue::glue(\"##########################################################################\")\nglue::glue(\"If you display a value of an ordered factor, it reveals the order with '<'\")\nhead(tbl11.1$satis_advance, 1)\nglue::glue(\" \")\nglue::glue(\"To prevent showing one value one can use forcats::fct_unique()\")\nforcats::fct_unique(tbl11.1$satis_advance)\nglue::glue(\"--------------------------------------------------------------------------\")\nhead(tbl11.1$sex, 1)\n\n\nglue::glue(\"How to check if a factor has ordered levels, but not the order itself?\")\nglue::glue(\" \")\nglue::glue(\"##########################################################################\")\nglue::glue(\"utils::str()\")\nutils::str(tbl11.1)\n\nglue::glue(\" \")\nglue::glue(\"##########################################################################\")\nglue::glue(\"base::class()\")\nbase::class(tbl11.1$satis_advance)\nglue::glue(\"--------------------------------------------------------------------------\")\nbase::class(tbl11.1$sex)\n\nglue::glue(\" \")\nglue::glue(\"##########################################################################\")\nglue::glue(\"base::is.ordered()\")\nbase::is.ordered(tbl11.1$satis_advance)\nglue::glue(\"--------------------------------------------------------------------------\")\nbase::is.ordered(tbl11.1$sex)\n\nglue::glue(\" \")\nglue::glue(\"##########################################################################\")\nglue::glue(\"skimr::skim()) has a column 'ordered' about the status of the factor variable\")\ntbl11.1 |> dplyr::select(satis_advance, sex) |> skimr::skim()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ##########################################################################\n#> base::levels() does not reveal if theres is an order in the factor levels\n#> [1] \"Very satisfied\"        \"Somewhat satisfied\"    \"Somewhat dissatisfied\"\n#> [4] \"Very dissatisfied\"    \n#> --------------------------------------------------------------------------\n#> [1] \"Male\"   \"Female\"\n#>  \n#> ##########################################################################\n#> If you display a value of an ordered factor, it reveals the order with '<'\n#> [1] Very satisfied\n#> 4 Levels: Very satisfied < Somewhat satisfied < ... < Very dissatisfied\n#>  \n#> To prevent showing one value one can use forcats::fct_unique()\n#> [1] Very satisfied        Somewhat satisfied    Somewhat dissatisfied\n#> [4] Very dissatisfied     <NA>                 \n#> 4 Levels: Very satisfied < Somewhat satisfied < ... < Very dissatisfied\n#> --------------------------------------------------------------------------\n#> [1] Female\n#> Levels: Male Female\n#> How to check if a factor has ordered levels, but not the order itself?\n#>  \n#> ##########################################################################\n#> utils::str()\n#> 'data.frame':\t83672 obs. of  6 variables:\n#>  $ age          : num  37 37 45 52 45 62 56 50 41 51 ...\n#>  $ job_cat      : Factor w/ 3 levels \"CS, Math, Eng\",..: NA 3 1 1 3 2 2 NA NA 3 ...\n#>  $ satis_advance: Ord.factor w/ 4 levels \"Very satisfied\"<..: 1 3 2 3 1 1 2 2 NA 3 ...\n#>  $ satis_salary : Ord.factor w/ 4 levels \"Very satisfied\"<..: 2 2 2 1 1 1 4 2 NA 2 ...\n#>  $ satis_contrib: Ord.factor w/ 4 levels \"Very satisfied\"<..: 1 2 2 3 1 2 1 1 NA 2 ...\n#>  $ sex          : Factor w/ 2 levels \"Male\",\"Female\": 2 2 1 2 1 1 2 1 2 1 ...\n#>  \n#> ##########################################################################\n#> base::class()\n#> [1] \"ordered\" \"factor\" \n#> --------------------------------------------------------------------------\n#> [1] \"factor\"\n#>  \n#> ##########################################################################\n#> base::is.ordered()\n#> [1] TRUE\n#> --------------------------------------------------------------------------\n#> [1] FALSE\n#>  \n#> ##########################################################################\n#> skimr::skim()) has a column 'ordered' about the status of the factor variable\n```\n\n\n:::\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |                             |\n|:------------------------|:----------------------------|\n|Name                     |dplyr::select(tbl11.1, sa... |\n|Number of rows           |83672                        |\n|Number of columns        |2                            |\n|_______________________  |                             |\n|Column type frequency:   |                             |\n|factor                   |2                            |\n|________________________ |                             |\n|Group variables          |None                         |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                                    |\n|:-------------|---------:|-------------:|:-------|--------:|:---------------------------------------------|\n|satis_advance |     14041|          0.83|TRUE    |        4|Som: 30443, Ver: 16980, Som: 15632, Ver: 6576 |\n|sex           |         0|          1.00|FALSE   |        2|Mal: 45470, Fem: 38202                        |\n\n\n:::\n:::\n\n\nSeveral options to check the order of factor levels\n:::\n:::\n:::\n\n### Show raw data\n\n::: my-example\n::: my-example-header\n::: {#exm-chap11-show-data}\n: Show summary of recoded data for chapter 11\n:::\n:::\n\n::: my-example-container\n::: panel-tabset\n###### tbl11.1\n\n::: my-r-code\n::: my-r-code-header\n::: {#cnj-chap11-show-tbl11.1}\n: Show recoded data for chapter 11 (`tbl11.1`)\n:::\n:::\n\n::: my-r-code-container\n::: {#lst-chap11-show-tbl11.1}\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl11.1 <- base::readRDS(\"data/chap11/tbl11.1.rds\")\n\nglue::glue(\"********** Summarizing with base:summary() **************\")\nbase::summary(tbl11.1)\n\nglue::glue(\"  \")\nglue::glue(\"  \")\nglue::glue(\"********** Summarizing with skimr::skim() **************\")\nglue::glue(\"  \")\nskimr::skim(tbl11.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ********** Summarizing with base:summary() **************\n#>       age                  job_cat                    satis_advance  \n#>  Min.   :20.00   CS, Math, Eng :17223   Very satisfied       :16980  \n#>  1st Qu.:32.00   Other Sciences: 7642   Somewhat satisfied   :30443  \n#>  Median :44.00   Nonscience    :31043   Somewhat dissatisfied:15632  \n#>  Mean   :45.53   NA's          :27764   Very dissatisfied    : 6576  \n#>  3rd Qu.:58.00                          NA's                 :14041  \n#>  Max.   :75.00                                                       \n#>                 satis_salary                 satis_contrib       sex       \n#>  Very satisfied       :21073   Very satisfied       :35124   Male  :45470  \n#>  Somewhat satisfied   :34453   Somewhat satisfied   :25341   Female:38202  \n#>  Somewhat dissatisfied: 9854   Somewhat dissatisfied: 6774                 \n#>  Very dissatisfied    : 4251   Very dissatisfied    : 2392                 \n#>  NA's                 :14041   NA's                 :14041                 \n#>                                                                            \n#>   \n#>   \n#> ********** Summarizing with skimr::skim() **************\n#> \n```\n\n\n:::\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |tbl11.1 |\n|Number of rows           |83672   |\n|Number of columns        |6       |\n|_______________________  |        |\n|Column type frequency:   |        |\n|factor                   |5       |\n|numeric                  |1       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                                    |\n|:-------------|---------:|-------------:|:-------|--------:|:---------------------------------------------|\n|job_cat       |     27764|          0.67|FALSE   |        3|Non: 31043, CS,: 17223, Oth: 7642             |\n|satis_advance |     14041|          0.83|TRUE    |        4|Som: 30443, Ver: 16980, Som: 15632, Ver: 6576 |\n|satis_salary  |     14041|          0.83|TRUE    |        4|Som: 34453, Ver: 21073, Som: 9854, Ver: 4251  |\n|satis_contrib |     14041|          0.83|TRUE    |        4|Ver: 35124, Som: 25341, Som: 6774, Ver: 2392  |\n|sex           |         0|          1.00|FALSE   |        2|Mal: 45470, Fem: 38202                        |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|  mean|   sd| p0| p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|-----:|----:|--:|---:|---:|---:|----:|:-----|\n|age           |         0|             1| 45.53| 14.3| 20|  32|  44|  58|   75|▆▇▆▆▃ |\n\n\n:::\n:::\n\n\nShow recoded data for chapter 11 (`tbl11.1`)\n:::\n\n------------------------------------------------------------------------\n\n-   **job_cat**: Job caktegory of current job. `n2ocprmg` was the\n    original variable name. Recoded into three categories:\n    -   CS, Math, Eng = Computer science, math, and engineering fields\n    -   Other sciences = Other science fields\n    -   Nonscience = Not a science field\n-   **satis_advance**: Satisfaction with advancement opportunity.\n    `satadv` was the original variable name. 4-point Likert scale from 4\n    = very dissatisfied to 1 = very satisfied.\n-   `satis_salary`: Satisfaction with salary. `satsal` was the original\n    variable name. 4-point Likert scale from 4 = very dissatisfied to 1\n    = very satisfied.\n-   **satis.contrib**: Satisfaction with contribution to society.\n    `satsoc` was the original variable name. 4-point Likert scale from 4\n    = very dissatisfied to 1 = very satisfied\n-   **sex**: gender was the original variable name. Two categories:\n    Female, Male\n-   **age**: Age in years, not recoded or renamed\n:::\n:::\n\n###### sample\n\n::: my-r-code\n::: my-r-code-header\n::: {#cnj-chap11-sample-by-group}\n: Sample 1500 cases: 500 from each job category\n:::\n:::\n\n::: my-r-code-container\n::: {#lst-chap11-sample-by-group}\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl11.1 <- base::readRDS(\"data/chap11/tbl11.1.rds\")\n\nbase::set.seed(seed = 143)\n# take a sample of 1500 cases\n# 500 from each job.cat category\ntbl11.2 <- tbl11.1 |> \n  tidyr::drop_na(job_cat) |> \n  dplyr::group_by(job_cat)  |> \n  dplyr::slice_sample(n = 500)\n\nsave_data_file(\"chap11\", tbl11.2, \"tbl11.2.rds\")\n\nglue::glue(\"********** Summarizing with base:summary() **************\")\nbase::summary(tbl11.2)\n\nglue::glue(\" \")\nglue::glue(\" \")\nglue::glue(\"********** Summarizing with skimr::skim() **************\")\nglue::glue(\" \")\nskimr::skim(tbl11.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ********** Summarizing with base:summary() **************\n#>       age                  job_cat                  satis_advance\n#>  Min.   :23.00   CS, Math, Eng :500   Very satisfied       :342  \n#>  1st Qu.:32.00   Other Sciences:500   Somewhat satisfied   :646  \n#>  Median :40.00   Nonscience    :500   Somewhat dissatisfied:361  \n#>  Mean   :42.89                        Very dissatisfied    :151  \n#>  3rd Qu.:54.00                                                   \n#>  Max.   :75.00                                                   \n#>                 satis_salary               satis_contrib     sex     \n#>  Very satisfied       :420   Very satisfied       :732   Male  :911  \n#>  Somewhat satisfied   :763   Somewhat satisfied   :570   Female:589  \n#>  Somewhat dissatisfied:225   Somewhat dissatisfied:154               \n#>  Very dissatisfied    : 92   Very dissatisfied    : 44               \n#>                                                                      \n#>                                                                      \n#>  \n#>  \n#> ********** Summarizing with skimr::skim() **************\n#> \n```\n\n\n:::\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |tbl11.2 |\n|Number of rows           |1500    |\n|Number of columns        |6       |\n|_______________________  |        |\n|Column type frequency:   |        |\n|factor                   |4       |\n|numeric                  |1       |\n|________________________ |        |\n|Group variables          |job_cat |\n\n\n**Variable type: factor**\n\n|skim_variable |job_cat        | n_missing| complete_rate|ordered | n_unique|top_counts                            |\n|:-------------|:--------------|---------:|-------------:|:-------|--------:|:-------------------------------------|\n|satis_advance |CS, Math, Eng  |         0|             1|TRUE    |        4|Som: 227, Ver: 115, Som: 115, Ver: 43 |\n|satis_advance |Other Sciences |         0|             1|TRUE    |        4|Som: 213, Som: 131, Ver: 109, Ver: 47 |\n|satis_advance |Nonscience     |         0|             1|TRUE    |        4|Som: 206, Ver: 118, Som: 115, Ver: 61 |\n|satis_salary  |CS, Math, Eng  |         0|             1|TRUE    |        4|Som: 254, Ver: 163, Som: 68, Ver: 15  |\n|satis_salary  |Other Sciences |         0|             1|TRUE    |        4|Som: 257, Ver: 128, Som: 79, Ver: 36  |\n|satis_salary  |Nonscience     |         0|             1|TRUE    |        4|Som: 252, Ver: 129, Som: 78, Ver: 41  |\n|satis_contrib |CS, Math, Eng  |         0|             1|TRUE    |        4|Som: 230, Ver: 193, Som: 61, Ver: 16  |\n|satis_contrib |Other Sciences |         0|             1|TRUE    |        4|Ver: 297, Som: 163, Som: 34, Ver: 6   |\n|satis_contrib |Nonscience     |         0|             1|TRUE    |        4|Ver: 242, Som: 177, Som: 59, Ver: 22  |\n|sex           |CS, Math, Eng  |         0|             1|FALSE   |        2|Mal: 389, Fem: 111                    |\n|sex           |Other Sciences |         0|             1|FALSE   |        2|Mal: 263, Fem: 237                    |\n|sex           |Nonscience     |         0|             1|FALSE   |        2|Mal: 259, Fem: 241                    |\n\n\n**Variable type: numeric**\n\n|skim_variable |job_cat        | n_missing| complete_rate|  mean|    sd| p0|   p25| p50| p75| p100|hist  |\n|:-------------|:--------------|---------:|-------------:|-----:|-----:|--:|-----:|---:|---:|----:|:-----|\n|age           |CS, Math, Eng  |         0|             1| 41.00| 12.39| 23| 30.75|  37|  52|   74|▇▅▃▃▁ |\n|age           |Other Sciences |         0|             1| 43.08| 13.26| 23| 32.00|  40|  55|   73|▇▆▅▅▂ |\n|age           |Nonscience     |         0|             1| 44.60| 13.18| 23| 33.00|  43|  55|   75|▇▇▆▆▂ |\n\n\n:::\n:::\n\n\nShow sampled data: 500 from each job category\n:::\n:::\n:::\n:::\n:::\n:::\n\n## Achievement 1: EDA for multinomial logistic regression {#sec-chap11-achievement1}\n\n### Visualizing employment\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap11-eda-employment}\n: Visualizing employment in computer science, math, and engineering by sex and age\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### sex-jobs\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-sex-wihtin-jobtype}\n: Plotting distribution of sex within job type\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-sex-wihtin-jobtype}\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl11.2 <- base::readRDS(\"data/chap11/tbl11.2.rds\")\n\n# plotting distribution of sex within job type (Figure 11.3)\ntbl11.2 |> \n  ggplot2::ggplot(\n    ggplot2::aes(\n        x = sex, \n        group = job_cat,\n        y = ggplot2::after_stat(prop)\n      )\n    ) +\n  ggplot2::geom_bar(fill = \"#7463AC\") +\n  ggplot2::labs(\n      y = \"Percent within job category\", \n      x = \"Sex\"\n    ) +\n  # ggplot2::facet_grid(cols = ggplot2::vars(job_cat)) +\n  # using another, more simple facet_grid() function:\n  ggplot2::facet_grid(~ job_cat) +\n  ggplot2::scale_y_continuous(labels = scales::percent)\n```\n\n::: {.cell-output-display}\n![](11-multinomial-regression_files/figure-html/eda-sex-wihtin-jobtype-1.png){width=672}\n:::\n:::\n\n\nDistribution of sex within job type among 1,500 college graduates in 2017\n:::\n\n***\n\n`ggplot2::after_stat()` replaces the old approach surrounding the variable names with .., e.g. `..prop..`.  {**ggplot2**} throws a warning:\n\n> #> Warning: The dot-dot notation (`..prop..`) was deprecated in ggplot2 3.4.0.\n>\n> #> ℹ Please use `after_stat(prop)` instead.\n\nAt first I had problems, because I used `y = ggplot2::after_stat(count/sum(count))` inside the `ggplot2::aes()` function. This calculated the percentage over all different categories and not within each job category. The I learned with **The 'computed variables' section in each stat lists which variables are available to access.** that {**ggplot2**} computes with the `ggplot2::stat_count()` function for bar charts also groupwise proportion with `ggplot2::after_stat(prop)`.\n\n\n\n::::\n:::::\n\n:::::{.my-resource}\n:::{.my-resource-header}\n:::::: {#lem-chap11-using-ggplot2-after-stat}\n: How to use ggplot2::after_stat()?\n::::::\n:::\n::::{.my-resource-container}\n\n\n\nTo learn how to use the `ggplot2::after_stat()` function:\n\n- Read the help page to understand the differences between the different stages of mapping (direct input, `after_stat()` and `after_scale()`). Very important is the sentence: **The 'computed variables' section in each stat lists which variables are available to access.**\n- Read the short article [Using after_stat() in {**ggplot2**}](https://rstudio-pubs-static.s3.amazonaws.com/789869_e4500f2be0ba45279290b1753d8358bc.html) to use `after_stat()` to show percentages in the bar chart. \n- The first article of the very extensive series of articles going into many technical detail working --- at least for me --- as an eye opener how {**ggplot2**} works [Demystifying delayed aesthetic evaluation: Part 1](https://yjunechoe.github.io/posts/2022-03-10-ggplot2-delayed-aes-1/).\n- Hadley Wickham is currently preparing online the third edition of [ggplot2: Elegant Graphics for Data Analysis](https://ggplot2-book.org/) which also has many details about the `after_stat()` function, for instance in [13 Build a plot layer by layer](https://ggplot2-book.org/layers.html#sec-stat). \n\n::::\n:::::\n\n\n\n###### jobs by sex\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-jobtype-sex}\n: Distribution of job type by sex\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-jobtype-sex}  \n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting distribution of job type by sex (Figure 11.4)\ntbl11.2 |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = job_cat, \n          group = sex,\n          y = ggplot2::after_stat(prop)\n      )\n  ) +\n  ggplot2::geom_bar(fill = \"#7463AC\") +\n  ggplot2::labs(\n      y = \"Percent within sex category\", \n      x = \"Job category\"\n  ) +\n  ggplot2::facet_grid(cols = ggplot2::vars(sex)) +\n  ggplot2::scale_y_continuous(labels = scales::percent)\n```\n\n::: {.cell-output-display}\n![](11-multinomial-regression_files/figure-html/eda-jobtype-sex-1.png){width=672}\n:::\n:::\n\n\nDistribution of job type by sex \n:::\n\n::::\n:::::\n\n###### jobs by age\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-jobtype-age}\n: Distribution of job type and age\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-jobtype-age}\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting distribution of job type and age (Figure 11.5)\ntbl11.2 |> \n  ggplot2::ggplot(\n    ggplot2::aes(\n      y = age, \n      x = job_cat\n      )\n  ) +\n  ggplot2::geom_jitter(\n    ggplot2::aes(\n        color = job_cat\n        ), \n    alpha = .6\n  ) +\n  ggplot2::geom_boxplot(\n    ggplot2::aes(\n          fill = job_cat\n          ), \n    alpha = .4\n  ) +\n  ggplot2::scale_fill_manual(\n      values = c(\"dodgerblue2\",\"#7463AC\", \"gray40\"), \n      guide = \"none\") +\n  ggplot2::scale_color_manual(values = c(\"dodgerblue2\",\"#7463AC\", \"gray40\"), \n      guide = \"none\") +\n  ggplot2::labs(\n    x = \"Job type\", \n    y = \"Age in years\"\n  )\n```\n\n::: {.cell-output-display}\n![](11-multinomial-regression_files/figure-html/eda-jobtype-age-1.png){width=672}\n:::\n:::\n\n\nDistribution of job type and age\n:::\n\n::::\n:::::\n\n###### jobs, age & sex\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-jobtype-age-sex}\n: Distribution of jobtype by age and sex\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-jobtype-age-sex}\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting distribution of job type, age, and sex (Figure 11.6)\ntbl11.2  |> \n  ggplot2::ggplot(\n    ggplot2::aes(\n      y = age, \n      x = job_cat, \n      fill = sex)\n  ) +\n  ggplot2::geom_jitter(\n    ggplot2::aes(\n      color = sex\n      ), \n    alpha = .6\n  ) +\n  ggplot2::geom_boxplot(\n    ggplot2::aes(\n      fill = sex\n      ), \n    alpha = .4) +\n  ggplot2::scale_fill_manual(\n    values = c(\"gray\", \"#7463AC\"), \n    name = \"Sex\"\n  ) +\n  ggplot2::scale_color_manual(\n    values = c(\"gray\", \"#7463AC\"), \n    guide = \"none\") +\n  ggplot2::labs(\n    x = \"Job type\", \n    y = \"Age in years\"\n  )\n```\n\n::: {.cell-output-display}\n![](11-multinomial-regression_files/figure-html/eda-jobtype-age-sex-1.png){width=672}\n:::\n:::\n\n\nDistribution of job type by age and sex\n:::\n\n\n::::\n:::::\n\n###### jobs by sex & age\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-jobtype-sex-age}\n: Distribution by job type sex and age\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-jobtype-sex-age}\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting distribution of job type, sex, and age (Figure 11.7)\ntbl11.2  |> \n  ggplot2::ggplot(\n    ggplot2::aes(\n      y = age, \n      x = job_cat)\n  ) +\n  ggplot2::geom_jitter(\n    ggplot2::aes(\n      color = sex\n      ), \n    alpha = .6\n  ) +\n  ggplot2::geom_boxplot(\n    ggplot2::aes(\n      fill = sex\n      ), \n    alpha = .4\n  ) +\n  ggplot2::scale_fill_manual(\n    values = c(\"gray\", \"#7463AC\"), \n    guide = \"none\"\n  ) +\n  ggplot2::scale_color_manual(\n    values = c(\"gray\", \"#7463AC\"), \n    guide = \"none\"\n  ) +\n  ggplot2::labs(\n    x = \"Job type\", \n    y = \"Age in years\"\n  ) +\n  ggplot2::facet_grid(cols = ggplot2::vars(sex))\n```\n\n::: {.cell-output-display}\n![](11-multinomial-regression_files/figure-html/eda-jobtype-sex-age-1.png){width=672}\n:::\n:::\n\n\nDistribution by job type sex and age\n:::\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n***\n\n::: {.callout #rep-chap11-visualizing-employment}\n##### Summary of the several plots about employment\n\n1. @lst-chap11-eda-sex-wihtin-jobtype: Computer science, math, and engineering have about a third as many females as males, other sciences and non-science were slightly more male than female.\n2. @lst-chap11-eda-jobtype-sex: Computer science, math, and engineering jobs were the least common for females while this category was the largest for males.\n3. @lst-chap11-eda-jobtype-age: While the age range for all the data appeared similar across the three job types, the computer science, math, and engineering field employed the youngest people on average.\n4. @lst-chap11-eda-jobtype-age-sex: In all three fields, the distribution of age showed that males have an older median age than females, and in the two science fields, the range of age is wider for males than females.\n5. @lst-chap11-eda-jobtype-sex-age: The lowest median age for females is in computer science, math, and engineering and higher in other sciences and non-science. The age distribution for males showed a similar pattern across the three job types. Computer science, math, and engineering has the youngest median age for both sexes.\n\n:::\n\n### Checking bivariate statistical associations\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap11-eda-bivariate-associations}\n: Checking bivariate statistical associations between job type, sex, and age\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### age distribution\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-age-distribution}\n: Age distribution by job type among 1,500 college graduates in 2017\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-age-distribution}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting distribution of age (Figure 11.8)\ntbl11.2  |> \n  ggplot2::ggplot(\n    ggplot2::aes(x = age)\n  ) +\n  ggplot2::geom_histogram(\n    bins = 30,\n    fill = \"#7463AC\", \n    color = \"white\"\n  ) +\n  ggplot2::labs(\n    x = \"Age in years\", \n    y = \"Number of observations\"\n  ) +\n  ggplot2::facet_grid(cols = ggplot2::vars(job_cat))\n```\n\n::: {.cell-output-display}\n![](11-multinomial-regression_files/figure-html/eda-age-distribution-1.png){width=672}\n:::\n:::\n\n\nAge distribution by job type among 1,500 college graduates in 2017\n\n:::\n\n***\n\nThe histograms were not normally distributed for any of the three groups.\n\n::::\n:::::\n\n\n###### statistics\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-eda-statistics}\n: Table of statistics to examine `job_cat`\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-eda-statistics}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make a table of statistics to examine job.cat\ntable_desc <- tableone::CreateTableOne(\n  data = tbl11.2, \n  strata = 'job_cat',\n  vars = c('sex', 'age')\n  )\n\nbase::print(table_desc, \n            showAllLevels = TRUE, \n            nonnormal = 'age'\n            )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                     Stratified by job_cat\n#>                      level  CS, Math, Eng        Other Sciences      \n#>   n                           500                  500               \n#>   sex (%)            Male     389 (77.8)           263 (52.6)        \n#>                      Female   111 (22.2)           237 (47.4)        \n#>   age (median [IQR])        37.00 [30.75, 52.00] 40.00 [32.00, 55.00]\n#>                     Stratified by job_cat\n#>                      Nonscience           p      test   \n#>   n                    500                              \n#>   sex (%)              259 (51.8)         <0.001        \n#>                        241 (48.2)                       \n#>   age (median [IQR]) 43.00 [33.00, 55.00] <0.001 nonnorm\n```\n\n\n:::\n:::\n\n\nTable of statistics to examine `job_cat`\n:::\n\n***\n\nThe visual differences in the graphs corresponded to statistically significant differences from the <a class='glossary' title='Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary)'>chi-squared</a> and <a class='glossary' title='Kruskal-Wallis test is used to compare ranks across three or more groups when the normal distribution assumption fails for analysis of variance (ANOVA) (SwR, Glossary)'>Kruskal-Wallis</a> tests. The median age for college graduates in computer science, math, or engineering was 3 years lower than the median age in other sciences and 6 years younger than the median age in non-science careers. Computer science, math, and engineering has more than three times as many males as females.\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n## Achievement 2: Estimating a multinomial logistic regression model {#sec-chap11-achievement2}\n\n### Introduction\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-chapp1-model-reporting}\n::::::\n: Important to report with every model\n::::\n:::: {.my-bulletbox-body}\n\n- **Model significance**: Is the model significantly better than some baseline at explaining the outcome? \n- **Model fit:** How well does the model capture the relationships in the underlying data? \n- **Predictor values and significance**: What is the size, direction, and significance of the relationship between each predictor and the outcome?\n- **Checking model assumptions**: Are the model assumptions met?\n::::\n:::\n\n\n### Check reference groups\n\nBefore starting with the computation for the multinomial logistic regression it is practicable to check the reference groups with `base::levels()`. The results are easier to interpret if the reference groups (= the first level) is consistent with what one is interested in. Otherwise use `stats::relevel()` or one of the many functions in {**forcats**}, for instance `fct_recode()` or `fct_relevel()`.\n\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-check-levels}\n: Check reference groups for regression\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-check-levels}\n\n::: {.cell}\n\n```{.r .cell-code}\nbase::levels(tbl11.2$job_cat)\nbase::levels(tbl11.2$sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] \"CS, Math, Eng\"  \"Other Sciences\" \"Nonscience\"    \n#> [1] \"Male\"   \"Female\"\n```\n\n\n:::\n:::\n\nReference group for `job_cat` (= \"CS, Math, Eng\") and `sex` (= \"Male\")\n:::\n\n***\nThe reference group are fine; no change is necessary.\n\n::::\n:::::\n\n\n### NHST Step 1\n\nWrite the null and alternate hypotheses:\n\n::: {.callout-note}\n- **H0**: A multinomial model including sex and age is not useful in explaining or predicting job type for college graduates.\n- **HA**: A multinomial model including sex and age is useful in explaining or predicting job type for college graduates.\n:::\n\n### NHST Step 2\n\nA Google search revealed the most of the R tutorials use the {**nnet**} package recommended also by <a class='glossary' title='SwR is my abbreviation of: Harris, J. K. (2020). Statistics With R: Solving Problems Using Real-World Data (Illustrated Edition). SAGE Publications, Inc.'>SwR</a>. A newer approach uses the meta-package {**tidymodel**} (similar to **tidyverse**) which collects 22 packages for modeling, containing {**parsnip**} with the `multinom_reg()` function that ca fit different classification models, including {**nnet**} as default package.\n\n:::::: {#tdo-chap11-learn-tidymodels}\n:::::{.my-checklist}\n:::{.my-checklist-header}\nTODO: Learn {**tidymodels**}\n:::\n::::{.my-checklist-container}\nI already learned from the {**tidymodels**} approach three-four years ago. But at that time I thought that it is too advanced for my skill level. This has changed now. I have worked through all of the three pre-requisites mentioned on the [start page of tidymodels](https://www.tidymodels.org/start/). And now --- coming to the end of <a class='glossary' title='SwR is my abbreviation of: Harris, J. K. (2020). Statistics With R: Solving Problems Using Real-World Data (Illustrated Edition). SAGE Publications, Inc.'>SwR</a> --- I understand why this unification project is important.\n::::\n:::::\nLearn [{**tidymodels**}](https://www.tidymodels.org/)\n:::\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap11-multinom-computation}\n: Computing a multinomial logical regression\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### model\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-estimate-multinomial-model}\n: Estimate model and print summary\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-estimate-multinomial-model}\n\n::: {.cell}\n\n```{.r .cell-code}\n# estimate the model and print its summary\nmnm1 <- nnet::multinom(\n  formula = job_cat ~ age + sex + age*sex,\n  data = tbl11.2,\n  model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # weights:  15 (8 variable)\n#> initial  value 1647.918433 \n#> iter  10 value 1587.596983\n#> final  value 1585.536069 \n#> converged\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(object = mnm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Call:\n#> nnet::multinom(formula = job_cat ~ age + sex + age * sex, data = tbl11.2, \n#>     model = TRUE)\n#> \n#> Coefficients:\n#>                (Intercept)        age sexFemale age:sexFemale\n#> Other Sciences   -1.108879 0.01671124  1.190186  5.013094e-05\n#> Nonscience       -1.659125 0.02846208  1.521268 -6.082880e-03\n#> \n#> Std. Errors:\n#>                (Intercept)         age sexFemale age:sexFemale\n#> Other Sciences   0.2724993 0.006032186 0.4968062    0.01166812\n#> Nonscience       0.2803308 0.006040267 0.5010979    0.01162522\n#> \n#> Residual Deviance: 3171.072 \n#> AIC: 3187.072\n```\n\n\n:::\n:::\n\n\nComputing a multinomial regression model for job types by age and sex with interaction \n:::\n\n::::\n:::::\n\n\n###### null model\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-estimate-multinomial-null-model}\n: Estimate null model\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-estimate-multinomial-null-model}  \n\n::: {.cell}\n\n```{.r .cell-code}\n# multinomial null model\nmnm2 <- nnet::multinom(\n  formula = job_cat ~ 1,\n  data = tbl11.2,\n  model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # weights:  6 (2 variable)\n#> initial  value 1647.918433 \n#> final  value 1647.918433 \n#> converged\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(object = mnm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Call:\n#> nnet::multinom(formula = job_cat ~ 1, data = tbl11.2, model = TRUE)\n#> \n#> Coefficients:\n#>                  (Intercept)\n#> Other Sciences -1.081690e-12\n#> Nonscience      2.222222e-12\n#> \n#> Std. Errors:\n#>                (Intercept)\n#> Other Sciences  0.06324555\n#> Nonscience      0.06324555\n#> \n#> Residual Deviance: 3295.837 \n#> AIC: 3299.837\n```\n\n\n:::\n:::\n\n\nMultinomial null model\n:::\n\n::::\n:::::\n\n###### test statistics\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-mnm-test-statistics}\n: Compute test statistics for the multinomial model `mnm1`\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-mnm-test-statistics}\n\n::: {.cell}\n\n```{.r .cell-code}\n# get the job model chi-squared\njob_chisq <- mnm2$deviance - mnm1$deviance\n\n# get the degrees of freedom for chi-squared\njob_df <- length(x = summary(object = mnm1)$coefficients) - \n  length(x = summary(object = mnm2)$coefficients)\n\n# get the p-value for chi-squared\njob_p <- stats::pchisq(\n  q = job_chisq, \n  df = job_df, \n  lower.tail = FALSE\n  )\n\n# put together into a vector and round to 3 decimal places\nmodel_sig <- base::round(x = c(job_chisq, job_df, job_p), 3)\n\n# add names to the vector\nbase::names(x = model_sig) <- c(\"Chi-squared\", \"df\", \"p\")\n\n# print the vector\nmodel_sig\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Chi-squared          df           p \n#>     124.765       6.000       0.000\n```\n\n\n:::\n:::\n\n\nTest statistics for the multinomial model\n:::\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n**Finishing step 2 of the NHST procedure:**\n\nCompute the test statistics.\n\nThe test statistic is a chi-squared of 124.77 with 6 degrees of freedom.\n\n### NHST Step 3\n\nReview and interpret the test statistics: \n\nCalculate the probability that your test statistic is at least as big as it is if there is no relationship (i.e., the null is true).\n\nThe probability computed for the chi-squared was < .001.\n\n\n### NHST Step 4\n\nConclude and write report.\n\n::: {.callout #rep-chap11-mnm1}\n##### Report the conclusion of the interpretation of the multinomial model `mnm1`\n\nWe have to reject the null hypothesis and conclude that a model including age, sex, and age*sex explained job type statistically significantly better [$χ^2(6) = 124.77; p < .001$] than a null model with no predictors.\n:::\n\n### Multinomial model fit\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap11-mnm-fit}\n: Multinomial model fit\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### fit & predict\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-show-fit-predict-values}\n: Show `fitted.values` and `predict()` results\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-show-fit-predict-values}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf1 <- my_glance_data(data.frame(mnm1$fitted.values))\ndf2 <- my_glance_data(data.frame(predicted = stats::predict(mnm1)))\ndplyr::full_join(df1, df2, by = dplyr::join_by(obs))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>     obs CS..Math..Eng Other.Sciences Nonscience      predicted\n#> 1     1     0.4029162      0.2964827  0.3006010  CS, Math, Eng\n#> 2    49     0.3705839      0.3014510  0.3279652  CS, Math, Eng\n#> 3   321     0.4855538      0.2780725  0.2363737  CS, Math, Eng\n#> 4   561     0.2156303      0.3999086  0.3844611 Other Sciences\n#> 5   634     0.1964633      0.4029106  0.4006260 Other Sciences\n#> 6  1098     0.3186954      0.3063952  0.3749094     Nonscience\n#> 7  1170     0.1995693      0.4024774  0.3979533 Other Sciences\n#> 8  1177     0.3547166      0.3033783  0.3419051  CS, Math, Eng\n#> 9  1252     0.2027106      0.4020175  0.3952718 Other Sciences\n#> 10 1500     0.1393026      0.4062125  0.4544848     Nonscience\n```\n\n\n:::\n:::\n\n\nRandom example rows of `fitted.values` to compare with the results from the `predict()` function\n:::\n\n***\n\n- `obs` column: Number of row taken from the sample data `tbl11.2`.\n- The next column are the predicted probability for each person to be in each of the three job type groups. The data are taken from the `fitted-values` result of the multinomial model `mnm1`.\n- The last column predict the job category for each randomly chosen person. This is always the highest probability from the `fitted.values` categories.\n\n::::\n:::::\n\n\n###### observed & predicted\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-compare-observed-predicted}\n: Compare observed job category with the predicted value\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-compare-observed-predicted}  \n\n::: {.cell}\n\n```{.r .cell-code}\n# observed vs. predicted category for each observation\nfit_abs <- base::table(\n  observed = mnm1$model$job_cat,\n  predicted = stats::predict(object = mnm1))\n\nglue::glue(\"Absolute values: observed vs. predicted category for each observation\")\nfit_abs\n\n# observed vs. predicted category for each observation\nfit_perc <- base::proportions(\n  base::table(\n    observed = mnm1$model$job_cat,\n    predicted = predict(object = mnm1)\n            ),\n  margin = 1\n)\n\nglue::glue(\" \")\nglue::glue(\" \")\nglue::glue(\"Percentages: observed vs. predicted category for each observation\")\nfit_perc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Absolute values: observed vs. predicted category for each observation\n#>                 predicted\n#> observed         CS, Math, Eng Other Sciences Nonscience\n#>   CS, Math, Eng            342             66         92\n#>   Other Sciences           206            129        165\n#>   Nonscience               201            112        187\n#>  \n#>  \n#> Percentages: observed vs. predicted category for each observation\n#>                 predicted\n#> observed         CS, Math, Eng Other Sciences Nonscience\n#>   CS, Math, Eng          0.684          0.132      0.184\n#>   Other Sciences         0.412          0.258      0.330\n#>   Nonscience             0.402          0.224      0.374\n```\n\n\n:::\n:::\n\n\nObserved job category versus the predicted value of the model (absolute and percentages)\n:::\n***\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\nThe model was best at predicting the computer science, math, or engineering job type, with 68.4% of the observations in this category correctly predicted. The nonscience job type was predicted with 37.4% accuracy, and other sciences was predicted with 25.8% accuracy. Overall, the model predicted job type correctly for 658 out of 1,500 observations (43.9%). Given that the sample included 500 people from each job type, without any other information, we would guess that everyone was in a single category and would be right for 500, or 33.3%, of the observations. Although the overall correctness was low, it was higher than this baseline probability of correctly classifying observations by job type.\n\n### Multinomial model predictor interpretation\n\nWe know that the model is statistically significantly better than baseline at explaining job type and that the predictions from the model were better than a baseline percentage would be. We also know that the prediction was best for computer science, math, and engineering. The next thing we want to examine is the predictor fit and significance.\n\n#### Predictor significance\n\n@lst-chap11-estimate-multinomial-model does not include any indication of whether or not each predictor (age, sex, age*sex) is statistically significantly associated with job type. To get statistical significance and more interpretable values, we need to compute odds ratios and 95% confidence intervals around the odds ratios.\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap11-predictor-significance}\n: Predictor significance\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Odds ratios\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-odds-ratios}\n: Get odds ratios\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-odds-ratios}\n\n::: {.cell}\n\n```{.r .cell-code}\n# get odds ratios and transpose to get 'standard' format\nbase::t(x = base::exp(x = stats::coef(object = mnm1)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>               Other Sciences Nonscience\n#> (Intercept)        0.3299285  0.1903055\n#> age                1.0168517  1.0288710\n#> sexFemale          3.2876930  4.5780248\n#> age:sexFemale      1.0000501  0.9939356\n```\n\n\n:::\n:::\n\n\nOdds ratios\n\n:::\n\n::: {.callout-caution #cau-chap11-reference-groups}\n##### Watch out for the correct reference group\n\nIt gets more complicated with this type of regression. Not only do the predictors have reference groups, but the outcome variable also has a reference group.\n\n:::\n\nThe reference group for the outcome variable is computer science, math, or engineering. This was not only our result with @lst-chap11-check-levels but it is confirmed by missing this group in the result. (The missing group is always the reference group.)\n\n::::\n:::::\n\n::: {.callout #rep-chap11-example-jobtype-age}\n##### Example of an interpretation of the odds ratios\n\nFor every year older a person gets, the odds of having a career in other sciences is 1.02 times higher compared to the odds of being in computer science, math, or engineering.\n:::\n\n\n###### confidence intervals\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-confidence-intervals}\n: Compute confidence intervals\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-confidence-intervals}  \n\n::: {.cell}\n\n```{.r .cell-code}\n# confidence intervals for odds ratios\nbase::exp(x = stats::confint(object = mnm1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> , , Other Sciences\n#> \n#>                   2.5 %    97.5 %\n#> (Intercept)   0.1934052 0.5628228\n#> age           1.0049003 1.0289451\n#> sexFemale     1.2416783 8.7050932\n#> age:sexFemale 0.9774394 1.0231839\n#> \n#> , , Nonscience\n#> \n#>                   2.5 %     97.5 %\n#> (Intercept)   0.1098584  0.3296623\n#> age           1.0167623  1.0411239\n#> sexFemale     1.7145211 12.2240033\n#> age:sexFemale 0.9715448  1.0168424\n```\n\n\n:::\n:::\n\n\nConfidence intervals for odds ratios\n:::\n\n***\n\nRemember: A confidence interval of odds ratio is statistically significant if it does not include `1`. This is the case for `age` and `Female sex` but not for the interaction term `age:sexFemale`.\n\n::::\n:::::\n\n###### togehter\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap11-odds-ratio-confidence-intervals-table}\n: Put odd ratios and confidence interval together into the same data table\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap11-odds-ratio-confidence-intervals-table}\n\n::: {.cell}\n\n```{.r .cell-code}\n# get odds ratios for other sciences from the model object\noddsratio_other_sci <- \n  base::t(x = base::exp(x = stats::coef(object = mnm1)))[ , 1]\n\n# get CI for other sciences\nconfint_other_sci <- \n  base::exp(x = stats::confint(object = mnm1))[ , 1:2, 1]\n\n# put into a data frame \nother_sci <- base::data.frame(\n  oddsratio_other = oddsratio_other_sci,\n  ci_other = confint_other_sci)\n\n# get odds ratios for non-science\noddsratio_non_sci <- \n  base::t(x = base::exp(x = stats::coef(object = mnm1)))[ , 2]\n\n# get CI for non-science\nconfint_non_sci <- \n  base::exp(x = stats::confint(object = mnm1))[ , 1:2, 2]\n\n# put into a data frame\nnon_sci <- base::data.frame(\n  oddsratio_non = oddsratio_non_sci,\n  ci_non = confint_non_sci)\n\n# all together\ndata.frame(other_sci, non_sci)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>               oddsratio_other ci_other.2.5.. ci_other.97.5.. oddsratio_non\n#> (Intercept)         0.3299285      0.1934052       0.5628228     0.1903055\n#> age                 1.0168517      1.0049003       1.0289451     1.0288710\n#> sexFemale           3.2876930      1.2416783       8.7050932     4.5780248\n#> age:sexFemale       1.0000501      0.9774394       1.0231839     0.9939356\n#>               ci_non.2.5.. ci_non.97.5..\n#> (Intercept)      0.1098584     0.3296623\n#> age              1.0167623     1.0411239\n#> sexFemale        1.7145211    12.2240033\n#> age:sexFemale    0.9715448     1.0168424\n```\n\n\n:::\n:::\n\n\nOdd ratios and confidence intervals of the multinomial model `mnm1`\n:::\n\n***\n\nThe first three columns of numbers are the odds ratios and confidence intervals for the job type of other sciences, while columns 4 through 6 are for the non-science job type.\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n#### Predictor interpretation\n\nThe outcome variable with multiple categories now had a reference group. In this case, the reference group is computer science, math, or engineering job type. The odds ratios are interpreted with respect to this reference group. This works OK for the continuous variable of age but gets a little tricky for the categorical variable of sex, where there are now two reference groups to consider.\n\n::: {.callout #rep-chap11-predictor-interpretation}\n##### Predictor interpretation of the multinomial logistic regression model `mnm1`\n\nThe age row starts with the odds ratio of 1.02 with confidence interval 1.00–1.03. For every 1-year increase in age, the odds of being in an other sciences job are 1.02 times higher than being in a computer science, math, or engineering job ($95% CI: 1.00–1.03$). Likewise, for every 1-year increase in age, the odds of being in a non-science job are 1.03 times higher than being in a computer science, math, or engineering job ($95% CI: 1.02–1.04$). \n\nCompared to males, the odds of females being in an other sciences job are 3.29 times higher than being in a computer science, math, or engineering job ($95% CI: 1.24–8.71$). Also, compared to males, females have 4.58 times higher odds of being in non-science jobs compared to computer science, math, or engineering jobs ($95% CI: 1.71–12.22$). \n\nThe interaction between age and sex was not statistically significant for either other sciences jobs or non-science jobs compared to computer science, math, or engineering jobs.\n\nOverall, it seems that females had higher odds than males of being in other sciences or nonscience compared to being in computer science, math, or engineering. Likewise, the older someone gets, the more likely they are to work in other sciences or non-science compared to computer science, math, or engineering. It seems that, overall, computer science, math, or engineering job types are most likely to be held by males and people who are younger.\n:::\n\n## Achievement 3: Checking assumptions for multinomial logistic regression {#sec-chap11-achievement3}\n\n\n\n## Exercises (empty)\n\n## Glossary\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Chi-squared </td>\n   <td style=\"text-align:left;\"> Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Kruskal-Wallis </td>\n   <td style=\"text-align:left;\"> Kruskal-Wallis test is used to compare ranks across three or more groups when the normal distribution assumption fails for analysis of variance (ANOVA) (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SwR </td>\n   <td style=\"text-align:left;\"> SwR is my abbreviation of: Harris, J. K. (2020). Statistics With R: Solving Problems Using Real-World Data (Illustrated Edition). SAGE Publications, Inc. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Session Info {.unnumbered}\n\n::: my-r-code\n::: my-r-code-header\nSession Info\n:::\n\n::: my-r-code-container\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.4.0 (2024-04-24)\n#>  os       macOS Sonoma 14.4.1\n#>  system   x86_64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Europe/Vienna\n#>  date     2024-05-04\n#>  pandoc   3.1.13 @ /usr/local/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  package     * version    date (UTC) lib source\n#>  base64enc     0.1-3      2015-07-28 [1] CRAN (R 4.4.0)\n#>  class         7.3-22     2023-05-03 [1] CRAN (R 4.4.0)\n#>  cli           3.6.2      2023-12-11 [1] CRAN (R 4.4.0)\n#>  colorspace    2.1-0      2023-01-23 [1] CRAN (R 4.4.0)\n#>  commonmark    1.9.1      2024-01-30 [1] CRAN (R 4.4.0)\n#>  crayon        1.5.2      2022-09-29 [1] CRAN (R 4.4.0)\n#>  curl          5.2.1      2024-03-01 [1] CRAN (R 4.4.0)\n#>  DBI           1.2.2      2024-02-16 [1] CRAN (R 4.4.0)\n#>  digest        0.6.35     2024-03-11 [1] CRAN (R 4.4.0)\n#>  dplyr         1.1.4      2023-11-17 [1] CRAN (R 4.4.0)\n#>  e1071         1.7-14     2023-12-06 [1] CRAN (R 4.4.0)\n#>  evaluate      0.23       2023-11-01 [1] CRAN (R 4.4.0)\n#>  fansi         1.0.6      2023-12-08 [1] CRAN (R 4.4.0)\n#>  farver        2.1.1      2022-07-06 [1] CRAN (R 4.4.0)\n#>  fastmap       1.1.1      2023-02-24 [1] CRAN (R 4.4.0)\n#>  forcats       1.0.0      2023-01-29 [1] CRAN (R 4.4.0)\n#>  generics      0.1.3      2022-07-05 [1] CRAN (R 4.4.0)\n#>  ggplot2       3.5.1      2024-04-23 [1] CRAN (R 4.4.0)\n#>  glossary    * 1.0.0.9003 2024-04-25 [1] Github (debruine/glossary@05e4a61)\n#>  glue          1.7.0      2024-01-09 [1] CRAN (R 4.4.0)\n#>  gtable        0.3.5      2024-04-22 [1] CRAN (R 4.4.0)\n#>  haven         2.5.4      2023-11-30 [1] CRAN (R 4.4.0)\n#>  here          1.0.1      2020-12-13 [1] CRAN (R 4.4.0)\n#>  highr         0.10       2022-12-22 [1] CRAN (R 4.4.0)\n#>  hms           1.1.3      2023-03-21 [1] CRAN (R 4.4.0)\n#>  htmltools     0.5.8.1    2024-04-04 [1] CRAN (R 4.4.0)\n#>  htmlwidgets   1.6.4      2023-12-06 [1] CRAN (R 4.4.0)\n#>  jsonlite      1.8.8      2023-12-04 [1] CRAN (R 4.4.0)\n#>  kableExtra    1.4.0      2024-01-24 [1] CRAN (R 4.4.0)\n#>  knitr         1.46       2024-04-06 [1] CRAN (R 4.4.0)\n#>  labeling      0.4.3      2023-08-29 [1] CRAN (R 4.4.0)\n#>  labelled      2.13.0     2024-04-23 [1] CRAN (R 4.4.0)\n#>  lattice       0.22-6     2024-03-20 [1] CRAN (R 4.4.0)\n#>  lifecycle     1.0.4      2023-11-07 [1] CRAN (R 4.4.0)\n#>  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.4.0)\n#>  markdown      1.12       2023-12-06 [1] CRAN (R 4.4.0)\n#>  MASS          7.3-60.2   2024-04-24 [1] local\n#>  Matrix        1.7-0      2024-03-22 [1] CRAN (R 4.4.0)\n#>  mitools       2.4        2019-04-26 [1] CRAN (R 4.4.0)\n#>  munsell       0.5.1      2024-04-01 [1] CRAN (R 4.4.0)\n#>  nnet          7.3-19     2023-05-03 [1] CRAN (R 4.4.0)\n#>  pillar        1.9.0      2023-03-22 [1] CRAN (R 4.4.0)\n#>  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.4.0)\n#>  proxy         0.4-27     2022-06-09 [1] CRAN (R 4.4.0)\n#>  purrr         1.0.2      2023-08-10 [1] CRAN (R 4.4.0)\n#>  R6            2.5.1      2021-08-19 [1] CRAN (R 4.4.0)\n#>  Rcpp          1.0.12     2024-01-09 [1] CRAN (R 4.4.0)\n#>  repr          1.1.7      2024-03-22 [1] CRAN (R 4.4.0)\n#>  rlang         1.1.3      2024-01-10 [1] CRAN (R 4.4.0)\n#>  rmarkdown     2.26       2024-03-05 [1] CRAN (R 4.4.0)\n#>  rprojroot     2.0.4      2023-11-05 [1] CRAN (R 4.4.0)\n#>  rstudioapi    0.16.0     2024-03-24 [1] CRAN (R 4.4.0)\n#>  rversions     2.1.2      2022-08-31 [1] CRAN (R 4.4.0)\n#>  scales        1.3.0      2023-11-28 [1] CRAN (R 4.4.0)\n#>  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.4.0)\n#>  skimr         2.1.5      2022-12-23 [1] CRAN (R 4.4.0)\n#>  stringi       1.8.3      2023-12-11 [1] CRAN (R 4.4.0)\n#>  stringr       1.5.1      2023-11-14 [1] CRAN (R 4.4.0)\n#>  survey        4.4-2      2024-03-20 [1] CRAN (R 4.4.0)\n#>  survival      3.6-4      2024-04-24 [1] CRAN (R 4.4.0)\n#>  svglite       2.1.3      2023-12-08 [1] CRAN (R 4.4.0)\n#>  systemfonts   1.0.6      2024-03-07 [1] CRAN (R 4.4.0)\n#>  tableone      0.13.2     2022-04-15 [1] CRAN (R 4.4.0)\n#>  tibble        3.2.1      2023-03-20 [1] CRAN (R 4.4.0)\n#>  tidyr         1.3.1      2024-01-24 [1] CRAN (R 4.4.0)\n#>  tidyselect    1.2.1      2024-03-11 [1] CRAN (R 4.4.0)\n#>  utf8          1.2.4      2023-10-22 [1] CRAN (R 4.4.0)\n#>  vctrs         0.6.5      2023-12-01 [1] CRAN (R 4.4.0)\n#>  viridisLite   0.4.2      2023-05-02 [1] CRAN (R 4.4.0)\n#>  withr         3.0.0      2024-01-16 [1] CRAN (R 4.4.0)\n#>  xfun          0.43       2024-03-25 [1] CRAN (R 4.4.0)\n#>  xml2          1.3.6      2023-12-04 [1] CRAN (R 4.4.0)\n#>  yaml          2.3.8      2023-12-11 [1] CRAN (R 4.4.0)\n#>  zoo           1.8-12     2023-04-13 [1] CRAN (R 4.4.0)\n#> \n#>  [1] /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n:::\n:::\n",
    "supporting": [
      "11-multinomial-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}