{
  "hash": "4498653b340bcb715a5965a9c1539c65",
  "result": {
    "engine": "knitr",
    "markdown": "# t-test {#sec-chap06}\n\n\n\n\n\n## Achievements to unlock\n\n::: my-objectives\n::: my-objectives-header\nObjectives\n:::\n\n::: my-objectives-container\n**SwR Achievements**\n\n- **Achievement 1**: Understanding the relationship between one categorical variable and one continuous variable using histograms, means, and standard deviations (@sec-chap06-achievement1)\n- **Achievement 2**: Comparing a sample mean to a population mean with a <a class='glossary' title='One-sample t-test, also known as the single-parameter t-test or single-sample t-test, is an inferential statistical test comparing the mean of a numeric variable to a population or hypothesized mean. (SwR, Glossary)'>one-sample t-test</a> (@sec-chap06-achievement2)\n- **Achievement 3**: Comparing two unrelated sample means with an <a class='glossary' title='Independent-samples t-test or unpaired sample t-test is an inferential test comparing two independent means. (SwR, Glossary)'>independent-samples t-test</a> (@sec-chap06-achievement3)\n- **Achievement 4**: Comparing two related sample means with a <a class='glossary' title='Dependent-samples test or paired-samples t-test is an inferential test comparing two related means . (SwR, Glossary)'>dependent-samples t-test</a> (@sec-chap06-achievement4)\n- **Achievement 5**: Computing and interpreting an <a class='glossary' title='Effect size is a measure of the strength of a relationship; effect sizes are important in inferential statistics in order to determine and communicate whether a statistically significant result has practical importance. (SwR, Glossary)'>effect size</a> for significant t-tests (@sec-chap06-achievement5)\n- **Achievement 6**: Examining and checking the underlying assumptions for using the t-test (@sec-chap06-achievement6)\n- **Achievement 7**: Identifying and using alternate tests when t-test assumptions are not met (@sec-chap06-achievement7)\n\n:::\n:::\n\n\n## The blood pressure predicament\n\n- **Systolic blood pressure** is measured in millimeters of mercury, or mmHG, and ranges from 74 to 238.\n- **Diastolic blood pressure** is also measured in mmHG and ranges from 0 to 120.\n\n## Resources & Chapter Outline\n\n### Data, codebook, and R packages {#sec-chap04-data-codebook-packages}\n\n::: my-resource\n::: my-resource-header\nData, codebook, and R packages for learning about t-test\n:::\n\n::: my-resource-container\n\n**Data**\n\nTwo options for accessing the data:\n\n- Download the data set `nhanes_2015–2016_ch6.csv` from <https://edge.sagepub.com/harris1e>. \n- Follow the instructions in Box 6.1 to import the data directly with the halp of {**NHANES**} from the Internet into R.\n\n**Codebook**\n\nTwo options for accessing the codebook:\n\n- Download the codebook files `nhanes_demographics_20152016_codebook.html` and `nhanes_examination_20152016_codebook.html` from <https://edge.sagepub.com/harris1e>.  \n- Use the online version of the codebook on the NHANES website (https://www.cdc.gov/nchs/nhanes/index.htm)\n\n**Packages**\n\n1. Packages used with the book (sorted alphabetically)\n\n-   {**BSDA**} @pak-bsda (Alan T. Arnholt) \n-   {**car**} @pak-car (John Fox)\n-   {**lsr**} @pak-lsr (Danielle Navarro)  \n-   {**rcompanion**} @pak-rcompanion (Salvatore Mangiafico)\n-   {**RNHANES**} @pak-RNHANES (Herb Susmann) \n-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)\n\n    \n2. My additional packages (sorted alphabetically)\n\n\n\n:::\n:::\n\n### Get data\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-get-data}\n: Numbered Example Title\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### NHANES data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-get-nhanes-data}\n: Get NHANES data for blood pressure examination with demographics variable for 2015-2016\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n## run one once manually #########\n\n## list EXAM tables for 2016 to get file names\nexam_tables_2016 <- nhanesA::nhanesTables('EXAM', 2016)\n\n## list variables in BPX_I (Blood Pressure file)\nbpx_i_variables <- nhanesA::nhanesTableVars('EXAM', 'BPX_I')\n\nbpx_i <- nhanesA::nhanes('BPX_I')\ndemo_i <-  nhanesA::nhanes('DEMO_I')\n\nbpx_2016 <- dplyr::full_join(demo_i, bpx_i, by = \"SEQN\")\n\nsave_data_file(\"chap06\", bpx_2016, \"bpx_2016.rds\")\n```\n:::\n\n\n(*For this R code chunk is no output available. For the raw data see *)\n\n::::\n:::::\n\n\n###### NHANES codebook\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-get-nhanes-codebook}\n: Get NHANES codebook for blood pressure examination with demographics variable for 2015-2016\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncb_systolic <- nhanesA::nhanesCodebook(\"BPX_I\", \"BPXSY1\")\ncb_diastolic <- nhanesA::nhanesCodebook(\"BPX_I\", \"BPXDI1\")\n```\n:::\n\n\n***\n\n(*For this R code chunk is no output available. For the raw data see*)\n\nBesides to call the appropriate website for 2015-2016 [examination codebook](nhanes_examination_20152016_codebook.html) and [demographic codebook](nhanes_demographics_20152016_codebook.html) there is also the option to download information via {**nhanesA**}.\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n\n\n\n### Show raw data \n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-show-raw-data}\n: Numbered Example Title\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Blood pressure data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-glance-nhanes-data}\n: Glance at NHANES data for blood pressure examination with demographics variable for 2015-2016\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-glance-nhanes-data}\n\n::: {.cell}\n\n```{.r .cell-code}\nbpx_2016 <- base::readRDS(\"data/chap06/bpx_2016.rds\")\n\nskimr::skim(bpx_2016)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |         |\n|:------------------------|:--------|\n|Name                     |bpx_2016 |\n|Number of rows           |9971     |\n|Number of columns        |67       |\n|_______________________  |         |\n|Column type frequency:   |         |\n|factor                   |45       |\n|numeric                  |22       |\n|________________________ |         |\n|Group variables          |None     |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                                 |\n|:-------------|---------:|-------------:|:-------|--------:|:------------------------------------------|\n|RIDSTATR      |         0|          1.00|FALSE   |        2|Bot: 9544, Int: 427                        |\n|RIAGENDR      |         0|          1.00|FALSE   |        2|Fem: 5079, Mal: 4892                       |\n|RIDRETH1      |         0|          1.00|FALSE   |        5|Non: 3066, Non: 2129, Mex: 1921, Oth: 1547 |\n|RIDRETH3      |         0|          1.00|FALSE   |        6|Non: 3066, Non: 2129, Mex: 1921, Oth: 1308 |\n|RIDEXMON      |       427|          0.96|FALSE   |        2|May: 4950, Nov: 4594                       |\n|DMQMILIZ      |      3822|          0.62|FALSE   |        2|No: 5622, Yes: 527                         |\n|DMQADFC       |      9444|          0.05|FALSE   |        3|No: 267, Yes: 258, Ref: 2                  |\n|DMDBORN4      |         0|          1.00|FALSE   |        3|Bor: 7733, Oth: 2236, Don: 2               |\n|DMDCITZN      |         2|          1.00|FALSE   |        4|Cit: 8785, Not: 1168, Ref: 9, Don: 7       |\n|DMDYRSUS      |      7735|          0.22|FALSE   |       11|20 : 384, 10 : 285, 30 : 281, 1 y: 273     |\n|DMDEDUC3      |      7324|          0.27|FALSE   |       19|1st: 252, Nev: 239, 2nd: 237, 3rd: 220     |\n|DMDEDUC2      |      4252|          0.57|FALSE   |        6|Som: 1692, Col: 1422, Hig: 1236, Les: 688  |\n|DMDMARTL      |      4252|          0.57|FALSE   |        8|Mar: 2886, Nev: 1048, Div: 614, Liv: 555   |\n|RIDEXPRG      |      8683|          0.13|FALSE   |        3|The: 1125, Can: 93, Yes: 70                |\n|SIALANG       |         0|          1.00|FALSE   |        2|Eng: 8584, Spa: 1387                       |\n|SIAPROXY      |         1|          1.00|FALSE   |        2|No: 6281, Yes: 3689                        |\n|SIAINTRP      |         0|          1.00|FALSE   |        2|No: 9514, Yes: 457                         |\n|FIALANG       |       329|          0.97|FALSE   |        2|Eng: 8430, Spa: 1212                       |\n|FIAPROXY      |       329|          0.97|FALSE   |        2|No: 9633, Yes: 9                           |\n|FIAINTRP      |       329|          0.97|FALSE   |        2|No: 9237, Yes: 405                         |\n|MIALANG       |      2994|          0.70|FALSE   |        2|Eng: 6382, Spa: 595                        |\n|MIAPROXY      |      2993|          0.70|FALSE   |        2|No: 6921, Yes: 57                          |\n|MIAINTRP      |      2993|          0.70|FALSE   |        2|No: 6632, Yes: 346                         |\n|AIALANGA      |      4009|          0.60|FALSE   |        3|Eng: 5218, Spa: 638, Asi: 106              |\n|DMDHHSIZ      |         0|          1.00|FALSE   |        7|4: 2061, 2: 1723, 3: 1719, 5: 1672         |\n|DMDFMSIZ      |         0|          1.00|FALSE   |        7|4: 2011, 5: 1635, 3: 1634, 2: 1510         |\n|DMDHHSZA      |         0|          1.00|FALSE   |        4|0: 6298, 1: 2147, 2: 1199, 3 o: 327        |\n|DMDHHSZB      |         0|          1.00|FALSE   |        5|0: 4715, 1: 1990, 2: 1833, 3: 822          |\n|DMDHHSZE      |         0|          1.00|FALSE   |        4|0: 7151, 1: 1663, 2: 1099, 3 o: 58         |\n|DMDHRGND      |         0|          1.00|FALSE   |        2|Mal: 5053, Fem: 4918                       |\n|DMDHRBR4      |       396|          0.96|FALSE   |        4|Bor: 6359, Oth: 3207, Ref: 5, Don: 4       |\n|DMDHREDU      |       396|          0.96|FALSE   |        6|Som: 2908, Col: 2331, Hig: 2015, 9-1: 1200 |\n|DMDHRMAR      |        62|          0.99|FALSE   |        8|Mar: 5681, Nev: 1305, Liv: 1017, Div: 977  |\n|DMDHSEDU      |      4745|          0.52|FALSE   |        7|Col: 1629, Som: 1462, Hig: 980, Les: 619   |\n|INDHHIN2      |       345|          0.97|FALSE   |       16|$10: 1634, $25: 1017, $35: 960, $75: 920   |\n|INDFMIN2      |       329|          0.97|FALSE   |       16|$10: 1548, $25: 1038, $35: 934, $75: 885   |\n|PEASCCT1      |      9735|          0.02|FALSE   |        3|Tim: 178, Oth: 46, SP : 12                 |\n|BPAARM        |      2573|          0.74|FALSE   |        3|Rig: 7361, Lef: 36, Cou: 1                 |\n|BPACSZ        |      2585|          0.74|FALSE   |        5|Lar: 3368, Adu: 2461, Thi: 1068, Chi: 488  |\n|BPXPULS       |       657|          0.93|FALSE   |        2|Reg: 9113, Irr: 201                        |\n|BPXPTY        |      2595|          0.74|FALSE   |        2|Rad: 7348, Bra: 28                         |\n|BPAEN1        |      2826|          0.72|FALSE   |        2|No: 7142, Yes: 3                           |\n|BPAEN2        |      2658|          0.73|FALSE   |        2|No: 7130, Yes: 183                         |\n|BPAEN3        |      2695|          0.73|FALSE   |        2|No: 7070, Yes: 206                         |\n|BPAEN4        |      9647|          0.03|FALSE   |        2|No: 248, Yes: 76                           |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|     mean|       sd|       p0|      p25|      p50|      p75|     p100|hist  |\n|:-------------|---------:|-------------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|:-----|\n|SEQN          |         0|          1.00| 88717.00|  2878.52| 83732.00| 86224.50| 88717.00| 91209.50|  93702.0|▇▇▇▇▇ |\n|SDDSRVYR      |         0|          1.00|     9.00|     0.00|     9.00|     9.00|     9.00|     9.00|      9.0|▁▁▇▁▁ |\n|RIDAGEYR      |         0|          1.00|    31.90|    24.77|     0.00|     9.00|    27.00|    53.00|     80.0|▇▃▃▃▃ |\n|RIDAGEMN      |      9276|          0.07|    10.79|     7.02|     0.00|     5.00|    10.00|    17.00|     24.0|▇▇▆▆▅ |\n|RIDEXAGM      |      5911|          0.41|   104.53|    68.97|     0.00|    41.00|   100.00|   162.00|    239.0|▇▆▆▅▅ |\n|DMDHRAGE      |         0|          1.00|    46.18|    15.83|    18.00|    34.00|    44.00|    57.00|     80.0|▅▇▆▃▃ |\n|WTINT2YR      |         0|          1.00| 31740.15| 32929.54|  3293.93| 12878.50| 20160.47| 33257.36| 233755.8|▇▁▁▁▁ |\n|WTMEC2YR      |         0|          1.00| 31740.15| 34105.57|     0.00| 12550.53| 20281.32| 33708.15| 242386.7|▇▁▁▁▁ |\n|SDMVPSU       |         0|          1.00|     1.49|     0.50|     1.00|     1.00|     1.00|     2.00|      2.0|▇▁▁▁▇ |\n|SDMVSTRA      |         0|          1.00|   126.27|     4.24|   119.00|   123.00|   126.00|   130.00|    133.0|▇▇▇▇▇ |\n|INDFMPIR      |      1052|          0.89|     2.27|     1.58|     0.00|     0.97|     1.82|     3.48|      5.0|▇▇▅▃▆ |\n|BPXCHR        |      8033|          0.19|   106.56|    21.76|    58.00|    90.00|   104.00|   120.00|    190.0|▃▇▅▂▁ |\n|BPXPLS        |      2595|          0.74|    74.61|    12.23|    36.00|    66.00|    74.00|    82.00|    142.0|▁▇▃▁▁ |\n|BPXML1        |      2600|          0.74|   146.60|    18.56|   110.00|   130.00|   140.00|   160.00|    260.0|▇▅▁▁▁ |\n|BPXSY1        |      2826|          0.72|   120.54|    18.62|    72.00|   108.00|   118.00|   130.00|    236.0|▂▇▂▁▁ |\n|BPXDI1        |      2826|          0.72|    66.18|    14.29|     0.00|    58.00|    66.00|    76.00|    120.0|▁▁▇▅▁ |\n|BPXSY2        |      2658|          0.73|   120.32|    18.62|    76.00|   108.00|   118.00|   130.00|    238.0|▃▇▂▁▁ |\n|BPXDI2        |      2658|          0.73|    66.06|    14.37|     0.00|    58.00|    66.00|    76.00|    144.0|▁▂▇▁▁ |\n|BPXSY3        |      2695|          0.73|   119.95|    18.29|    76.00|   108.00|   116.00|   130.00|    226.0|▃▇▂▁▁ |\n|BPXDI3        |      2695|          0.73|    65.99|    14.56|     0.00|    58.00|    66.00|    76.00|    140.0|▁▂▇▁▁ |\n|BPXSY4        |      9647|          0.03|   129.10|    22.88|    82.00|   112.00|   128.00|   142.50|    212.0|▃▇▅▁▁ |\n|BPXDI4        |      9647|          0.03|    70.38|    18.62|     0.00|    62.00|    72.00|    80.00|    132.0|▁▁▇▃▁ |\n\n\n:::\n\n```{.r .cell-code}\nglance_data(bpx_2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>     obs  SEQN SDDSRVYR                          RIDSTATR RIAGENDR RIDAGEYR\n#> 1     1 83732        9 Both interviewed and MEC examined     Male       62\n#> 2   356 84087        9 Both interviewed and MEC examined     Male       36\n#> 3  1252 84983        9                  Interviewed only   Female       10\n#> 4  2369 86100        9 Both interviewed and MEC examined     Male       33\n#> 5  3954 87685        9 Both interviewed and MEC examined   Female        1\n#> 6  5273 89004        9 Both interviewed and MEC examined   Female        0\n#> 7  7700 91431        9                  Interviewed only   Female       47\n#> 8  8826 92557        9 Both interviewed and MEC examined     Male       71\n#> 9  9290 93021        9 Both interviewed and MEC examined   Female       18\n#> 10 9971 93702        9 Both interviewed and MEC examined   Female       24\n#>    RIDAGEMN                            RIDRETH1           RIDRETH3\n#> 1        NA                  Non-Hispanic White Non-Hispanic White\n#> 2        NA Other Race - Including Multi-Racial Non-Hispanic Asian\n#> 3        NA                  Non-Hispanic Black Non-Hispanic Black\n#> 4        NA                    Mexican American   Mexican American\n#> 5        22 Other Race - Including Multi-Racial Non-Hispanic Asian\n#> 6         3                    Mexican American   Mexican American\n#> 7        NA                      Other Hispanic     Other Hispanic\n#> 8        NA Other Race - Including Multi-Racial Non-Hispanic Asian\n#> 9        NA                    Mexican American   Mexican American\n#> 10       NA                  Non-Hispanic White Non-Hispanic White\n#>                       RIDEXMON RIDEXAGM DMQMILIZ DMQADFC\n#> 1  November 1 through April 30       NA       No    <NA>\n#> 2  November 1 through April 30       NA       No    <NA>\n#> 3                         <NA>       NA     <NA>    <NA>\n#> 4  November 1 through April 30       NA       No    <NA>\n#> 5     May 1 through October 31       23     <NA>    <NA>\n#> 6  November 1 through April 30        3     <NA>    <NA>\n#> 7                         <NA>       NA       No    <NA>\n#> 8     May 1 through October 31       NA       No    <NA>\n#> 9  November 1 through April 30      226       No    <NA>\n#> 10    May 1 through October 31       NA       No    <NA>\n#>                                  DMDBORN4                           DMDCITZN\n#> 1  Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#> 2                                  Others            Not a citizen of the US\n#> 3  Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#> 4                                  Others            Not a citizen of the US\n#> 5  Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#> 6  Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#> 7  Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#> 8                                  Others Citizen by birth or naturalization\n#> 9  Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#> 10 Born in 50 US states or Washington, DC Citizen by birth or naturalization\n#>                                   DMDYRSUS             DMDEDUC3\n#> 1                                     <NA>                 <NA>\n#> 2  15 year or more, but less than 20 years                 <NA>\n#> 3                                     <NA>            3rd grade\n#> 4  10 year or more, but less than 15 years                 <NA>\n#> 5                                     <NA>                 <NA>\n#> 6                                     <NA>                 <NA>\n#> 7                                     <NA>                 <NA>\n#> 8    1 year or more, but less than 5 years                 <NA>\n#> 9                                     <NA> High school graduate\n#> 10                                    <NA>                 <NA>\n#>                                              DMDEDUC2            DMDMARTL\n#> 1                           College graduate or above             Married\n#> 2                           College graduate or above Living with partner\n#> 3                                                <NA>                <NA>\n#> 4  9-11th grade (Includes 12th grade with no diploma)             Married\n#> 5                                                <NA>                <NA>\n#> 6                                                <NA>                <NA>\n#> 7                           College graduate or above           Separated\n#> 8  9-11th grade (Includes 12th grade with no diploma)             Married\n#> 9                                                <NA>                <NA>\n#> 10                          College graduate or above       Never married\n#>                                    RIDEXPRG SIALANG SIAPROXY SIAINTRP FIALANG\n#> 1                                      <NA> English       No       No English\n#> 2                                      <NA> English       No       No English\n#> 3                                      <NA> English      Yes       No English\n#> 4                                      <NA> Spanish       No       No Spanish\n#> 5                                      <NA> English      Yes      Yes English\n#> 6                                      <NA> English      Yes       No English\n#> 7                                      <NA> English       No       No English\n#> 8                                      <NA> English       No      Yes    <NA>\n#> 9                                      <NA> English       No       No English\n#> 10 The participant was not pregnant at exam English       No       No English\n#>    FIAPROXY FIAINTRP MIALANG MIAPROXY MIAINTRP AIALANGA\n#> 1        No       No English       No       No  English\n#> 2        No       No English       No       No  English\n#> 3        No       No    <NA>     <NA>     <NA>     <NA>\n#> 4        No       No English       No       No  Spanish\n#> 5        No      Yes    <NA>     <NA>     <NA>     <NA>\n#> 6        No       No    <NA>     <NA>     <NA>     <NA>\n#> 7        No       No    <NA>     <NA>     <NA>     <NA>\n#> 8      <NA>     <NA> English       No      Yes     <NA>\n#> 9        No       No English       No       No  English\n#> 10       No       No English       No       No  English\n#>                             DMDHHSIZ                       DMDFMSIZ  DMDHHSZA\n#> 1                                  2                              2         0\n#> 2                                  4                              4         0\n#> 3                                  2                              2         0\n#> 4                                  6                              6         1\n#> 5                                  5                              5 3 or more\n#> 6  7 or more people in the Household 7 or more people in the Family         2\n#> 7                                  4                              4         1\n#> 8                                  3                              3         0\n#> 9                                  4                              1         0\n#> 10                                 3                              1         0\n#>    DMDHHSZB DMDHHSZE DMDHRGND DMDHRAGE                               DMDHRBR4\n#> 1         0        1     Male       62 Born in 50 US states or Washington, DC\n#> 2         2        0     Male       36                                 Others\n#> 3         1        0   Female       35 Born in 50 US states or Washington, DC\n#> 4         3        0   Female       36                                 Others\n#> 5         0        0     Male       37                                 Others\n#> 6         1        0     Male       37                                 Others\n#> 7         0        0   Female       23 Born in 50 US states or Washington, DC\n#> 8         0        1     Male       71                                 Others\n#> 9         0        0   Female       26                                   <NA>\n#> 10        0        0   Female       22 Born in 50 US states or Washington, DC\n#>                                              DMDHREDU            DMDHRMAR\n#> 1                           College Graduate or above             Married\n#> 2                           College Graduate or above Living with partner\n#> 3                           Some College or AA degree       Never married\n#> 4  9-11th Grade (Includes 12th grade with no diploma)             Married\n#> 5                  High School Grad/GED or Equivalent             Married\n#> 6                                 Less Than 9th Grade             Married\n#> 7                  High School Grad/GED or Equivalent Living with partner\n#> 8  9-11th Grade (Includes 12th grade with no diploma)             Married\n#> 9                                                <NA>       Never married\n#> 10                          College Graduate or above       Never married\n#>                                              DMDHSEDU   WTINT2YR   WTMEC2YR\n#> 1                  High School Grad/GED or Equivalent 134671.370 135629.507\n#> 2                                                <NA>  18448.501  18550.188\n#> 3                                                <NA>  14840.527      0.000\n#> 4  9-11th Grade (Includes 12th grade with no diploma)  26689.378  27745.104\n#> 5                  High School Grad/GED or Equivalent   8860.151   8793.912\n#> 6                                 Less Than 9th Grade   5454.854   5610.739\n#> 7                                                <NA>  19288.330      0.000\n#> 8                                                <NA>  19926.979  25066.422\n#> 9                                                <NA>  16127.645  16401.812\n#> 10                                               <NA> 107361.907 105080.445\n#>    SDMVPSU SDMVSTRA           INDHHIN2           INDFMIN2 INDFMPIR PEASCCT1\n#> 1        1      125 $65,000 to $74,999 $65,000 to $74,999     4.39     <NA>\n#> 2        1      133  $100,000 and Over  $100,000 and Over     5.00     <NA>\n#> 3        2      132 $15,000 to $19,999 $15,000 to $19,999     0.94     <NA>\n#> 4        1      128 $15,000 to $19,999 $15,000 to $19,999     0.48     <NA>\n#> 5        1      122 $15,000 to $19,999 $15,000 to $19,999     0.63     <NA>\n#> 6        2      121 $55,000 to $64,999 $55,000 to $64,999     1.50     <NA>\n#> 7        1      121 $35,000 to $44,999 $35,000 to $44,999     1.65     <NA>\n#> 8        1      129               <NA>               <NA>       NA     <NA>\n#> 9        2      128 $45,000 to $54,999 $ 5,000 to $ 9,999     0.59     <NA>\n#> 10       2      119 $65,000 to $74,999 $35,000 to $44,999     3.54     <NA>\n#>    BPXCHR BPAARM        BPACSZ BPXPLS BPXPULS BPXPTY BPXML1 BPXSY1 BPXDI1\n#> 1      NA  Right Large (15X32)     76 Regular Radial    150    128     70\n#> 2      NA  Right Adult (12X22)     46 Regular Radial    160    122     80\n#> 3      NA   <NA>          <NA>     NA    <NA>   <NA>     NA     NA     NA\n#> 4      NA  Right Large (15X32)     68 Regular Radial    150    116     70\n#> 5     110   <NA>          <NA>     NA Regular   <NA>     NA     NA     NA\n#> 6     122   <NA>          <NA>     NA Regular   <NA>     NA     NA     NA\n#> 7      NA   <NA>          <NA>     NA    <NA>   <NA>     NA     NA     NA\n#> 8      NA  Right Adult (12X22)     72 Regular Radial    140    112     80\n#> 9      NA  Right  Child (9X17)     74 Regular Radial    120    100     74\n#> 10     NA  Right Adult (12X22)     80 Regular Radial    150    118     66\n#>    BPAEN1 BPXSY2 BPXDI2 BPAEN2 BPXSY3 BPXDI3 BPAEN3 BPXSY4 BPXDI4 BPAEN4\n#> 1      No    124     64     No    116     62     No     NA     NA   <NA>\n#> 2      No    128     82     No    122     86     No     NA     NA   <NA>\n#> 3    <NA>     NA     NA   <NA>     NA     NA   <NA>     NA     NA   <NA>\n#> 4      No    124     66     No    116     66     No     NA     NA   <NA>\n#> 5    <NA>     NA     NA   <NA>     NA     NA   <NA>     NA     NA   <NA>\n#> 6    <NA>     NA     NA   <NA>     NA     NA   <NA>     NA     NA   <NA>\n#> 7    <NA>     NA     NA   <NA>     NA     NA   <NA>     NA     NA   <NA>\n#> 8      No    118     78     No    122     80     No     NA     NA   <NA>\n#> 9      No    100     66     No     98     68     No     NA     NA   <NA>\n#> 10     No    114     68     No    124     64     No     NA     NA   <NA>\n```\n\n\n:::\n:::\n\nGlance at NHANES data for blood pressure examination with demographics variable for 2015-2016\n\n:::\n\n::::\n:::::\n\n\n\n###### Blood pressure codebook\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-glance-nhanes-codebook}\n: Glance at NHANES codebook for systolic & diastolic blood pressure (2015-2016)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglue::glue(\"*********************** Systolic blood pressure ******************\")\ncb_systolic\nglue::glue(\" \")\nglue::glue(\"*********************** Diastolic blood pressure ******************\")\ncb_diastolic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> *********************** Systolic blood pressure ******************\n#> $`Variable Name:`\n#> [1] \"BPXSY1\"\n#> \n#> $`SAS Label:`\n#> [1] \"Systolic: Blood pres (1st rdg) mm Hg\"\n#> \n#> $`English Text:`\n#> [1] \"Systolic: Blood pressure (first reading) mm Hg\"\n#> \n#> $`Target:`\n#> [1] \"Both males and females 8 YEARS -\\r 150 YEARS\"\n#> \n#> $BPXSY1\n#> # A tibble: 2 × 5\n#>   `Code or Value` `Value Description` Count Cumulative `Skip to Item`\n#>   <chr>           <chr>               <int>      <int> <lgl>         \n#> 1 72 to 236       Range of Values      7145       7145 NA            \n#> 2 .               Missing              2399       9544 NA            \n#> \n#>  \n#> *********************** Diastolic blood pressure ******************\n#> $`Variable Name:`\n#> [1] \"BPXDI1\"\n#> \n#> $`SAS Label:`\n#> [1] \"Diastolic: Blood pres (1st rdg) mm Hg\"\n#> \n#> $`English Text:`\n#> [1] \"Diastolic: Blood pressure (first reading) mm Hg\"\n#> \n#> $`Target:`\n#> [1] \"Both males and females 8 YEARS -\\r 150 YEARS\"\n#> \n#> $BPXDI1\n#> # A tibble: 2 × 5\n#>   `Code or Value` `Value Description` Count Cumulative `Skip to Item`\n#>   <chr>           <chr>               <int>      <int> <lgl>         \n#> 1 0 to 120        Range of Values      7145       7145 NA            \n#> 2 .               Missing              2399       9544 NA\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n\n\n### Recode data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-clean-data}\n: Clean NHANES blood pressure data (2015-2016)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n## load bpx_2016 #######\nbpx_2016 <- base::readRDS(\"data/chap06/bpx_2016.rds\")\n\nbp_clean <-  bpx_2016 |> \n    dplyr::rename(\n        systolic = BPXSY1,\n        systolic2 = BPXSY2,\n        sex = RIAGENDR\n        ) |> \n    dplyr::mutate(diff_syst = systolic - systolic2) |> \n    dplyr::relocate(c(systolic, systolic2, diff_syst), .before = sex)\n\nsave_data_file(\"chap06\", bp_clean, \"bp_clean.rds\")\n```\n:::\n\n\n***\n(*For this R code chunk is no output available*)\n::::\n:::::\n\n\n## Achievement 1: Relationship between one categorical and one continuous variable {#sec-chap06-achievement1}\n\nFor this first achievement we are going to look into the relationship between one categorical variable and one continuous variable using histograms, means, and standard deviations.\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-descriptive}\n: Description of blood pressure data from NHANES 2015-2016\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Histogram 1\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-systolic-histo1}\n: Histogram of systolic blood pressure (NHANES 2015-2016)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## load bpx_2016 #######\nbpx_2016 <- base::readRDS(\"data/chap06/bpx_2016.rds\")\n\n## graph systolic blood pressure variable BPXSY1 (Figure 6.1)\nsys_histo <- bpx_2016  |>  \n    ggplot2::ggplot(\n        ggplot2::aes(x = BPXSY1)\n        ) + \n    ggplot2::geom_histogram(\n        fill =  \"mediumpurple\",\n        color = \"white\",\n        bins = 30,\n        na.rm = TRUE\n        ) + \n    ggplot2::theme_bw() + \n    ggplot2::labs(\n        x = \"Systolic blood pressure (mmHg)\", \n        y = \"NHANES participants\"\n        ) \n\nsys_histo\n```\n\n::: {.cell-output-display}\n![Histogram of systolic blood pressure (NHANES 2015-2016)](06-t-test_files/figure-html/systolic-histo1-1.png){width=672}\n:::\n:::\n\n***\n\nThis is the replication of the book’s Figure 6.1.\n\nThe graph is not exactly normally distributed; it has a little right skew.  The <a class='glossary' title='Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities (Wikipedia)'>quantile</a> values (0%  25%  50%  75%  100%) are 72, 108, 118, 130, 236. The middle 50% lies in the range between 108 and 130 mmHG. You can't see the highest values because their frequencies are too small.  \n::::\n:::::\n\n\n###### Histogram 2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-systolic-histo2}\n: Histogram of systolic blood pressure with risk factors (NHANES 2015-2016)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## graph systolic blood pressure with risk factors (Figure 6.2)\nsys_histo2 <- bpx_2016 |>  \n    ggplot2::ggplot(\n        ggplot2::aes(\n            x = BPXSY1, \n            fill = BPXSY1 > 120)\n        ) + \n    ggplot2::geom_histogram(\n        color = \"white\",\n        bins = 30,\n        na.rm = TRUE) + \n    ggplot2::theme_bw() + \n    ggplot2::labs(\n        x = \"Systolic blood pressure (mmHg)\", \n        y = \"NHANES participants\"\n        ) +\n    ggplot2::scale_fill_manual(\n        values = c(\"mediumpurple\", \"grey\"),\n        labels = c(\"Normal range\",\n                   \"at-risk or high\"),\n        name = \"Systolic\\nBlood Pressure\"\n    )\n\nsys_histo2\n```\n\n::: {.cell-output-display}\n![Histogram of systolic blood pressure with risk factors (NHANES 2015-2016)](06-t-test_files/figure-html/systolic-histo2-1.png){width=672}\n:::\n:::\n\n***\n\nThis is the replication of the book’s Figure 6.2.\n::::\n:::::\n\n###### Experiment\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-systolic-histo3}\n: Blood pressure histogram with several colors according to their medical conditions\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## graph systolic blood pressure differentiated\nsys_histo3 <- bpx_2016 |>  \n    dplyr::select(BPXSY1) |> \n    dplyr::mutate(sys = dplyr::case_when(\n        BPXSY1 < 105 ~ \"0\",\n        BPXSY1 >= 105 & BPXSY1 < 120 ~ \"1\",\n        BPXSY1 >= 120 & BPXSY1 < 130 ~ \"2\",\n        BPXSY1 >= 130 & BPXSY1 < 140 ~ \"3\",\n        BPXSY1 >= 140 ~ \"4\"\n        )\n    ) |> \n    ggplot2::ggplot(\n        ggplot2::aes(x = BPXSY1, fill = sys)\n        ) + \n    ggplot2::geom_histogram(\n        color = \"white\",\n        binwidth = 2,\n        na.rm = TRUE) + \n    ggplot2::theme_bw() + \n    ggplot2::theme(legend.position = \"bottom\") +\n    ggplot2::labs(\n        x = \"Systolic blood pressure (mmHg)\", \n        y = \"NHANES participants\"\n        ) +\n    ggplot2::scale_fill_manual(\n        values = c(\n            \"0\" = \"grey\", \n            \"1\" = \"mediumpurple\", \n            \"2\" = \"yellow\", \n            \"3\" = \"darkorange\", \n            \"4\" = \"red\"\n            ),\n        labels = c(\"Low\",\n                   \"Optimal\",\n                   \"Normal\",\n                   \"At-risk\",\n                   \"High\"\n                  ),\n        name = \"Systolic\\nBlood Pressure\"\n    ) +\n    ggplot2::xlim(70, 240)\n\nsys_histo3\n```\n\n::: {.cell-output-display}\n![](06-t-test_files/figure-html/systolic-histo3-1.png){width=672}\n:::\n:::\n\n***\nHere I have experimented to colorize the histogram with different colors. I took as borders the medical condition for isolated blood pressure measures:\n\n- Low: < 105\n- Optimal: >= 105 & < 120\n- Normal: >= 120 & < 130\n- At Risk: >= 130 & < 140\n- High: >= 140\n\nIn this case I can’t use the color directly as `fill` variable into the `ggplots::aes()` function. Besides I learned two other solve two other issues:\n\n- The sequence of colors are aligned to the values alphabetically. Therefore I had to take characters that are sorted in the correct order. I took c(\"0\", \"1\", \"2\", \"3\", \"4\") but c(\"a\", \"b\", \"c\", \"d\" ,\"e\") would have worked too.\n- Wider bins brought the problem that the color has changed in the middle of the bar length. I did not know how to solve this issue generally, for instance with providing `breaks` or to provide borders conforming to the medical status. Only `binwidth` of 1 and 2 worked, 3 already showed the problem. Other people had the same problem, see for instance the section \"Example 2: Draw Histogram with Different Colors Using ggplot2 Package\" in [Draw Histogram with Different Colors in R (2 Examples)](https://statisticsglobe.com/draw-histogram-with-different-colors-in-r) [@schorkn.d].\n\n::::\n:::::\n\n###### Histogram 3\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-diastolic-histo}\n: Histogram of diastolic blood pressure with risk factors (NHANES 2015-2016)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## graph systolic blood pressure with risk factors (Figure 6.3)\ndia_histo <- bpx_2016 |>  \n    ggplot2::ggplot(\n        ggplot2::aes(\n            x = BPXDI1, \n            fill = BPXDI1 > 80)\n        ) + \n    ggplot2::geom_histogram(\n        color = \"white\",\n        bins = 30,\n        na.rm = TRUE) + \n    ggplot2::theme_bw() + \n    ggplot2::labs(\n        x = \"Diastolic blood pressure (mmHg)\", \n        y = \"NHANES participants\"\n        ) +\n    ggplot2::scale_fill_manual(\n        values = c(\"mediumpurple\", \"grey\"),\n        labels = c(\"Normal range\",\n                   \"at-risk or high\"),\n        name = \"Diastolic\\nBlood Pressure\"\n    )\n\ndia_histo\n```\n\n::: {.cell-output-display}\n![Histogram of diastolic blood pressure with risk factors (NHANES 2015-2016)](06-t-test_files/figure-html/diastolic-histo-1.png){width=672}\n:::\n:::\n\n***\n\nThis is the replication of the book’s Figure 6.3.\n::::\n:::::\n\n###### `mean()` & `sd()`\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-systolic-mean-sd}\n: Mean and standard deviation of systolic blood pressure in the NHANES data sample (2015-2016)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nbpx_stats <- \n    bpx_2016 |> \n        tidyr::drop_na(BPXSY1) |> \n        dplyr::summarize(\n            mean = base::mean(BPXSY1),\n            sd = stats::sd(BPXSY1),\n            n = dplyr::n()\n            )\nbpx_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       mean       sd    n\n#> 1 120.5394 18.61692 7145\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n## Achievement 2: One-Sample t-test {#sec-chap06-achievement2}\n\n### Introduction\n\nWe have a mean of the systolic blood pressure a little bit above 120.54 mmHG. This is almost exactly the upper cutoff value of 120 mmHG for the \"normal range\" of blood pressure. Is this only valid for the sample of also for the whole population? Have about half of the US people high systolic blood pressure, e.g. more than 120mmHG? The question can be answered with a <a class='glossary' title='One-sample t-test, also known as the single-parameter t-test or single-sample t-test, is an inferential statistical test comparing the mean of a numeric variable to a population or hypothesized mean. (SwR, Glossary)'>one-sample t-test</a>. The one sample t-test compares a sample mean to a *hypothesized or population* mean.\n\n:::::{.my-important}\n:::{.my-important-header}\nThere are three different t-tests\n:::\n::::{.my-important-container}\n\n- **One-sample t-test**: compares a mean to a population or hypothesized value \n- **Independent-samples t-test**: compares the means of two unrelated groups \n- **Dependent-samples t-test**: compares the means of two related groups\n\n::::\n:::::\n\nThe t-distribution has a bell shape like the normal distribution. But unlike the normal distribution its variance is not known but approximated with its only parameter <a class='glossary' title='Degree of Freedom (df) is the number of pieces of information that are allowed to vary in computing a statistic before the remaining pieces of information are known; degrees of freedom are often used as parameters for distributions (e.g., chi-squared, F). (SwR, Glossary)'>degrees of freedom</a> (df). `df` is calculated by the number of observations minus one ($n-1$). With higher degrees of freedom the t-distribution will get closer to the normal distribution. Often the number 30 is recommended as the cutting point where t-distribution and normal distribution are equivalent.\n\n\nI am following @prp-chap05-nhst from @sec-chap05-achievement5.\n\n\n### NHST Step 1\n\nWrite the null and alternate hypotheses:\n\nTwo considerations:\n\n1. The Null relates most of the times to a situation where no change occurs. In this case that there is no difference in the means of the systolic blood pressure. This is different to the assumption that the mean difference is not higher than 120 mmHG!\n2. In the one-sample t-test we are comparing sample mean with population mean. In this case the NHANES sample from the 2015-2016 data with the population mean of the US population.\n\n::: {.callout-note}\n- **H0**: There is no difference in the mean systolic blood pressure in the US population and the cutoff for normal blood pressure of 120 mmHG in the NHANES 2015-2016 data set.\n- **HA**: There is a difference in the mean systolic blood pressure in the US population and the cutoff for normal blood pressure of 120 mmHG in the NHANES 2015-2016 data set.\n:::\n\n### NHST Step 2\n\nCompute the test statistic. The one-sample t-test uses the <a class='glossary' title='The T-Statistic is used in a T test when you are deciding if you should support or reject the null hypothesis. It’s very similar to a Z-score and you use it in the same way: find a cut off point, find your t score, and compare the two. You use the t statistic when you have a small sample size, or if you don’t know the population standard deviation. (Statistics How-To)'>t-statistic</a> (sort of like a z-statistic) \n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap06-t-statistic}\n: t-test formula\n::::::\n:::\n::::{.my-theorem-container}\n\n$$\nt = \\frac{m_{x} - \\mu_{x}}{\\frac{s_x}{\\sqrt{n_{x}}}}\n$$ {#eq-chap06-t-statistic}\n\n- $m_{x}$ represents the mean of the variable x, the variable to be tested, \n- $\\mu_{x}$ is the *population mean or hypothesized value* of the variable, \n- $s_{x}$ is the sample standard deviation of x, and \n- $n_{x}$ is the sample size\n::::\n:::::\n\nThe formula is very similar as the <a class='glossary' title='A z-score (also called a standard score) gives you an idea of how far from the mean a data point is. But more technically it’s a measure of how many standard deviations below or above the population mean a raw score is. (StatisticsHowTo)'>Z-score</a> statistic in @eq-chap04-z-score. The only difference is that in the above <a class='glossary' title='The T-Statistic is used in a T test when you are deciding if you should support or reject the null hypothesis. It’s very similar to a Z-score and you use it in the same way: find a cut off point, find your t score, and compare the two. You use the t statistic when you have a small sample size, or if you don’t know the population standard deviation. (Statistics How-To)'>t-statistic</a> the denominator is the <a class='glossary' title='The standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. The standard deviation is the square root of its variance. A useful property of the standard deviation is that, unlike the variance, it is expressed in the same unit as the data. Standard deviation may be abbreviated SD, and is most commonly represented in mathematical texts and equations by the lower case Greek letter \\(\\sigma\\) (sigma), for the population standard deviation, or the Latin letter \\(s\\) for the sample standard deviation. (Wikipedia)'>standard deviation</a> rather than the <a class='glossary' title='The standard error (SE) of a statistic is the standard deviation of its [sampling distribution]. If the statistic is the sample mean, it is called the standard error of the mean (SEM). (Wikipedia) The standard error is a measure of variability that estimates how much variability there is in a population based on the variability in the sample and the size of the sample. (SwR, Glossary)'>standard error</a>.\n\n- `z` shows how many sample standard deviations some value is away from the mean.\n- `t` shows how many standard errors (i.e., population standard deviations) some value is away from the mean.\n\n$$\nt = \\frac{120.5394 - 120}{\\frac{18.61692}{\\sqrt{7145}}} = 2.45\n$$\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-t-statistic-systolic}\n: t-statistic of systolic blood pressure aof NHANES sample with hypothesized population mean\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n(\n    t_test_systolic <- stats::t.test(\n        bpx_2016$BPXSY1,\n        alternative = \"two.sided\",\n        mu = 120)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tOne Sample t-test\n#> \n#> data:  bpx_2016$BPXSY1\n#> t = 2.4491, df = 7144, p-value = 0.01435\n#> alternative hypothesis: true mean is not equal to 120\n#> 95 percent confidence interval:\n#>  120.1077 120.9711\n#> sample estimates:\n#> mean of x \n#>  120.5394\n```\n\n\n:::\n\n```{.r .cell-code}\n## for later use #########\nt_sys = t_test_systolic[[\"statistic\"]][[\"t\"]]\ndf_sys = t_test_systolic[[\"parameter\"]][[\"df\"]]\nnull_sys = t_test_systolic[[\"null.value\"]][[\"mean\"]]\nestimate_sys = t_test_systolic[[\"estimate\"]][[\"mean of x\"]]\np_value_sys = t_test_systolic[[\"p.value\"]]\nse_sys = t_test_systolic[[\"stderr\"]]\n```\n:::\n\n\n***\n\nI have stored the result of the t-test into variables for later use.\n\n\n\n::::\n:::::\n\n:::::{.my-assessment}\n:::{.my-assessment-header}\n:::::: {#cor-chap06-t-test-output}\n: Explications of the t-test output\n::::::\n:::\n::::{.my-assessment-container}\n\n**1. Line**: Data (variable) used.\n**2. Line**: \n    - `t`: value of the t-test statistic.\n    - `df`: degrees of freedom, with t-statistic = subtracting 1 from sample size = $n - 1$.\n    - `p-value`: The probability of the sample coming from a population where the null hypothesis is true. \n**3. Line**: wording of the alternative hypothesis.\n**4. Line**: Chosen confidence interval.\n**5. Line**: The lower and upper boundary of the confidence interval.\n**6. Line**: Sample estimates that has to be compared to the value of the null hypothesis.\n\n::::\n:::::\n\n### NHST Step 3\n\nReview and interpret the test statistics: Calculate the probability that your test statistic is at least as big as it is if there is no relationship (i.e., the null is true).\n\nThe following examples replicates Figure 6.4, 6.5 and 6.6. I will break down the final code into several steps following the nice article [Visualizing Sampling Distributions: Learn how to add areas under the curve in sampling distributions]https://ggplot2tutor.com/tutorials/sampling_distributions [@burkhart2021].\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-prob-dist-t-test}\n: Probability distribution of t-test statistic\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### t (df=1)\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-two-t-prob-dist}\n: Student t distributions with 1 degree of freedom (df)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot() +\n    ggplot2::xlim(-7, 7) +\n\n## or as an alternative\n# ggplot2::ggplot(tibble::tibble(x = c(-7, 7)), \n#          ggplot2::aes(x)) +\n    \n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = 1),\n             geom = \"line\",\n             linewidth = 0.7\n         ) +\n    ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Student t distributions with 1 degree of freedom (df)](06-t-test_files/figure-html/fig-t-prob-dist-1.png){#fig-t-prob-dist width=672}\n:::\n:::\n\n\n::::\n:::::\n\n:::::{.my-procedure}\n:::{.my-procedure-header}\n:::::: {#prp-chap06-plot-dist}\n: Plotting a distribution with {**ggplot2**}\n::::::\n:::\n::::{.my-procedure-container}\n\n1. As there is no data (just the formula for the function) we need to specify the x-limits.\n2. `ggplot2::stat_function` draws the function. We can specify the function extra or create an anonymous function or --- as I have done here --- use a function from an R package. Note that there is no parenthesis behind the function name.\n\n::::\n:::::\n\n\n###### comparing t\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-compare-t-prob-dist}\n: Student t distributions with 1 and 7144 degree of freedom (df) and normal distribution compared\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot(tibble::tibble(x = c(-7, 7)), \n         ggplot2::aes(x)) +\n         ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = 1),\n             geom = \"line\",\n             linewidth = 0.7,\n             ggplot2::aes(linetype = \"1\")\n         ) +\n         ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = 7144),\n             geom = \"line\",\n             linewidth = 0.7,\n             ggplot2::aes(linetype = \"5\")\n         ) + \n         ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = 30),\n             geom = \"line\",\n             linewidth = 0.7,\n             ggplot2::aes(linetype = \"3\")\n         ) +\n         ggplot2::stat_function(\n            fun = stats::dnorm,\n            geom = \"line\",\n            linewidth = 0.7,\n            ggplot2::aes(color = \"red\")\n         ) +\n         ggplot2::scale_linetype_discrete(\n             name = \"t dist\",\n             labels = c(\"df = 1\", \"df = 30\", \"df = 7144\")\n         ) +\n         ggplot2::scale_color_discrete(\n             name = \"normal dist\",\n             labels = \"mean = 0, sd = 1\"\n         ) +\n         ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Student t distributions with 1 and 7144 degree of freedom (df) and normal distribution compared](06-t-test_files/figure-html/fig-compare-t-prob-dist-1.png){#fig-compare-t-prob-dist width=672}\n:::\n:::\n\n***\n\nThe plot shows two things:\n\n1. There is a big difference between a t distribution with df = 1 and df = 30.\n2. There is no visible difference between t with df = 30, df = 7144 and a normal distribution.\n\n\n::::\n:::::\n\n:::::{.my-procedure}\n:::{.my-procedure-header}\n:::::: {#prp-chap06-plot-several-dist}\n: Plotting several distributions with {**ggplot2**}\n::::::\n:::\n::::{.my-procedure-container}\n\n1. Use for every distribution `ggplot2::stat_function()`.\n2. Put the aesthetic into an `ggplot2::aes()` function.\n3. Add for each legend a corresponding scale with name and labels.\n\n::::\n:::::\n\n\n###### t systolic\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-code-name-b}\n: t-distribution (df = 7,144) shaded for values of 2.4491 or higher (replicating Figure 6.5)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot() +\n    ggplot2::xlim(-4, 4) +\n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = df_sys),\n             geom = \"line\",\n             linewidth = 0.7\n             ) +\n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = df_sys),\n             geom = \"area\",\n             xlim = c(t_sys, 4),\n             ggplot2::aes(fill = \n                paste(\"t >=\", round(t_sys, 3))\n                ) \n             ) +\n    ggplot2::theme_bw() +\n    ggplot2::scale_fill_manual(\n        name = \"\",\n        values = \"steelblue\"\n    )\n```\n\n::: {.cell-output-display}\n![t-distribution (df = 7,144) shaded for values of 2.4491 or higher (replicating Figure 6.5)](06-t-test_files/figure-html/fig-t-test-systolic-1.png){#fig-t-test-systolic width=672}\n:::\n:::\n\n***\n\nThe plot shows that the t-value of 2.499 is very unlikely if the null hypotheses were true, e.g. if the sample comes from a population with a systolic blodd pressure mean of 240.\n\n\n::::\n:::::\n\n###### 2.5% shaded\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-two-sided-shaded}\n: t-distribution (df = 7,144) with 2.5% shaded in each tail of the distribution (replicating Figure 6.6)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot() +\n    ggplot2::xlim(-4, 4) +\n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = df_sys),\n             geom = \"line\",\n             linewidth = 0.7\n             ) +\n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = df_sys),\n             geom = \"area\",\n             xlim = c(1.96, 4),\n             ggplot2::aes(fill = \n                paste(\"Rejection region\")\n                ) \n             ) +\n    ggplot2::stat_function(\n         fun = stats::dt,\n         args = list(df = df_sys),\n         geom = \"area\",\n         xlim = c(-4, -1.96),\n         ggplot2::aes(fill = \n            paste(\"Rejection region\")\n            ) \n         ) +\n    ggplot2::theme_bw() +\n    ggplot2::scale_fill_manual(\n        name = \"\",\n        values = \"purple3\"\n    ) +\n    ggplot2::labs(\n        x = \"t-statistic\",\n        y = \"Probability density\"\n    )\n```\n\n::: {.cell-output-display}\n![t-distribution (df = 7,144) with 2.5% shaded in each tail of the distribution (replicating Figure 6.6)](06-t-test_files/figure-html/fig-two-sided-shaded-1.png){#fig-two-sided-shaded width=672}\n:::\n:::\n\n***\n\nThe plot shows the rejection regions for the probability of 95%.\n\n$$\n\\begin{align*}\np_{low}(x > 1.96) \\approx 0.025 \\\\\np_{high}(x < 1.96) \\approx 0.975 \\\\\np_{high} - p_{low} = \\\\\n0.975 - 0.025 = 0.95\n\\end{align*}\n$$ \n\n::::\n:::::\n\n###### t systolic & 2.5% shaded overlaid\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-t-two-sided-shaded}\n: t-distribution (df = 7,144) with 2.5% shaded in each tail of the distribution (replicating Figure 6.6)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot() +\n    ggplot2::xlim(-4, 4) +\n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = df_sys),\n             geom = \"line\",\n             linewidth = 0.7\n             ) +\n    ggplot2::stat_function(\n             fun = stats::dt,\n             args = list(df = df_sys),\n             geom = \"area\",\n             xlim = c(1.96, 4),\n             alpha = 0.5,\n             ggplot2::aes(fill = \n                paste(\"Rejection region\"),\n                ) \n             ) +\n    ggplot2::stat_function(\n         fun = stats::dt,\n         args = list(df = df_sys),\n         geom = \"area\",\n         xlim = c(-4, -1.96),\n        alpha = 0.5,\n         ggplot2::aes(fill = \n            paste(\"Rejection region\"),\n            ),\n         ) +\n    ggplot2::stat_function(\n     fun = stats::dt,\n     args = list(df = df_sys),\n     geom = \"area\",\n     xlim = c(t_sys, 4),\n     alpha = 0.5,\n     ggplot2::aes(fill = \n        paste(\"t >=\", round(t_sys, 3))\n        ) \n     ) +\n    ggplot2::theme_bw() +\n    ggplot2::scale_fill_manual(\n        name = \"\",\n        values = c(\"purple3\", \"red\")\n    ) +\n    ggplot2::labs(\n        x = \"t-statistic\",\n        y = \"Probability density\"\n    )\n```\n\n::: {.cell-output-display}\n![t-distribution (df = 7,144) with 2.5% shaded in each tail of the distribution (replicating Figure 6.6)](06-t-test_files/figure-html/fig-t-two-sided-shaded-1.png){#fig-t-two-sided-shaded width=672}\n:::\n:::\n\n***\n\nThe plot shows that the t-value is in the <a class='glossary' title='Rejection region is the area under the curve of a sampling distribution where the probability of obtaining a value is very small, often below 5%; the rejection region is in the end of the tail or tails of the distribution. (SwR, Glossary)'>rejection area</a>, e.g., the null has to be rejected.\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n### NHST Step 4\n\nConclude and write the report.\n\nEven though the difference between the mean systolic blood pressure of 120.54 and the hypothesized value of 120 is small, it is statistically significant. The probability of this sample that it comes from a population where the mean systolic blood pressure is actually 120 is just 1.4%. This sample is likely to be from a population with a higher mean blood pressure.\n\n::: {.callout-tip}\nThe mean systolic blood pressure in a sample of 7145 people was 120.54 (sd = 18.62). A one-sample t-test found this mean to be statistically significantly different from the hypothesized mean of 120 [t(7144) = 2.449; p = 0.014]. The sample likely came from a population with a mean systolic blood pressure not equal to 120.\n:::\n\n## Achievement 3: Independent-samples t-test {#sec-chap06-achievement3}\n\nInstead of comparing one mean to a hypothesized or population mean, the <a class='glossary' title='Independent-samples t-test or unpaired sample t-test is an inferential test comparing two independent means. (SwR, Glossary)'>independent-samples t-test</a> compares the means of two groups to each other.\n\nWe could for instance be interested to see if the blood pressure for persons of different sex are the same. Or the question statistically formulated: Do males and females in the sample come from a population where males and females have the same mean systolic blood pressure?\n\nI am not going into the details of achievement 3 because there is no much difference between the procedure for the one-sample t-test and the independent-samples t-test. Essentially there are only two differences:\n\n### Formula\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap06-t-independent-test}\n: Independent-samples t-test formula\n::::::\n:::\n::::{.my-theorem-container}\n\n$$\nt = \\frac{m_{1} - m_{2}}{\\sqrt{\\frac{s_1^2}{n_{1}} + \\frac{s_2^2}{n_{2}}}}\n$$ {#eq-chap06-t-independent-test}\n\n- $m_{1}$ represents the mean of one group, \n- $m_{2}$ represents the mean of another group, \n- $s_{1}^2$ is the variance of the first group,\n- $s_{2}^2$ is the variance of the second group,\n- $n_{1}$ is the size of the first group,\n- $n_{2}$ is the size of the second group.\n::::\n:::::\n\n### Computing\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-t-indpendent-test}\n: Independent-samples t-test for systolic blood pressure of males and females\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap06-t-indpendent-test}\n\n::: {.cell}\n\n```{.r .cell-code}\nbp_clean = base::readRDS(\"data/chap06/bp_clean.rds\")\n\nbp_clean |> \n    tidyr::drop_na(systolic) |> \n    dplyr::group_by(sex) |> \n    dplyr::summarize(\n        mean_systolic = mean(systolic),\n        var_systolic = var(systolic),\n        sample_size = dplyr::n()\n    )\n\ntwo_sample_t <- t.test(formula = \n           bp_clean$systolic ~ bp_clean$sex)\ntwo_sample_t\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 2 × 4\n#>   sex    mean_systolic var_systolic sample_size\n#>   <fct>          <dbl>        <dbl>       <int>\n#> 1 Male            122.         329.        3498\n#> 2 Female          119.         358.        3647\n#> \n#> \tWelch Two Sample t-test\n#> \n#> data:  bp_clean$systolic by bp_clean$sex\n#> t = 7.3135, df = 7143, p-value = 2.886e-13\n#> alternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n#> 95 percent confidence interval:\n#>  2.347882 4.067432\n#> sample estimates:\n#>   mean in group Male mean in group Female \n#>             122.1767             118.9690\n```\n\n\n:::\n:::\n\n\nIndependent-samples t-test for systolic blood pressure of males and females\n:::\n::::\n:::::\n\nIt is important to note that category variables like `sex` do not work with the default `x, y` version of the t-test. Therefore we have to apply the method with class `formula`.\n\nIn R formulae a single variable on the left-hand side is followed by the tilde sign `~` and one ore more objects that predict or explain the left-hand side.\n\n> In a lot of statistical tests, the object on the left-hand side of the formula is the <a class='glossary' title='Outcome is the variable being explained or predicted by a model; in linear and logistic regression, the outcome variable is on the left-hand side of the equal sign. (SwR, Glossary)'>outcome</a> or dependent variable while the object(s) on the right-hand side of the formula are the <a class='glossary' title='Predictor variable – also known sometimes as the independent or explanatory variable – is the counterpart to the response or dependent variable. Predictor variables are used to make predictions for dependent variables. (DeepAI, MiniTab)'>predictors</a> or independent variables. (SwR)\n\n> It is commonly used to generate *design matrices* for modeling function (e.g. `lm`) [@kuhn2017].\n\nIn our case, systolic blood pressure is the *outcome* being explained by the *predictor* of sex.\n\nIn R the default t-test for independent samples is the <a class='glossary' title='Welch’s t-test is a variation on the Student’s t-test that does not assume equal variances in group (SwR, Glossary).'>Welch’s t-test</a> and not the student t-test. \n\n> Welch’s t-test is slightly different from the original formula for t, which used pooled variance in the denominator. <a class='glossary' title='Pooled variance is the assumption that the variances in two groups are equal, so these variances are combined (‘pooled’) (SwR, Glossary).'>Pooled variance</a> assumes that the variances in the two groups are equal and combines them. (SwR)\n\nThere is an scientific article explaining why Welch's t-test should be used in any case, even if the assumption of homogeneity of variance is met: \n\n> We show that the Welch’s t-test provides a better control of Type 1 error rates when the assumption of homogeneity of variance is not met, and it loses little robustness compared to Student’s t-test when the assumptions are met. We argue that Welch’s t-test should be used as a default strategy. [@delacre2017; see also: @delacre2022]\n\nJust to conclude this abbreviated section I quote the final summary reporting the independent t-test results.\n\n::: {.callout-tip}\n> There was a statistically significant difference [t(7143) = 7.31; p < .05] in mean systolic blood pressure between males (m = 122.18) and females (m = 118.97) in the sample. The sample was taken from the U.S. population, indicating that males in the United States likely have a different mean systolic blood pressure than females in the United States. The difference between male and female mean systolic blood pressure was 3.21 in the sample; in the population this sample came from, the difference between male and female mean blood pressure was likely to be between 2.35 and 4.07 (d = 3.21; 95% CI: 2.35–4.07). (SwR)\n:::\n\n\n## Achievement 4: Dependent-samples t-test {#sec-chap06-achievement4}\n\nAgain: I am not going to summarize this section because it resembles achievement 2 (one-sample t-test) and achievement 3 (independent.samples t-test).\n\n### Formula\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap06-t-dependent-test}\n: Independent-samples t-test formula\n::::::\n:::\n::::{.my-theorem-container}\n\n$$\nt = \\frac{m_{d} - 0}{\\sqrt{\\frac{s_d}{n_{d}}}}\n$$ {#eq-chap06-t-dependent-test}\n\n- $m_{d}$ represents the mean of differences between to measures, \n- $s_{d}^2$ is the variance of the mean differences between to measures,\n- $n_{d}$ is the sample size,\n- $0$ subtracting represents the null hypothesis; zero is the mean difference if the two measures were exactly the same.\n::::\n:::::\n\n### Computing\n\n:::::{.my-important}\n:::{.my-important-header}\nGeneral advice before starting a test statistics\n:::\n::::{.my-important-container}\nAlways look at some visuals and descriptive statistics before you are starting the test procedure and following the NHST procedure as outlined in @prp-chap05-nhst.\n::::\n:::::\n\nThis shows that the *difference of the mean* between two measures is very small (0.55 mmHG). But it turned out that this value is highly statistically significant. But from a clinical point of view it is irrelevant!\n\n:::::{.my-important}\n:::{.my-important-header}\nStatistically significant != meaningful!\n:::\n::::{.my-important-container}\nAll our three t-tests result in small but statistically significant values. This is an important reminder that statistically significant p-values are not necessarily of relevance.\n\nBy the way: The reason for our small but statistically significant values are very large samples.\n::::\n:::::\n\n\nThe computation in R is the same as in @lst-chap06-t-indpendent-test. Again apply the formula version of Welch’s t-test with the only difference to add the argument `paired = TRUE`.\n\n## Achievement 5: Effect size {#sec-chap06-achievement5}\n\n### Introduction\n\nWe haven seen that even the very small difference of 0.54 mmHG systolic blood pressure is with a large sample size statistically significant. But this small difference is clinically not relevant. To judge the importance of some statistically significant results we need effect sizes as another criteria. \n\nThe proportion of people that believe that effect sizes are even more important than p-values is rising. P-values only report whether a difference or relationship from a sample is likely to be true in the population, while effect sizes provide information about the strength or size of a difference or relationship.\n\nIn @sec-chap05 we discussed for the Chi-squared test as effect sizes \n\n- Cramèrs V (@sec-chap05-cramers-v)\n- Phi coefficient $\\phi$ (@sec-chap05-phi-coefficient) and\n- Odds ratio (@sec-chap05-odds-ratio)\n\nFor t-test the appropriate effect size measure is <a class='glossary' title='Cohen’s d is a standardized effect size for measuring the difference between two group means. It is frequently used to compare a treatment to a control group. It can be a suitable effect size to include with t-test and ANOVA results. (Statistics by Jim)'>Cohen’s d</a>. \n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap06-cohens-d}\n: Formula for Cohen’s d one-sample t-test\n::::::\n:::\n::::{.my-theorem-container}\n$$\nd = \\frac{m_{x} - \\mu_{x}}{s_{x}}\n$$ {#eq-chap06-cohens-d-one-sample}\n\n$m_{x}$ = sample mean for $x$\n$\\mu_{x}$ = hypothesized or population mean\n$s_{x}$ = sample standard deviation for $x$\n::::\n:::::\n\nThe formula is similar to the already well-known z-score calculation (@eq-chap04-z-score).\n\n:::::{.my-assessment}\n:::{.my-assessment-header}\n:::::: {#cor-chap06-cohens-d}\n: Classification of Cohen’s d values\n::::::\n:::\n::::{.my-assessment-container}\n\n- **Small effect size**: Cohen’s d = .2 to d < .5 \n- **Medium effect size**: Cohen’s d = .5 to d < .8 \n- **Large effect size**: Cohen’s d ≥ .8\n\n::::\n:::::\n\n### Cohen’s d computation\n\n:::::{.my-resource}\n:::{.my-resource-header}\nPackages with Cohen’s d functions\n:::\n::::{.my-resource-container}\n\n- {**lsr**}: The recommendation from the book (see @pak-lsr)\n- {**effectsize**}: Indices of effect sizes (see @pak-effectsize)\n- {**rstatix**}: (see @pak-rstatix)\n\nThee is another package {**effsize**} that I have not used. I had problems to use it, because it has no argument for $\\mu$ but it also has not many downloads.\n\nThe packages {**effectsize**} and {**rstatix**} are important as they have many other computation for effect soze parameters.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npkgs_dl(c(\"lsr\", \"effectsize\", \"rstatix\", \"effsize\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 4 × 2\n#>   package        n\n#>   <chr>      <dbl>\n#> 1 rstatix     5488\n#> 2 effectsize  1602\n#> 3 lsr          399\n#> 4 effsize      270\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n### Cohen’s d for one-sample t-tests\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-cohens-d}\n: Computation of Cohen’s d for one-sample t-tests\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Manual\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-manual}\n: Computation of Cohen’s d for one-sample t-tests manually (by hand)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nbp_clean <-  base::readRDS(\"data/chap06/bp_clean.rds\")\n\n(estimate_sys - null_sys) / sd(bp_clean$systolic, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.02897354\n```\n\n\n:::\n:::\n\n\nThe effect size is very small, it is not even close the starting value for \"small effect size\".\n\n::: {.callout-tip}\nThe mean systolic blood pressure in a sample of 7,145 people was 120.54 (sd = 18.62). A one-sample t-test found this mean to be statistically significantly different from the hypothesized mean of 120 [t(7144) = 2.45; p = 0.014]. The sample likely came from a population with a mean systolic blood pressure not equal to 120. While the sample mean was statistically significantly different from 120, is has a very small effect size (Cohen’s d = .03).\n:::\n\n::::\n:::::\n\n\n###### {**lsr**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-one-sample-lsr}\n: Compute Cohen’s d with for one-sample t-tests {**lsr**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlsr::cohensD(bp_clean$systolic, mu = 120)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.02897354\n```\n\n\n:::\n:::\n\n***\n\n\n\n\n::::\n:::::\n\n\n###### {**effectsize**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-one-sample-effectsize}\n: Compute Cohen’s d for one-sample t-tests with {**effectsize**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\neffectsize::cohens_d(\n    x = bp_clean$systolic,\n    mu = 120\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Missing values detected. NAs dropped.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Cohen's d |       95% CI\n#> ------------------------\n#> 0.03      | [0.01, 0.05]\n#> \n#> - Deviation from a difference of 120.\n```\n\n\n:::\n:::\n\n***\n\nThe {**effectsize**} packages discusses two alternatives for Cohen’s d:\n\n- **Hedges' g** provides a correction for small-sample bias (using the exact method) to Cohen's d. For sample sizes > 20, the results for both statistics are roughly equivalent. \n- **Glass’s delta** is appropriate when the standard deviations are significantly different between the populations, as it uses only the second group's standard deviation.\n::::\n:::::\n\n###### {**rstatix**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-one-sample-rstatix}\n: Compute Cohen’s d for one-sample t-tests with {**rstatix**}\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nrstatix::cohens_d(\n    data = bp_clean,\n    formula = systolic ~ 1,\n    mu = 120\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 6\n#>   .y.      group1 group2     effsize     n magnitude \n#> * <chr>    <chr>  <chr>        <dbl> <int> <ord>     \n#> 1 systolic 1      null model  0.0290  7145 negligible\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n### Cohen’s d for independent-samples t-tests\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap06-dependent-samples-cohens-d}\n: Formula for independent-samples cohen’s d\n::::::\n:::\n::::{.my-theorem-container}\n\n$$\nd = \\frac{m_{1}-{m_{2}}}{\\sqrt{\\frac{s_{1}^2 + s_{2}^2}{2}}}\n$$ {#eq-chap06-cohens-d-independent-samples}\n***\n\n- $m_{1}, m_{2}$: sample means \n- $s_{1}^2, s_{2}^2$: sample variances\n::::\n:::::\n\n\n\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-cohens-d}\n: Computation of Cohen’s d for independent-samples t-tests\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Manual\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-independent-samples-manual}\n: Computation of Cohen’s d for independent-samples t-tests manually (by hand)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nbp_clean <-  base::readRDS(\"data/chap06/bp_clean.rds\")\n\nbp_ind_samples <- \n    bp_clean |> \n    tidyr::drop_na(systolic) |> \n    dplyr::group_by(sex) |> \n    dplyr::summarize(\n        mean_sys_sex = mean(systolic),\n        var_sys_sex = var(systolic)\n    )\nbp_ind_samples\n\nm1 <- bp_ind_samples[[1,2]] \nm2 <- bp_ind_samples[[2,2]] \nvar1 <- bp_ind_samples[[1,3]]\nvar2 <- bp_ind_samples[[2,3]]\n\n(m1 - m2) / (sqrt((var1 + var2) / 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 2 × 3\n#>   sex    mean_sys_sex var_sys_sex\n#>   <fct>         <dbl>       <dbl>\n#> 1 Male           122.        329.\n#> 2 Female         119.        358.\n#> [1] 0.1730045\n```\n\n\n:::\n:::\n\n\nThe effect size is very small.\n\n::::\n:::::\n\n\n\n\n\n###### {**lsr**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-independent-samples-lsr}\n: Compute Cohen’s d of independent samples with {**lsr**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlsr::cohensD(\n    x = systolic ~ sex,\n    data = bp_clean,\n    method = \"unequal\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1730045\n```\n\n\n:::\n:::\n\n***\n\n1. Instead of a vector variable we are using the formula interface.\n2. Because we are using the Welch's t-test we change the default method \"pooled\", to \"unequal\", e.g., we are not assuming equal variances.\n\n\n::::\n:::::\n\n\n###### {**effectsize**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-independent-samples-effectsize}\n: Compute Cohen’s d for independent-samples t-tests with {**effectsize**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\neffectsize::cohens_d(\n    x = bp_clean$systolic,\n    y = bp_clean$sex,\n    pooled_sd = FALSE,\n    paired = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Missing values detected. NAs dropped.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Cohen's d |       95% CI\n#> ------------------------\n#> 0.17      | [0.13, 0.22]\n#> \n#> - Estimated using un-pooled SD.\n```\n\n\n:::\n:::\n\n***\n\nThe {**effectsize**} packages discusses two alternatives for Cohen’s d:\n\n- **Hedges' g** provides a correction for small-sample bias (using the exact method) to Cohen's d. For sample sizes > 20, the results for both statistics are roughly equivalent. \n- **Glass’s delta** is appropriate when the standard deviations are significantly different between the populations, as it uses only the second group's standard deviation.\n::::\n:::::\n\n###### {**rstatix**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-independent-samples-rstatix}\n: Compute Cohen’s d for independent-samples t-tests with {**rstatix**}\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nrstatix::cohens_d(\n    data = bp_clean,\n    formula = systolic ~ sex\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 7\n#>   .y.      group1 group2 effsize    n1    n2 magnitude \n#> * <chr>    <chr>  <chr>    <dbl> <int> <int> <ord>     \n#> 1 systolic Male   Female   0.173  3498  3647 negligible\n```\n\n\n:::\n:::\n\n***\n\n- We have used the default value for `paired = FALSE` because we have an independent samples t-test.\n- We have used the default value for `var.equal = FALSE` because we have used the Welch’s t-test taht does not assume equal variances.\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n### Cohen’s d for dependent-samples t-tests\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap06-dependent-samples-cohens-d}\n: Formula for dependent-samples cohen’s d\n::::::\n:::\n::::{.my-theorem-container}\n\n$$\nd = \\frac{m_{d}-0}{s_{d}}\n$$ {#eq-chap06-cohens-d-dependent-samples}\n\n***\n- $m_{d}$: mean difference between the two measures (for instance in our case, systolic and systolic2)\n- $s_{d}$: standard deviation of the differences between the two measures\n::::\n:::::\n\n\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap06-cohens-d-dependent-samples}\n: Computation of Cohen’s d for dependent-samples t-tests\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Manual\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-dependent-samples-manual}\n: Computation of Cohen’s d for dependent-samples t-tests manually (by hand)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nbp_clean <-  base::readRDS(\"data/chap06/bp_clean.rds\")\n\nbp_ind_samples <- bp_clean |> \n    tidyr::drop_na(diff_syst) |> \n    dplyr::summarize(\n        mean_diff = mean(diff_syst),\n        sd_diff = sd(diff_syst)\n    )\nbp_ind_samples\n\n\n(bp_ind_samples$mean_diff - 0) / bp_ind_samples$sd_diff\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>   mean_diff  sd_diff\n#> 1 0.5449937 4.898043\n#> [1] 0.1112676\n```\n\n\n:::\n:::\n\n\nThe effect size is very small.\n\n::::\n:::::\n\n\n\n\n\n###### {**lsr**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-dependent-samples-lsr}\n: Compute Cohen’s d of dependent samples with {**lsr**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlsr::cohensD(\n    x = bp_clean$systolic, \n    y = bp_clean$systolic2, \n    method = \"paired\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1112676\n```\n\n\n:::\n:::\n\n***\n\nInstead of the default method (\"pooled\") we need \"paired\" as method for the dependent-samples t-test.\n\n\n::::\n:::::\n\n\n###### {**effectsize**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-dependent-samples-effectsize}\n: Compute Cohen’s d for dependent-samples t-tests with {**effectsize**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\neffectsize::cohens_d(\n    x = bp_clean$systolic,\n    y = bp_clean$systolic2,\n    paired = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Missing values detected. NAs dropped.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Cohen's d |       95% CI\n#> ------------------------\n#> 0.11      | [0.09, 0.13]\n```\n\n\n:::\n:::\n\n***\n\nThe {**effectsize**} packages discusses two alternatives for Cohen’s d:\n\n- **Hedges' g** provides a correction for small-sample bias (using the exact method) to Cohen's d. For sample sizes > 20, the results for both statistics are roughly equivalent. \n- **Glass’s delta** is appropriate when the standard deviations are significantly different between the populations, as it uses only the second group's standard deviation.\n::::\n:::::\n\n###### {**rstatix**}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap06-cohens-d-dependent-samples-rstatix}\n: Compute Cohen’s d for dependent-samples t-tests with {**rstatix**}\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nbp_clean |> \n    dplyr::select(systolic, systolic2) |> \n    tidyr::drop_na() |> \n    tidyr::pivot_longer(\n        cols = c(\"systolic\", \"systolic2\"), \n        names_to = \"treatment\", \n        values_to = \"value\") |> \n    rstatix::cohens_d(\n        formula = value ~ treatment,\n        paired = TRUE   \n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 7\n#>   .y.   group1   group2    effsize    n1    n2 magnitude \n#> * <chr> <chr>    <chr>       <dbl> <int> <int> <ord>     \n#> 1 value systolic systolic2   0.111  7101  7101 negligible\n```\n\n\n:::\n:::\n\n\nIn order to get a working cohen’s d computation with {**rstatix**} I had to apply `tidyr::pivot_longer()`.\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n## Exercises (empty)\n\n## Packages introduced in this chapter\n\n### BSDA\n\n:::::{.my-resource}\n:::{.my-resource-header}\nBSDA: Basic Statistics and Data Analysis \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-bsda}\n\n***\n\n{**BSDA**}: [Basic Statistics and Data Analysis](https://alanarnholt.github.io/BSDA/) [@BSDA]\n\n(*There is no hexagon logo for {**BSDA**} available*)\n\nFunctions and data sets for the text Basic Statistics and Data Analysis (BSDA) [@kitchens2002].\n\n\n{**pkg-name**}: Basic Statistics and Data Analysis\n:::\n\n***\n::::\n:::::\n\n\n### car\n\n:::::{.my-resource}\n:::{.my-resource-header}\ncar: Companion to Applied Regression \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-car}\n\n***\n\n{**car**}: [Companion to Applied Regression](https://www.john-fox.ca/Companion/index.html) [@car]\n\n::: {layout=\"[10, 30]\" layout-valign=\"center\"}\n![](img/chap06/logoi/logo-car-min.png){width=\"176\"}\n\nFunctions to Accompany J. Fox and S. Weisberg, An R Companion to Applied Regression, Third Edition, Sage, 2019. [@fox2018]\n\n:::\nAn R Companion to Applied Regression is a broad introduction to the R statistical computing environment in the context of applied regression analysis. The book provides a step-by-step guide to using the free statistical software R, and emphasizes integrating statistical computing in R with the practice of data analysis.  The R packages car and effects, written to facilitate the application and interpretation of regression analysis, are extensively covered in the book.\n\n{**car**}: Companion to Applied Regression\n:::\n\n***\n::::\n:::::\n\n:::::{.my-resource}\n:::{.my-resource-header}\nrcompanion: Functions to Support Extension Education Program Evaluation \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-rcompanion}\n\n***\n\n{**rcompanion**}: [Functions to Support Extension Education Program Evaluation](https://rcompanion.org/handbook/) [@rcompanion]\n\n(*There is no hexagon logo for {**rcompanion**} available*)\n\n\nFunctions and datasets to support Summary and Analysis of Extension Program Evaluation in R, and An R Companion for the Handbook of Biological Statistics. Vignettes are available at <https://rcompanion.org>.\n\n{**rcompanion**}: Functions to Support Extension Education Program Evaluation [@mangiafico2023]\n:::\n\n\n***\n::::\n:::::\n\n### effectsize\n\n:::::{.my-resource}\n:::{.my-resource-header}\neffectsize: Indices of Effect Size \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-effectsize}\n\n***\n\n{**effectsize**}: [Indices of Effect Size](https://easystats.github.io/effectsize/) [@effectsize]\n\n::: {layout=\"[10, 30]\" layout-valign=\"center\"}\n![](img/chap06/logoi/logo-effectsize-min.png){width=\"176\"}\n\nThe goal of this package is to provide utilities to work with indices of effect size and standardized parameters, allowing computation and conversion of indices such as Cohen’s d, r, odds-ratios, etc.\n\n:::\n\nProvide utilities to work with indices of effect size for a wide  variety of models and hypothesis tests (see list of supported models using the function 'insight::supported_models()'), allowing computation of and  conversion between indices such as Cohen's d, r, odds, etc.\n\n{**effectsize**}: Indices of Effect Size\n:::\n\n\n\n***\n::::\n:::::\n\n\n\n\n\n### nhanesA\n\n:::::{.my-resource}\n:::{.my-resource-header}\nnhanesA: NHANES Data Retrieval \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-nhanesA}\n\n***\n\n{**nhanesA**}: [NHANES Data Retrieval](https://github.com/cjendres1/nhanes/) [@nhanesA]\n\n::: {layout=\"[10, 30]\" layout-valign=\"center\"}\n![](img/chap06/logoi/logo-nhanesA-min.png){width=\"176\"}\n\n\nUtility to retrieve data from the National Health and Nutrition Examination Survey (NHANES) website <https://www.cdc.gov/nchs/nhanes/index.htm>.\n\n:::\n\n{**nhanesA**} is an R package for browsing and retrieving data from the National Health And Nutrition Examination Survey (NHANES). This package is designed to be useful for research and instructional purposes.\n\nThe functions in the {**nhanesA**} package allow for fully customizable selection and import of data directly from the NHANES website thus it is essential to have an active network connection.\n\nThere are other similar packages also available, but the are more restricted as newer data than 2014 cant be downloaded: \n\n- {**NHANES**}: For the years 2009-2012\n- {**RNHANES**}: For the years 1999-2014\n\n\n{**nhanesA**}: NHANES Data Retrieval\n:::\n\nSee for my other reflection of packages for downloading NHANES data in @not-chap01-nhanesA-pkg and @sec-chap03-rnhanes.\n\n***\n::::\n:::::\n\n\n## Glossary\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Cohen’s d </td>\n   <td style=\"text-align:left;\"> Cohen’s d is a standardized effect size for measuring the difference between two group means. It is frequently used to compare a treatment to a control group. It can be a suitable effect size to include with t-test and ANOVA results. (&lt;a href= \"https://statisticsbyjim.com/basics/cohens-d/\"&gt;Statistics by Jim&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Degrees of Freedom </td>\n   <td style=\"text-align:left;\"> Degree of Freedom (df) is the number of pieces of information that are allowed to vary in computing a statistic before the remaining pieces of information are known; degrees of freedom are often used as parameters for distributions (e.g., chi-squared, F). (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Effect Size </td>\n   <td style=\"text-align:left;\"> Effect size is a measure of the strength of a relationship; effect sizes are important in inferential statistics in order to determine and communicate whether a statistically significant result has practical importance. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Independent </td>\n   <td style=\"text-align:left;\"> Independent-samples t-test or unpaired sample t-test is an inferential test comparing two independent means. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> One-sample t-test </td>\n   <td style=\"text-align:left;\"> One-sample t-test, also known as the single-parameter t-test or single-sample t-test, is an inferential statistical test comparing the mean of a numeric variable to a population or hypothesized mean. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Outcome </td>\n   <td style=\"text-align:left;\"> Outcome is the variable being explained or predicted by a model; in linear and logistic regression, the outcome variable is on the left-hand side of the equal sign. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Paired </td>\n   <td style=\"text-align:left;\"> Dependent-samples test or paired-samples t-test is an inferential test comparing two related means . (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Pooled Variance </td>\n   <td style=\"text-align:left;\"> Pooled variance is the assumption that the variances in two groups are equal, so these variances are combined ('pooled') (SwR, Glossary). </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Predictor Variable </td>\n   <td style=\"text-align:left;\"> Predictor variable -- also known sometimes as the independent or explanatory variable -- is the counterpart to the response or dependent variable. Predictor variables are used to make predictions for dependent variables. ([DeepAI](https://deepai.org/machine-learning-glossary-and-terms/predictor-variable), [MiniTab](https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistical-modeling/regression/supporting-topics/basics/what-are-response-and-predictor-variables/)) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Quantile </td>\n   <td style=\"text-align:left;\"> Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities (&lt;a href=\"https://en.wikipedia.org/wiki/Quantile\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Rejection Region </td>\n   <td style=\"text-align:left;\"> Rejection region is the area under the curve of a sampling distribution where the probability of obtaining a value is very small, often below 5%; the rejection region is in the end of the tail or tails of the distribution. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Standard Deviation </td>\n   <td style=\"text-align:left;\"> The standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. The standard deviation is the square root of its variance. A useful property of the standard deviation is that, unlike the variance, it is expressed in the same unit as the data. Standard deviation may be abbreviated SD, and is most commonly represented in mathematical texts and equations by the lower case Greek letter $\\sigma$ (sigma), for the population standard deviation, or the Latin letter $s$ for the sample standard deviation. ([Wikipedia] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Standard Error </td>\n   <td style=\"text-align:left;\"> The standard error (SE) of a statistic is the standard deviation of its [sampling distribution]. If the statistic is the sample mean, it is called the standard error of the mean (SEM). (&lt;a href=\"https://en.wikipedia.org/wiki/Standard_error\"&gt;Wikipedia&lt;/a&gt;) The standard error is a measure of variability that estimates how much variability there is in a population based on the variability in the sample and the size of the sample. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> T-Statistic </td>\n   <td style=\"text-align:left;\"> The T-Statistic is used in a T test when you are deciding if you should support or reject the null hypothesis. It’s very similar to a Z-score and you use it in the same way: find a cut off point, find your t score, and compare the two. You use the t statistic when you have a small sample size, or if you don’t know the population standard deviation. (&lt;a href=\"https://www.statisticshowto.com/t-statistic/\"&gt;Statistics How-To&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Welch </td>\n   <td style=\"text-align:left;\"> Welch’s t-test is a variation on the Student’s t-test that does not assume equal variances in group (SwR, Glossary). </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Z-score </td>\n   <td style=\"text-align:left;\"> A z-score (also called a standard score) gives you an idea of how far from the mean a data point is. But more technically it’s a measure of how many standard deviations below or above the population mean a raw score is. (&lt;a href=\"https://www.statisticshowto.com/probability-and-statistics/z-score/#Whatisazscore\"&gt;StatisticsHowTo&lt;/a&gt;) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n## Session Info {.unnumbered}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\nSession Info\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.3.3 (2024-02-29)\n#>  os       macOS Sonoma 14.3.1\n#>  system   x86_64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Europe/Vienna\n#>  date     2024-03-20\n#>  pandoc   3.1.12.2 @ /usr/local/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  package      * version    date (UTC) lib source\n#>  abind          1.4-5      2016-07-21 [1] CRAN (R 4.3.0)\n#>  backports      1.4.1      2021-12-13 [1] CRAN (R 4.3.0)\n#>  base64enc      0.1-3      2015-07-28 [1] CRAN (R 4.3.0)\n#>  bayestestR     0.13.2     2024-02-12 [1] CRAN (R 4.3.2)\n#>  broom          1.0.5      2023-06-09 [1] CRAN (R 4.3.0)\n#>  car            3.1-2      2023-03-30 [1] CRAN (R 4.3.0)\n#>  carData        3.0-5      2022-01-06 [1] CRAN (R 4.3.0)\n#>  chromote       0.2.0      2024-02-12 [1] CRAN (R 4.3.2)\n#>  cli            3.6.2      2023-12-11 [1] CRAN (R 4.3.0)\n#>  coda           0.19-4.1   2024-01-31 [1] CRAN (R 4.3.2)\n#>  codetools      0.2-19     2023-02-01 [2] CRAN (R 4.3.3)\n#>  colorspace     2.1-1      2024-01-03 [1] R-Forge (R 4.3.2)\n#>  commonmark     1.9.1      2024-01-30 [1] CRAN (R 4.3.2)\n#>  cranlogs       2.1.1      2019-04-29 [1] CRAN (R 4.3.0)\n#>  crayon         1.5.2      2022-09-29 [1] CRAN (R 4.3.0)\n#>  curl           5.2.1      2024-03-01 [1] CRAN (R 4.3.2)\n#>  datawizard     0.9.1      2023-12-21 [1] CRAN (R 4.3.0)\n#>  digest         0.6.35     2024-03-11 [1] CRAN (R 4.3.2)\n#>  dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.3.0)\n#>  effectsize     0.8.6      2023-09-14 [1] CRAN (R 4.3.0)\n#>  emmeans        1.10.0     2024-01-23 [1] CRAN (R 4.3.2)\n#>  estimability   1.5        2024-02-20 [1] CRAN (R 4.3.2)\n#>  evaluate       0.23       2023-11-01 [1] CRAN (R 4.3.0)\n#>  fansi          1.0.6      2023-12-08 [1] CRAN (R 4.3.0)\n#>  farver         2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n#>  fastmap        1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n#>  foreign        0.8-86     2023-11-28 [1] CRAN (R 4.3.2)\n#>  generics       0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n#>  ggplot2        3.5.0      2024-02-23 [1] CRAN (R 4.3.2)\n#>  glossary     * 1.0.0.9000 2023-08-12 [1] Github (debruine/glossary@819e329)\n#>  glue           1.7.0      2024-01-09 [1] CRAN (R 4.3.0)\n#>  gtable         0.3.4      2023-08-21 [1] CRAN (R 4.3.0)\n#>  here           1.0.1      2020-12-13 [1] CRAN (R 4.3.0)\n#>  highr          0.10       2022-12-22 [1] CRAN (R 4.3.0)\n#>  htmltools      0.5.7      2023-11-03 [1] CRAN (R 4.3.0)\n#>  htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.3.0)\n#>  httr           1.4.7      2023-08-15 [1] CRAN (R 4.3.0)\n#>  insight        0.19.9     2024-03-15 [1] CRAN (R 4.3.3)\n#>  jsonlite       1.8.8      2023-12-04 [1] CRAN (R 4.3.0)\n#>  kableExtra     1.4.0      2024-01-24 [1] CRAN (R 4.3.2)\n#>  knitr          1.45       2023-10-30 [1] CRAN (R 4.3.0)\n#>  labeling       0.4.3      2023-08-29 [1] CRAN (R 4.3.0)\n#>  later          1.3.2      2023-12-06 [1] CRAN (R 4.3.0)\n#>  lattice        0.22-5     2023-10-24 [2] CRAN (R 4.3.3)\n#>  lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.3.0)\n#>  lsr            0.5.2      2021-12-01 [1] CRAN (R 4.3.0)\n#>  magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n#>  markdown       1.12       2023-12-06 [1] CRAN (R 4.3.0)\n#>  MASS           7.3-60.0.1 2024-01-13 [2] CRAN (R 4.3.3)\n#>  Matrix         1.6-5      2024-01-11 [1] CRAN (R 4.3.0)\n#>  multcomp       1.4-25     2023-06-20 [1] CRAN (R 4.3.0)\n#>  munsell        0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n#>  mvtnorm        1.2-4      2023-11-27 [1] CRAN (R 4.3.2)\n#>  nhanesA        1.0        2024-01-09 [1] CRAN (R 4.3.0)\n#>  parameters     0.21.5     2024-02-07 [1] CRAN (R 4.3.2)\n#>  pillar         1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n#>  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n#>  plyr           1.8.9      2023-10-02 [1] CRAN (R 4.3.0)\n#>  processx       3.8.3      2023-12-10 [1] CRAN (R 4.3.0)\n#>  promises       1.2.1      2023-08-10 [1] CRAN (R 4.3.0)\n#>  ps             1.7.6      2024-01-18 [1] CRAN (R 4.3.0)\n#>  purrr          1.0.2      2023-08-10 [1] CRAN (R 4.3.0)\n#>  R6             2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n#>  Rcpp           1.0.12     2024-01-09 [1] CRAN (R 4.3.0)\n#>  repr           1.1.6      2023-01-26 [1] CRAN (R 4.3.0)\n#>  rlang          1.1.3      2024-01-10 [1] CRAN (R 4.3.0)\n#>  rmarkdown      2.26       2024-03-05 [1] CRAN (R 4.3.2)\n#>  rprojroot      2.0.4      2023-11-05 [1] CRAN (R 4.3.0)\n#>  rstatix        0.7.2      2023-02-01 [1] CRAN (R 4.3.0)\n#>  rstudioapi     0.15.0     2023-07-07 [1] CRAN (R 4.3.0)\n#>  rversions      2.1.2      2022-08-31 [1] CRAN (R 4.3.0)\n#>  rvest          1.0.4      2024-02-12 [1] CRAN (R 4.3.2)\n#>  sandwich       3.1-0      2023-12-11 [1] CRAN (R 4.3.0)\n#>  scales         1.3.0      2023-11-28 [1] CRAN (R 4.3.2)\n#>  selectr        0.4-2      2019-11-20 [1] CRAN (R 4.3.0)\n#>  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n#>  skimr          2.1.5      2022-12-23 [1] CRAN (R 4.3.0)\n#>  stringi        1.8.3      2023-12-11 [1] CRAN (R 4.3.0)\n#>  stringr        1.5.1      2023-11-14 [1] CRAN (R 4.3.0)\n#>  survival       3.5-8      2024-02-14 [2] CRAN (R 4.3.3)\n#>  svglite        2.1.3      2023-12-08 [1] CRAN (R 4.3.0)\n#>  systemfonts    1.0.6      2024-03-07 [1] CRAN (R 4.3.2)\n#>  TH.data        1.1-2      2023-04-17 [1] CRAN (R 4.3.0)\n#>  tibble         3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n#>  tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n#>  tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.3.2)\n#>  utf8           1.2.4      2023-10-22 [1] CRAN (R 4.3.0)\n#>  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n#>  viridisLite    0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n#>  websocket      1.4.1      2021-08-18 [1] CRAN (R 4.3.0)\n#>  withr          3.0.0      2024-01-16 [1] CRAN (R 4.3.0)\n#>  xfun           0.42       2024-02-08 [1] CRAN (R 4.3.2)\n#>  xml2           1.3.6      2023-12-04 [1] CRAN (R 4.3.0)\n#>  xtable         1.8-4      2019-04-21 [1] CRAN (R 4.3.0)\n#>  yaml           2.3.8      2023-12-11 [1] CRAN (R 4.3.0)\n#>  zoo            1.8-12     2023-04-13 [1] CRAN (R 4.3.0)\n#> \n#>  [1] /Library/Frameworks/R.framework/Versions/4.3-x86_64/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}