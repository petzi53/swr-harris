{
  "hash": "a4acc654f0db65136abf5e764c9b2082",
  "result": {
    "engine": "knitr",
    "markdown": "# Computing Chi-Squared {#sec-chap05}\n\n\n\n\n\n## Achievements to unlock\n\n::: my-objectives\n::: my-objectives-header\nObjectives\n:::\n\n::: my-objectives-container\n**SwR Achievements**\n\n-   **Achievement 1**: Understanding the relationship between two\n    categorical variables using bar charts, frequencies, and percentages (@sec-chap05-achievement1)\n-   **Achievement 2**: Computing and comparing observed and expected\n    values for the groups (@sec-chap05-achievement2)\n-   **Achievement 3**: Calculating the chi-squared statistic for the\n    test of independence (@sec-chap05-achievement3)\n-   **Achievement 4**: Interpreting the chi-squared statistic and making\n    a conclusion about whether or not there is a relationship (@sec-chap05-achievement4)\n-   **Achievement 5**: Using Null Hypothesis Significance Testing to\n    organize statistical testing (@sec-chap05-achievement5)\n-   **Achievement 6**: Using standardized residuals to understand which\n    groups contributed to significant relationships (@sec-chap05-achievement6)\n-   **Achievement 7**: Computing and interpreting effect sizes to\n    understand the strength of a significant chi-squared relationship (@sec-chap05-achievement7)\n-   **Achievement 8**: Understanding the options for failed chi-squared\n    assumptions (@sec-chap05-achievement8)\n:::\n:::\n\n## The voter fraud problem\n\nInformation from studies suggests that voter fraud does happen but it\nis rare. In contrast to these studies a great minority of people (20-30%) in\nthe US believe that voter fraud is a big problem. Many states are\nbuilding barriers to vote, and other states make voting more easily, for\ninstance with automatic voter registration bills.\n\n## Resources & Chapter Outline\n\n### Data, codebook, and R packages {#sec-chap05-data-codebook-packages}\n\n::: my-resource\n::: my-resource-header\nData, codebook, and R packages for learning about descriptive statistics\n:::\n\n::: my-resource-container\n**Data**\n\nTwo options for assessing the data:\n\n1.  Download the data set `pew_apr_19-23_2017_weekly_ch5.sav` from\n    <https://edge.sagepub.com/harris1e>\n2.  Download the data set from the <a class='glossary' title='The Pew Research Center (also simply known as Pew) is a nonpartisan American think tank based in Washington, D.C. It provides information on social issues, public opinion, and demographic trends shaping the United States and the world. It also conducts public opinion polling, demographic research, random sample survey research, and panel based surveys, media content analysis, and other empirical social science research. (Wikipedia)'>Pew Research Center</a>\n    website\n    (<https://www.people-press.org/2017/06/28/public-supports-aimof-making-it-easy-for-all-citizens-to-vote/>)\n\n**Codebook**\n\nTwo options for assessing the documentation:\n\n1.  Download the documentation files `pew_voting_april_2017_ch5.pdf`,\n    `pew_voting_demographics_april_2017_ch5.docx`, and\n    `pew_chap5_readme.txt` from <https://edge.sagepub.com/harris1e>\n2.  Download the data set from the [Pew Research Center website](https://www.pewresearch.org/download-datasets/) and the\n    documentation will be included with the zipped file.\n\n**Packages**\n\n1.  Packages used with the book (sorted alphabetically)\n\n-   {**desc**}: @pak-descr (Jakson Alves de Aquino)\n-   {**fmsb**}: @pak-fmsb (Minato Nakazawa)\n-   {**haven**}: @pak-haven (Hadley Wickham)\n-   {**lsr**}: @pak-lsr (Danielle Navarro[^05-chi-squared-1])\n-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)\n\n2.  My additional packages (sorted alphabetically)\n:::\n:::\n\n[^05-chi-squared-1]: Not Daniel Navarro as mentioned in the book.\n    Danielle has changed her gender.\n\n### Get data\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-get-data}\n: Get data for chapter 5\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Pew data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-get-pew-data}\n: Get pew data about public support for making it easy to vote\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## run only once manually #########\nvote <- haven::read_sav(\"data/chap05/pew_apr_19-23_2017_weekly_ch5.sav\")\n\nvote <- vote |> \n    labelled::remove_labels()\nsave_data_file(\"chap05\", vote, \"vote.rds\")\n```\n:::\n\n\n***\n\n(*For this R code chunk is no output available*)\n\n:::::{.my-note}\n:::{.my-note-header}\nRemoving labels\n:::\n::::{.my-note-container}\n`haven::zap_labels()` as used in the book removes value labels and not variable labels. The correct function would be `haven::zap_label()`. I have used the {**labelled**} package where you can use `labelled::remove_labels()` to delete both (variable & value labels).\n::::\n:::::\n\n::::\n:::::\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nError message with labelled data\n:::\n::::{.my-watch-out-container}\nI have removed the labelled data immediately, because I got an error message caused by summary statistics (e.g., `base::summary()`, `skimr::skim()`, `dplyr::summarize()`) whenever I rendered the file (but not when I compiled the code chunk.) \n\nI didn't have time to look into this issue --- and I had to remove the labels anyway. \n\nWhat follows is the error message:\n\n```\nQuitting from lines 180-186 [show-pew-raw-data] (05-chi-squared.qmd)\nError in `dplyr::summarize()`:\nℹ In argument: `skimmed = purrr::map2(...)`.\nCaused by error in `purrr::map2()`:\nℹ In index: 1.\nℹ With name: character.\nCaused by error in `dplyr::summarize()`:\nℹ In argument: `dplyr::across(tidyselect::any_of(variable_names),\n  mangled_skimmers$funs)`.\nCaused by error in `across()`:\n! Can't compute column `state_~!@#$%^&*()-+character.empty`.\nCaused by error in `as.character()`:\n! Can't convert `x` <haven_labelled> to <character>.\nBacktrace:\n  1. skimr::skim(vote)\n 28. skimr (local) `<fn>`(state)\n 29. x %in% empty_strings\n 31. base::mtfrm.default(`<hvn_lbll>`)\n 33. vctrs:::as.character.vctrs_vctr(x)\n ```\n::::\n:::::\n\n\n\n\n\n###### header2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-code-name-b}\n: Numbered R Code Title (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 + 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n### Show raw data\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-show-data}\n: Show raw data for chapter 5\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Vote\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-show-pew-raw-data}\n: Get pew data about public support for making it easy to vote\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote <-  base::readRDS(\"data/chap05/vote.rds\")\nskimr::skim(vote)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |vote |\n|Number of rows           |1028 |\n|Number of columns        |49   |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |4    |\n|numeric                  |45   |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|case_id       |         0|             1|   8|   8|     0|     1028|          0|\n|state         |         0|             1|   2|   2|     0|       51|          0|\n|date          |         0|             1|   6|   6|     0|        5|          0|\n|pew1rot       |         0|             1|   5|   5|     0|      120|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd|     p0|   p25|    p50|    p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|------:|-----:|------:|------:|----:|:-----|\n|week          |         0|          1.00| 816.00|  0.00| 816.00| 816.0| 816.00| 816.00|  816|▁▁▇▁▁ |\n|metro         |         0|          1.00|   2.45|  1.61|   0.00|   1.0|   2.00|   3.00|    5|▇▃▅▁▅ |\n|region        |         0|          1.00|   2.62|  1.03|   1.00|   2.0|   3.00|   3.00|    4|▅▆▁▇▅ |\n|division      |         0|          1.00|   5.08|  2.48|   1.00|   3.0|   5.00|   7.00|    9|▆▇▆▅▇ |\n|pew1arot      |         0|          1.00|   1.53|  0.50|   1.00|   1.0|   2.00|   2.00|    2|▇▁▁▁▇ |\n|pew1a         |         0|          1.00|   1.72|  0.95|   1.00|   1.0|   2.00|   2.00|    9|▇▁▁▁▁ |\n|pew1brot      |         0|          1.00|   1.47|  0.50|   1.00|   1.0|   1.00|   2.00|    2|▇▁▁▁▇ |\n|pew1b         |         0|          1.00|   1.90|  0.90|   1.00|   2.0|   2.00|   2.00|    9|▇▁▁▁▁ |\n|pew1crot      |         0|          1.00|   1.49|  0.50|   1.00|   1.0|   1.00|   2.00|    2|▇▁▁▁▇ |\n|pew1c         |         0|          1.00|   1.63|  1.26|   1.00|   1.0|   1.00|   2.00|    9|▇▁▁▁▁ |\n|pew1drot      |         0|          1.00|   1.51|  0.50|   1.00|   1.0|   2.00|   2.00|    2|▇▁▁▁▇ |\n|pew1d         |         0|          1.00|   1.87|  1.02|   1.00|   1.0|   2.00|   2.00|    9|▇▁▁▁▁ |\n|pew1erot      |         0|          1.00|   1.50|  0.50|   1.00|   1.0|   2.00|   2.00|    2|▇▁▁▁▇ |\n|pew1e         |         0|          1.00|   1.78|  1.77|   1.00|   1.0|   1.00|   2.00|    9|▇▁▁▁▁ |\n|pew2rot       |         0|          1.00|   1.53|  0.50|   1.00|   1.0|   2.00|   2.00|    2|▇▁▁▁▇ |\n|pew2          |         0|          1.00|   1.42|  0.96|   1.00|   1.0|   1.00|   2.00|    9|▇▁▁▁▁ |\n|ownhome       |         0|          1.00|   1.48|  1.15|   1.00|   1.0|   1.00|   2.00|    9|▇▁▁▁▁ |\n|mstatus       |         0|          1.00|   3.22|  1.75|   1.00|   2.0|   3.00|   5.00|    9|▆▇▂▂▁ |\n|employ        |         0|          1.00|   2.53|  1.75|   1.00|   1.0|   2.00|   3.00|    9|▇▅▁▂▁ |\n|totper        |         0|          1.00|   2.66|  1.72|   1.00|   1.0|   2.00|   3.00|    9|▇▃▁▁▁ |\n|adults        |         0|          1.00|   2.23|  1.40|   1.00|   1.0|   2.00|   3.00|    9|▇▂▁▁▁ |\n|kids1217      |       791|          0.23|   0.77|  0.79|   0.00|   0.0|   1.00|   1.00|    4|▇▇▃▁▁ |\n|kids611       |       791|          0.23|   0.56|  0.75|   0.00|   0.0|   0.00|   1.00|    3|▇▃▁▂▁ |\n|kidsless6     |       791|          0.23|   0.58|  0.83|   0.00|   0.0|   0.00|   1.00|    4|▇▃▂▁▁ |\n|parent        |       791|          0.23|   1.26|  0.44|   1.00|   1.0|   1.00|   2.00|    2|▇▁▁▁▃ |\n|age           |         0|          1.00|  54.71| 21.35|  18.00|  37.0|  56.00|  70.00|   99|▆▆▇▆▃ |\n|age2          |       989|          0.04|   3.49|  1.85|   1.00|   2.0|   3.00|   4.00|    9|▅▇▁▁▁ |\n|totalage      |         0|          1.00|   2.77|  1.13|   1.00|   2.0|   3.00|   4.00|    9|▆▇▁▁▁ |\n|refage        |         0|          1.00|   2.91|  1.29|   1.00|   2.0|   3.00|   4.00|    9|▅▇▁▁▁ |\n|educ          |         0|          1.00|   5.55|  9.42|   1.00|   3.0|   4.00|   6.00|   99|▇▁▁▁▁ |\n|income        |         0|          1.00|  17.06| 30.62|   1.00|   3.0|   6.00|  12.00|   99|▇▁▁▁▁ |\n|race          |         0|          1.00|   4.48| 15.07|   1.00|   1.0|   1.00|   2.00|   99|▇▁▁▁▁ |\n|affilrot      |         0|          1.00|   1.50|  0.50|   1.00|   1.0|   2.00|   2.00|    2|▇▁▁▁▇ |\n|polparty      |         0|          1.00|   2.47|  1.65|   0.00|   1.0|   2.00|   3.00|    9|▃▇▁▁▁ |\n|polviewrot    |         0|          1.00|   1.49|  0.50|   1.00|   1.0|   1.00|   2.00|    2|▇▁▁▁▇ |\n|polview       |         0|          1.00|   3.29|  1.83|   1.00|   2.0|   3.00|   4.00|    9|▇▇▂▁▂ |\n|regvote       |         0|          1.00|   1.24|  0.72|   1.00|   1.0|   1.00|   1.00|    9|▇▁▁▁▁ |\n|c3a           |       384|          0.63|   2.13|  9.43|   0.00|   1.0|   1.00|   1.00|   99|▇▁▁▁▁ |\n|sex           |         0|          1.00|   1.52|  0.50|   1.00|   1.0|   2.00|   2.00|    2|▇▁▁▁▇ |\n|religion      |         0|          1.00|  34.01| 37.57|   1.00|   2.0|  15.00|  90.00|   99|▇▂▁▁▅ |\n|ident         |         0|          1.00|   1.68|  0.66|   1.00|   1.0|   2.00|   2.00|    4|▆▇▁▁▁ |\n|c1a           |        76|          0.93|   1.41|  1.22|   0.00|   1.0|   1.00|   1.00|    9|▇▂▁▁▁ |\n|bornus        |       878|          0.15|   1.99|  1.13|   1.00|   1.0|   1.50|   3.00|    9|▇▆▁▁▁ |\n|qnco3         |      1028|          0.00|    NaN|    NA|     NA|    NA|     NA|     NA|   NA|      |\n|popwght       |         0|          1.00|   1.00|  0.66|   0.25|   0.5|   0.84|   1.33|    4|▇▃▂▁▁ |\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n###### header2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-code-name-b}\n: Numbered R Code Title (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 + 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n### Recode data for chapter 5\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-recode-data}\n: Numbered Example Title\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Pew data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-recode-pew-data}\n: Select some columns from the pew data set\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote <-  base::readRDS(\"data/chap05/vote.rds\")\n\n## create vote_clean #############\nvote_clean <-  vote |> \n    dplyr::select(pew1a, pew1b, race, sex, \n                  mstatus, ownhome, employ, polparty) |> \n    labelled::remove_labels() |> \n    dplyr::mutate(dplyr::across(1:8, forcats::as_factor)) |> \n    naniar::replace_with_na(replace = list(\n        pew1a = c(5, 9),\n        pew1b = c(5, 9),\n        race = 99,\n        ownhome = c(8, 9)\n    )) |> \n    dplyr::mutate(pew1a = forcats::fct_recode(pew1a,\n             \"Register to vote\" = \"1\",\n             \"Make easy to vote\" = \"2\",\n             )) |> \n    dplyr::mutate(pew1b = forcats::fct_recode(pew1b,\n             \"Require to vote\" = \"1\",\n             \"Choose to vote\" = \"2\",\n             )) |> \n    dplyr::mutate(race = forcats::fct_recode(race,\n             \"White non-Hispanic\" = \"1\",\n             \"Black non-Hispanic\" = \"2\",\n             )) |> \n    dplyr::mutate(race = forcats::fct_collapse(race,\n             \"Hispanic\" = c(\"3\", \"4\", \"5\"),\n             \"Other\" = c(\"6\", \"7\", \"8\", \"9\", \"10\")\n    )) |> \n    dplyr::mutate(sex = forcats::fct_recode(sex,\n             \"Male\" = \"1\",\n             \"Female\" = \"2\",\n             )) |> \n    dplyr::mutate(ownhome = forcats::fct_recode(ownhome,\n             \"Owned\" = \"1\",\n             \"Rented\" = \"2\",\n             )) |> \n    dplyr::mutate(dplyr::across(1:8, forcats::fct_drop)) |> \n    dplyr::rename(ease_vote = \"pew1a\",\n                  require_vote = \"pew1b\")\n\nsave_data_file(\"chap05\", vote_clean, \"vote_clean.rds\")\n    \nskimr::skim(vote_clean)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |vote_clean |\n|Number of rows           |1028       |\n|Number of columns        |8          |\n|_______________________  |           |\n|Column type frequency:   |           |\n|factor                   |8          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                            |\n|:-------------|---------:|-------------:|:-------|--------:|:-------------------------------------|\n|ease_vote     |        27|          0.97|FALSE   |        2|Mak: 593, Reg: 408                    |\n|require_vote  |        17|          0.98|FALSE   |        2|Cho: 806, Req: 205                    |\n|race          |        25|          0.98|FALSE   |        4|Whi: 646, His: 150, Bla: 129, Oth: 78 |\n|sex           |         0|          1.00|FALSE   |        2|Fem: 533, Mal: 495                    |\n|mstatus       |         0|          1.00|FALSE   |        7|3: 422, 1: 229, 6: 139, 5: 126        |\n|ownhome       |        22|          0.98|FALSE   |        2|Own: 678, Ren: 328                    |\n|employ        |         0|          1.00|FALSE   |        9|1: 414, 3: 309, 2: 133, 6: 50         |\n|polparty      |         0|          1.00|FALSE   |        6|3: 398, 2: 314, 1: 249, 8: 31         |\n\n\n:::\n:::\n\n\n***\nI have used in this recoding R chunk several functions for the first time:\n\n- I turned all character columns into factor variables with just one line of code using `dplyr::across()` in combination with `forcats::as_factor()`.\n- I replaced missing values (NAs) with the `replace_with_na()` function of the {**naniar**} package (see @pak-naniar).\n- I combined several levels with `forcats::fct_collapse()`.\n- And finally I dropped all unused levels in the whole data.frame using `dplyr::across()` in conjunction with `forcats::fct_drop()`.\n\n\n::::\n:::::\n\n\n###### header2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-code-name-b}\n: Numbered R Code Title (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n## Achievement 1: Relationship of two categorical variables {#sec-chap05-achievement1}\n\n### Descriptive statistics\n\nFor better display I have reversed the order of the variables: Instead of grouping y ease of vote I will group by race/ethnicity. This will give a smaller table with only two columns instead of four that will not fit on the sceen without horizontal scrolling.\n\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-stats-voting-data}\n: Frequencies between two categorical variables\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### summarize()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-summarize-ease-voting}\n: Summarize relationship ease of vote and race/ethnicity\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## load vote_clean ##########\nvote_clean <-  base::readRDS(\"data/chap05/vote_clean.rds\")\n\nease_vote_sum <- vote_clean |> \n    tidyr::drop_na(ease_vote) |> \n    tidyr::drop_na(race) |> \n    dplyr::group_by(race, ease_vote) |> \n    ## either summarize\n    dplyr::summarize(n = dplyr::n(),\n                     .groups = \"keep\")\n    ## or count the observation in each group\n    # dplyr::count()\nease_vote_sum\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 8 × 3\n#> # Groups:   race, ease_vote [8]\n#>   race               ease_vote             n\n#>   <fct>              <fct>             <int>\n#> 1 White non-Hispanic Register to vote    292\n#> 2 White non-Hispanic Make easy to vote   338\n#> 3 Black non-Hispanic Register to vote     28\n#> 4 Black non-Hispanic Make easy to vote    98\n#> 5 Hispanic           Register to vote     51\n#> 6 Hispanic           Make easy to vote    97\n#> 7 Other              Register to vote     27\n#> 8 Other              Make easy to vote    46\n```\n\n\n:::\n:::\n\n***\nHere I used \"standard\" tidyverse code to count frequencies. Instead of the somewhat complex last code line I could have used just `dplyr::count()` with the same result.\n\n\n\n::::\n:::::\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nWATCH OUT! Prevent warning with `.groups` argument\n:::\n::::{.my-watch-out-container}\nBy using two variables inside `dplyr::group_by()` I got a warning message:\n\n> `summarise()` has grouped output by 'ease_vote'. \n> You can override using the `.groups` argument.\n\nAt first I had to set the chunk option `warning: false` to turn off this warning. But finally I managed to prevent the warning with R code. See the [summarize help page](https://dplyr.tidyverse.org/reference/summarise.html) under arguments `.groups`. Another option to suppress the warning would have been `options(dplyr.summarise.inform = FALSE)`. See also the two [comments in StackOverflow](https://stackoverflow.com/questions/71914704/override-using-groups-argument) and [r-stats-tips](https://rstats-tips.net/2020/07/31/get-rid-of-info-of-dplyr-when-grouping-summarise-regrouping-output-by-species-override-with-groups-argument/).\n::::\n:::::\n\n\n###### pivot_wider()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-pivot-wider-ease-voting}\n: Summarize by converting data from long to wide with `pivot_wider()` from {**tidyr**}\n::::::\n:::\n::::{.my-r-code-container}\n\n:::{#lst-chap05-pivot-wider-ease-voting}\n\n::: {.cell}\n\n```{.r .cell-code}\nease_vote_wider <- vote_clean |> \n    tidyr::drop_na(ease_vote) |> \n    tidyr::drop_na(race) |> \n    dplyr::group_by(race, ease_vote) |> \n    dplyr::summarize(\n        n = dplyr::n(),\n        .groups = \"keep\") |> \n    tidyr::pivot_wider(\n        names_from = ease_vote,\n        values_from = n\n    )\nease_vote_wider\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 4 × 3\n#> # Groups:   race [4]\n#>   race               `Register to vote` `Make easy to vote`\n#>   <fct>                           <int>               <int>\n#> 1 White non-Hispanic                292                 338\n#> 2 Black non-Hispanic                 28                  98\n#> 3 Hispanic                           51                  97\n#> 4 Other                              27                  46\n```\n\n\n:::\n:::\n\nSummarizing and converting data from long to wide with `pivot_wider()` from {**tidyr**}\n:::\n\n***\n\nWe get with `dplyr::pivot_wider()` a more neatly arranged table.\n::::\n:::::\n\n###### table()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-base-table-ease-voting}\n: Summarize with `base::table()`\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nease_vote_table <- base::table(vote_clean$race, vote_clean$ease_vote)\nease_vote_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                     \n#>                      Register to vote Make easy to vote\n#>   White non-Hispanic              292               338\n#>   Black non-Hispanic               28                98\n#>   Hispanic                         51                97\n#>   Other                            27                46\n```\n\n\n:::\n:::\n\n***\n\nNote that NA's are automatically excluded from the table.\n\n\n\n\n\n::::\n:::::\n\nWith the simple `base::table()` we will get a very similar result as in the more complex `dplyr::pivot_wider()` code variant in @lst-chap05-pivot-wider-ease-voting. \n\nBut I prefer in any case the tidyverse version for several reasons:\n\n:::::{.my-note}\n:::{.my-note-header}\nSome deficiencies of `base::table()` \n:::\n::::{.my-note-container}\n\n- `table()` does not accept data.frame as input and you can't therefore chain several commands together with the ` |> ` pipe.\n- `table()` does not output data.frames\n- `table()` is very difficult to format and to make it print ready.\n::::\n:::::\n\n###### xtabs()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-base-xtabs-ease-voting}\n: Summarize with a `stats::xtabs()`\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nease_vote_xtabs <- stats::xtabs(n ~ race + ease_vote, data = ease_vote_sum)\nease_vote_xtabs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                     ease_vote\n#> race                 Register to vote Make easy to vote\n#>   White non-Hispanic              292               338\n#>   Black non-Hispanic               28                98\n#>   Hispanic                         51                97\n#>   Other                            27                46\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n###### tabyl()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-tabyl-voting-data}\n: Frequencies with `tabyl()` from {**janitor**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean |> \n    janitor::tabyl(race, ease_vote, show_na = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                race Register to vote Make easy to vote\n#>  White non-Hispanic              292               338\n#>  Black non-Hispanic               28                98\n#>            Hispanic               51                97\n#>               Other               27                46\n```\n\n\n:::\n:::\n\n***\n\n`janitor::tabyl()` prevents the weaknesses of the `base::table()` function. It works with data.frames, is tidyverse compatible and has many `adorn_*` functions (`adorn_` stands for \"adornment\") to format the output values.\n::::\n:::::\n\n###### prop.table()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-contingency-prop-table-voting-data}\n: Summarize with a base R proportion contingency table \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase::prop.table(\n    base::table(`Race / Ethnicity` = vote_clean$race,\n          `Ease of voting` = vote_clean$ease_vote), margin = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                     Ease of voting\n#> Race / Ethnicity     Register to vote Make easy to vote\n#>   White non-Hispanic        0.4634921         0.5365079\n#>   Black non-Hispanic        0.2222222         0.7777778\n#>   Hispanic                  0.3445946         0.6554054\n#>   Other                     0.3698630         0.6301370\n```\n\n\n:::\n:::\n\n***\nAll was I said about flaws for `base::table()` is of course valid for the `base::prop.table()` function as well.\n\n::::\n:::::\n\n###### tabyl() formatted\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-janitor-voting-data}\n: Frequencies with `tabyl()` from {**janitor**} formatted\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean |> \n    janitor::tabyl(race, ease_vote, show_na = FALSE) |> \n    janitor::adorn_percentages(\"row\")  |> \n    janitor::adorn_pct_formatting(digits = 2)  |> \n    janitor::adorn_ns() |> \n    janitor::adorn_title(row_name = \"Race / Ethnicity\",\n                         col_name = \"Ease of voting\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                       Ease of voting                  \n#>    Race / Ethnicity Register to vote Make easy to vote\n#>  White non-Hispanic     46.35% (292)      53.65% (338)\n#>  Black non-Hispanic     22.22%  (28)      77.78%  (98)\n#>            Hispanic     34.46%  (51)      65.54%  (97)\n#>               Other     36.99%  (27)      63.01%  (46)\n```\n\n\n:::\n:::\n\n***\n\nIn this example you can see the power of the {**janitor**} package. The main purpose of the {**janitor**} is data cleaning, but because counting is such a fundamental part of data cleaning and exploration the `tabyl()` and `adorn_*()` has been included in this package.\n::::\n:::::\n\n###### Ease of voting\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-ease-voting-data}\n: Ease of voting by race / ethnicity\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap05-ease-voting}\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean |> \n    janitor::tabyl(race, ease_vote, show_na = FALSE) |> \n    janitor::adorn_percentages(\"row\")  |> \n    janitor::adorn_pct_formatting(digits = 2)  |> \n    janitor::adorn_ns() |> \n    janitor::adorn_title(row_name = \"Race / Ethnicity\",\n                         col_name = \"Ease of voting\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                       Ease of voting                  \n#>    Race / Ethnicity Register to vote Make easy to vote\n#>  White non-Hispanic     46.35% (292)      53.65% (338)\n#>  Black non-Hispanic     22.22%  (28)      77.78%  (98)\n#>            Hispanic     34.46%  (51)      65.54%  (97)\n#>               Other     36.99%  (27)      63.01%  (46)\n```\n\n\n:::\n:::\n\n\nEase of voting by race / ethnicity\n:::\n\n***\n\n::: {.callout-tip}\nThe voting registration policy a person favors differed by race/ethnicity.\n\n- White non-Hispanic participants were fairly evenly divided between those who thought people should register if they want to vote and those who thought voting should be made as easy as possible.\n- The other three race-ethnicity groups had larger percentages in favor of making it as easy as possible to vote.\n- Black non-Hispanic participants have the highest percentage (77.78%) in favor of making it easy to vote.\n:::\n\n\n::::\n:::::\n\n###### Require to vote\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-require-voting-data}\n: Voting as requirement or free choice by race /ethnicity\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap05-require-voting}\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean |> \n    janitor::tabyl(race, require_vote, show_na = FALSE) |> \n    janitor::adorn_percentages(\"row\")  |> \n    janitor::adorn_pct_formatting(digits = 2)  |> \n    janitor::adorn_ns() |> \n    janitor::adorn_title(row_name = \"Race / Ethnicity\",\n                         col_name = \"Voting as citizen duty or as a free choice?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                     Voting as citizen duty or as a free choice?               \n#>    Race / Ethnicity                             Require to vote Choose to vote\n#>  White non-Hispanic                                 15.02% (96)   84.98% (543)\n#>  Black non-Hispanic                                 32.28% (41)   67.72%  (86)\n#>            Hispanic                                 34.01% (50)   65.99%  (97)\n#>               Other                                 18.92% (14)   81.08%  (60)\n```\n\n\n:::\n:::\n\nVoting as requirement or free choice by race /ethnicity\n\n:::\n\n***\n\n::: {.callout-tip}\nDifferent ethnicities have distinct opinions about the character of voting. \n\n- About one-third of Black non-Hispanic and Hispanic believe that voting should be a requirement. But this means on the other hand, that at least two-third of both groups see voting as a free choice. \n- In contrast to this proportion are white non-Hispanic and other non-Hispanic ethnicities: In those groups more than 80% favor voting as a free choice.\n\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n:::::{.my-resource}\n:::{.my-resource-header}\nCross-Tabulation\n:::\n::::{.my-resource-container}\n\n- [Working with Tables in R](https://bookdown.org/kdonovan125/ibis_data_analysis_r4/working-with-tables-in-r.html) in [@donovan2019a].\n- [Cross-Tabulation in R](https://www.marsja.se/cross-tabulation-in-r-creating-interpreting-contingency-tables/): Creating & Interpreting Contingency Tables [@marsja2023].\n- [Tables in R](https://cran.r-project.org/web/packages/DescTools/vignettes/TablesInR.pdf): A Quick Practical Overview [@signorell2021], see also [@pak-DescTools].\n- [Introduction to Crosstable](https://cran.r-project.org/web/packages/crosstable/vignettes/crosstable.html) [@chalthiel2023], see also [@pak-crosstable].\n\n::::\n:::::\n\n\n### Graphs\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-descriptive-graphs}\n: Descriptive graphs\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### geom_col()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-pew-voting-geom-col-graph}\n: Visualizing opinions about ease of voting by race / ethnicity \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_ease_vote <- vote_clean |> \n    ## prepare data\n    tidyr::drop_na(ease_vote) |>\n    tidyr::drop_na(race) |>\n    dplyr::group_by(race, ease_vote) |>\n    dplyr::count() |>\n    dplyr::group_by(race) |>\n    dplyr::mutate(perc = n / base::sum(n)) |>\n    \n    ## draw graph\n    ggplot2::ggplot(\n        ggplot2::aes(\n            x = race, \n            y = perc,\n            fill = ease_vote)\n    ) +\n    ggplot2::geom_col(position = \"dodge\") +\n    ggplot2::scale_y_continuous(labels = scales::percent) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        x = \"Race / Ethnicity\",\n        y = \"Percent\"\n    ) +\n    ggplot2::scale_fill_viridis_d(\n        name = \"Ease of voting\",\n        alpha = .8, # here alpha works!!\n        begin = .25,\n         end = .75,\n        direction = -1,\n        option = \"viridis\"\n    )\n\np_ease_vote\n```\n\n::: {.cell-output-display}\n![Opinion on ease of voting by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)](05-chi-squared_files/figure-html/fig-pew-voting-geom-col-graph-1.png){#fig-pew-voting-geom-col-graph width=672}\n:::\n:::\n\n***\n\nI had several difficulties by drawing this graph:\n\n1. Most important: I did not know that the second variable `ease_vote` has to be included by the `fill` argument. That seems not logical but together with `position = dodge` it make sense.\n2. I didn't know that I have to group by race again (the line after `dplyr::count()`)\n3. I thought that I could calculate the percentages with `ggplot2::after_stat()`. The solution was more trivial: Creating a new column with the calculated percentages and using `geom_col()` instead of `geom_bar()`.\n\nInstead of the last line I could have used with the same result: `ggplot2::geom_bar(position = \"dodge\", stat = \"identity\")`. `geom_bar()` uses as standard option `ggplot2::stat_count()`. It is however possible to override the default value as was done in the book code. But it easier here to use `geom_col()` because it uses as default `stat_identity()` e.g., it leaves the data as is.\n\n::: {.callout-note}\n**Two additional remarks**:\n\n1. I have used here the percent scale from the {**scales**} package to get percent signs on the y-axis.\n2. I practiced my learnings from @sec-chap03 about adding a color-friendly palette (see @sec-chap03-practice-test). (See also my color test in @cnj-chap05-color-test-bw.)\n:::\n\n\n::::\n:::::\n\n###### geom_bar()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-pew-voting-geom-bar-graph}\n: Visualizing opinions about ease of voting by race / ethnicity \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean |> \n    tidyr::drop_na(ease_vote) |>\n    tidyr::drop_na(race) |>\n    ggplot2::ggplot(\n        ggplot2::aes(\n            x = race, \n            fill = ease_vote\n        )\n    ) +\n    ggplot2::geom_bar(position = \"dodge\",\n        ggplot2::aes(\n            y = ggplot2::after_stat(count / base::sum(count))\n        )) +\n    ggplot2::scale_y_continuous(labels = scales::percent) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        x = \"Race / Ethnicity\",\n        y = \"Percent\"\n    ) +\n    ggplot2::scale_fill_viridis_d(\n        name = \"Ease of voting\",\n        alpha = .8, # here alpha works!!\n        begin = .25,\n         end = .75,\n        direction = -1,\n        option = \"viridis\"\n    )\n```\n\n::: {.cell-output-display}\n![Opinion on ease of voting by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)](05-chi-squared_files/figure-html/fig-pew-voting-geom-bar-graph-1.png){#fig-pew-voting-geom-bar-graph width=672}\n:::\n:::\n\n***\n\nHere I have used `geom_bar()` with the `after_stat()` calculation. It turned out that the function computes the percentages of the different race categories for the two `ease_vote` values. This was not was I had intended.\n\nI tried for several hours to use `after_stat()` with the same result as in @cnj-chap05-pew-voting-geom-col-graph, but I didn't succeed. I do not know if the reason is my missing knowledge (for instance to generate another structure of the data.frame) or if you can't do that in general. \n\n::::\n:::::\n\n###### geom_col() with labels\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-pew-voting-geom-col-label-graph}\n: Visualizing opinions about ease of voting by race / ethnicity \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean |> \n    tidyr::drop_na(ease_vote) |>\n    tidyr::drop_na(race) |>\n    dplyr::group_by(race, ease_vote) |>\n    dplyr::count() |>\n    dplyr::group_by(race) |>\n    dplyr::mutate(perc = n / base::sum(n)) |>\n    ggplot2::ggplot(\n        ggplot2::aes(\n            x = race, \n            y = perc,\n            fill = ease_vote)\n    ) +\n    ggplot2::geom_col(position = \"dodge\") +\n    ggplot2::geom_label(\n        ggplot2::aes(\n            x = race,\n            y = perc,\n            label = paste0(round(100 * perc, 1),\"%\"),\n            vjust = 1.5, hjust = -.035\n        ),\n        color = \"white\"\n    ) +\n    ggplot2::scale_y_continuous(labels = scales::percent) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        x = \"Race / Ethnicity\",\n        y = \"Percent\"\n    ) +\n    ggplot2::scale_fill_viridis_d(\n        name = \"Ease of voting\",\n        alpha = .8, # here alpha works!!\n        begin = .25,\n         end = .75,\n        direction = -1,\n        option = \"viridis\"\n    )\n```\n\n::: {.cell-output-display}\n![Opinion on ease of voting by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)](05-chi-squared_files/figure-html/fig-pew-voting-geom-col-label-graph-1.png){#fig-pew-voting-geom-col-label-graph width=672}\n:::\n:::\n\n***\n\nHere I have experimented with labels. It seems that with the argument `position = dodge` the labels can't appear on each of the appropriate bars.\n\n::::\n:::::\n\n###### requirements\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-pew-voting-requirements-by-race}\n: Visualizing opinions about requirements of voting by race / ethnicity \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_require_vote <- vote_clean |> \n    ## prepare data\n    tidyr::drop_na(require_vote) |>\n    tidyr::drop_na(race) |>\n    dplyr::group_by(race, require_vote) |>\n    dplyr::count() |>\n    dplyr::group_by(race) |>\n    dplyr::mutate(perc = n / base::sum(n)) |>\n    \n    ## draw graph\n    ggplot2::ggplot(\n        ggplot2::aes(\n            x = race, \n            y = perc,\n            fill = require_vote)\n    ) +\n    ggplot2::geom_col(position = \"dodge\") +\n    ggplot2::scale_y_continuous(labels = scales::percent) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        x = \"Race / Ethnicity\",\n        y = \"Percent\"\n    ) +\n    ggplot2::scale_fill_viridis_d(\n        name = \"Requirements of voting\",\n        alpha = .8, # here alpha works!!\n        begin = .25,\n         end = .75,\n        direction = -1,\n        option = \"viridis\"\n    )\n\np_require_vote\n```\n\n::: {.cell-output-display}\n![Opinion on voting requirements by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)](05-chi-squared_files/figure-html/fig-pew-voting-requirements-by-race-1.png){#fig-pew-voting-requirements-by-race width=672}\n:::\n:::\n\n\n\n\n::::\n:::::\n\n###### Voting by race\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-voting-opinions-by-race}\n: Visualizing opinions about voting by race / ethnicity \n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\np_ease <- p_ease_vote +\n    ggplot2::labs(\n        x = \"\",\n        y = \"Percent within group\"\n    ) +\n    ggplot2::scale_fill_viridis_d(\n        name = \"Opinion on\\nvoter registration\",\n        alpha = .8, \n        begin = .25,\n        end = .75,\n        direction = -1,\n        option = \"viridis\"\n    ) +\n    ggplot2::theme(axis.text.x = ggplot2::element_blank())\n\np_require <- p_require_vote +\n    ggplot2::labs(y = \"Percent within group\") +\n    ggplot2::scale_fill_viridis_d(\n        name = \"Opinion on\\nvoting\",\n        alpha = .8,\n        begin = .25,\n        end = .75,\n        direction = -1,\n        option = \"viridis\"\n    )\n\ngridExtra::grid.arrange(p_ease, p_require, ncol = 1)\n```\n\n::: {.cell-output-display}\n![Opinion on ease of voting and voting requirements by race / ethnicity from a study of the Pew Research Center 2017 (n = 1,028)](05-chi-squared_files/figure-html/fig-pew-voting-by-race-1.png){#fig-pew-voting-by-race width=672}\n:::\n:::\n\n\n::::\n:::::\n\n\n###### Color test\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-color-test-bw}\n: Test how the colors used for the graph race by ease of voting look for printing in black & white\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {#lst-chap05-color-test-bw}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npal_data <- list(names = c(\"Normal\", \"desaturated\"),\n    color = list(scales::viridis_pal(\n                                alpha = .8, \n                                begin = .25, \n                                 end = .75, \n                                direction = -1, \n                                option = \"viridis\")(2),\n    colorspace::desaturate(scales::viridis_pal(\n                                alpha = .8, \n                                begin = .25, \n                                end = .75, \n                                direction = -1, \n                                option = \"viridis\")(2)))\n    )\nlist_plotter(pal_data$color, pal_data$names, \n    \"Colors and black & white of graph race by ease of voting\")\n```\n\n::: {.cell-output-display}\n![Test if used colors of my graph race by ease of voting look are also readable for black & white printing](05-chi-squared_files/figure-html/fig-color-test-bw-1.png){#fig-color-test-bw width=672}\n:::\n:::\n\n\nTest how the colors I have used for my graphs about race by ease of voting look in black & white\n:::\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n\n## Achievement 2: Comparing groups {#sec-chap05-achievement2}\n\nThe <a class='glossary' title='Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary)'>chi-squared</a> test is useful for testing to see if there may be a statistical relationship between two categorical variables. The chi-squared test is based on the observed values, and the values expected to occur if there were no relationship between the variables.\n\n### Observed values\n\nWe will use the observed values from @lst-chap05-ease-voting and @lst-chap05-require-voting.\n\n### Expected values\n\nFor each cell in the table, multiply the row total for that row by the column total for that column and divide by the overall total.\n\nTo prevent manually computing the values I have used `CrossTable()` from the {**descr**} package (see @pak-descr and [StackOverflow](https://stackoverflow.com/a/34214973/7322615)).\n\n$$\n\\text{Expected Values} = \\frac{rowTotal \\times columnTotal}{Total}\n$$ {#eq-expected-values}\n\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-expected-values}\n: Show observed and expected values\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Ease\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-expected-ease-vote}\n: Ease of voting by race / ethnicity\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean <- base::readRDS(\"data/chap05/vote_clean.rds\")\n\nvote_opinions <- vote_clean |> \n    dplyr::select(race, ease_vote, require_vote) |>\n    tidyr::drop_na()\n\nct_ease <- descr::CrossTable(\n    x = vote_opinions$race,\n    y = vote_opinions$ease_vote,\n    dnn = c(\"Race\", \"Ease of voting\"),\n    prop.r = FALSE, \n    prop.c = FALSE, \n    prop.t = FALSE,\n    prop.chisq = FALSE,\n    expected = TRUE\n    )\nct_ease\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>    Cell Contents \n#> |-------------------------|\n#> |                       N | \n#> |              Expected N | \n#> |-------------------------|\n#> \n#> ==================================================================\n#>                       Ease of voting\n#> Race                  Register to vote   Make easy to vote   Total\n#> ------------------------------------------------------------------\n#> White non-Hispanic                 292                 335     627\n#>                                  255.5               371.5        \n#> ------------------------------------------------------------------\n#> Black non-Hispanic                  27                  97     124\n#>                                   50.5                73.5        \n#> ------------------------------------------------------------------\n#> Hispanic                            50                  96     146\n#>                                   59.5                86.5        \n#> ------------------------------------------------------------------\n#> Other                               25                  45      70\n#>                                   28.5                41.5        \n#> ------------------------------------------------------------------\n#> Total                              394                 573     967\n#> ==================================================================\n```\n\n\n:::\n:::\n\n\n***\n\n::: {.callout-tip}\n\n- Some of the cells have observed and expected values that are very close to each other. For example, the observed number of Other race-ethnicity people who want to make it easy to vote is 46, while the expected is 43.3. \n- But other categories show bigger differences. For example, the observed number of Black non-Hispanics who think people should register to vote is 28, and the expected value is nearly twice as high at 51.3.\n:::\n\n::::\n:::::\n\n###### Require\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-exprected-race-by-require}\n: Status of voting by race / ethnicity\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nct_require <- descr::CrossTable(\n        x = vote_opinions$race,\n        y = vote_opinions$require_vote,\n        dnn = c(\"Race\", \"Status of voting\"),\n        prop.r = FALSE, \n        prop.c = FALSE, \n        prop.t = FALSE,\n        prop.chisq = FALSE,\n        expected = TRUE\n    )\nct_require\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>    Cell Contents \n#> |-------------------------|\n#> |                       N | \n#> |              Expected N | \n#> |-------------------------|\n#> \n#> ==============================================================\n#>                       Status of voting\n#> Race                  Require to vote   Choose to vote   Total\n#> --------------------------------------------------------------\n#> White non-Hispanic                 95              532     627\n#>                                 128.4            498.6        \n#> --------------------------------------------------------------\n#> Black non-Hispanic                 40               84     124\n#>                                  25.4             98.6        \n#> --------------------------------------------------------------\n#> Hispanic                           50               96     146\n#>                                  29.9            116.1        \n#> --------------------------------------------------------------\n#> Other                              13               57      70\n#>                                  14.3             55.7        \n#> --------------------------------------------------------------\n#> Total                             198              769     967\n#> ==============================================================\n```\n\n\n:::\n:::\n\n\n***\n\n::: {.callout-tip}\nThe cell \"Other\" has similar observed and expected values, but the rest have bigger differences.\n:::\n\n::::\n:::::\n\n###### Both\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-expected-voting-data}\n: Computing ease and require of voting using the {**sjstats**} package\n::::::\n:::\n::::{.my-r-code-container}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## load vote_clean ##########\nvote_clean <-  base::readRDS(\"data/chap05/vote_clean.rds\")\n\nvote_clean2 <- vote_clean |> \n    dplyr::select(race, ease_vote, require_vote) |> \n    tidyr::drop_na()\n\nease_vote_n <- vote_clean2 |> \n    dplyr::select(race, ease_vote) |> \n    dplyr::group_by(race, ease_vote) |> \n    dplyr::summarize(n_ease = dplyr::n(),\n                     .groups = \"keep\")\n\nease_expected  <-  \n    tibble::as_tibble(\n        base::as.data.frame(\n            sjstats::table_values(\n                base::table(\n                    vote_clean$race, \n                    vote_clean$ease_vote)\n                )$expected,\n                .name_repair = \"unique\")) |> \n    dplyr::arrange(Var1)\n\n(\n    ease_expected2 <- dplyr::bind_cols(\n    ease_vote_n,\n    exp_ease = ease_expected$Freq)\n)\n\nglue::glue(\" \")\nglue::glue(\"**********************************************************\")\nglue::glue(\" \")\n\nrequire_vote_n <- vote_clean2 |> \n    dplyr::select(race, require_vote) |> \n    dplyr::group_by(race, require_vote) |> \n    dplyr::summarize(n_require = dplyr::n(),\n                     .groups = \"keep\")\n\nrequire_expected  <-  \n    tibble::as_tibble(\n        base::as.data.frame(\n            sjstats::table_values(\n                base::table(\n                    vote_clean$race, \n                    vote_clean$require_vote)\n                )$expected,\n                .name_repair = \"unique\")) |> \n    dplyr::arrange(Var1)\n\n(\n    require_expected2 <- dplyr::bind_cols(\n    require_vote_n,\n    exp_require = require_expected$Freq)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 8 × 4\n#> # Groups:   race, ease_vote [8]\n#>   race               ease_vote         n_ease exp_ease\n#>   <fct>              <fct>              <int>    <dbl>\n#> 1 White non-Hispanic Register to vote     292      257\n#> 2 White non-Hispanic Make easy to vote    335      373\n#> 3 Black non-Hispanic Register to vote      27       51\n#> 4 Black non-Hispanic Make easy to vote     97       75\n#> 5 Hispanic           Register to vote      50       60\n#> 6 Hispanic           Make easy to vote     96       88\n#> 7 Other              Register to vote      25       30\n#> 8 Other              Make easy to vote     45       43\n#>  \n#> **********************************************************\n#>  \n#> # A tibble: 8 × 4\n#> # Groups:   race, require_vote [8]\n#>   race               require_vote    n_require exp_require\n#>   <fct>              <fct>               <int>       <dbl>\n#> 1 White non-Hispanic Require to vote        95         130\n#> 2 White non-Hispanic Choose to vote        532         509\n#> 3 Black non-Hispanic Require to vote        40          26\n#> 4 Black non-Hispanic Choose to vote         84         101\n#> 5 Hispanic           Require to vote        50          30\n#> 6 Hispanic           Choose to vote         96         117\n#> 7 Other              Require to vote        13          15\n#> 8 Other              Choose to vote         57          59\n```\n\n\n:::\n:::\n\n\n***\n\nThe `sjstats::table_values()` function has the advantage that it can be converted to a data.frame. We can therefore manipulate the data and --- for example --- combine expected data for different variables.\n\n\n::::\n:::::\n\n###### Together\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-expected-vote-data}\n: : Combining ease and require of voting\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire_expected3 <- require_expected2 |> \n    dplyr::ungroup() |> \n    dplyr::select(-1)\n\nvote_expected <- dplyr::bind_cols(\n    ease_expected2,\n    require_expected3\n)\n\nvote_expected\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 8 × 7\n#> # Groups:   race, ease_vote [8]\n#>   race              ease_vote n_ease exp_ease require_vote n_require exp_require\n#>   <fct>             <fct>      <int>    <dbl> <fct>            <int>       <dbl>\n#> 1 White non-Hispan… Register…    292      257 Require to …        95         130\n#> 2 White non-Hispan… Make eas…    335      373 Choose to v…       532         509\n#> 3 Black non-Hispan… Register…     27       51 Require to …        40          26\n#> 4 Black non-Hispan… Make eas…     97       75 Choose to v…        84         101\n#> 5 Hispanic          Register…     50       60 Require to …        50          30\n#> 6 Hispanic          Make eas…     96       88 Choose to v…        96         117\n#> 7 Other             Register…     25       30 Require to …        13          15\n#> 8 Other             Make eas…     45       43 Choose to v…        57          59\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n:::::{.my-important}\n:::{.my-important-header}\nDifferences between observed values and expected indicates that there may be a relationship between the variables. \n:::\n:::::\n\n### Assumptions of the chi-squared test of independence\n\n***\n\n::: {#bul-chap05-assumptions-chi-squared}\n- **The variables must be nominal or ordinal (usually nominal)**. We have categorical data with no order, e.g., nominal data: *The assumption is met.*\n- **The expected values should be 5 or higher in at least 80% of groups**. We have 8 cells with values. None of these cells are 5 or lower: *The assumption is met.*\n- **The observations must be independent**. We have neither the same set of people asked before and after an intervention nor do are the respondents family members or other affiliated with each other: *The assumption is met. *\n\nAssumptions for the chi-squared test\n\n:::\n------------------------------------------------------------------------\n\n## Calculating the chi-squared statistic {#sec-chap05-achievement3}\n\nThe differences between observed values and expected values can be combined into an overall statistic. But adding (resp. subtracting) does not work as the result is always 0. So we will again --- like in the variance --- square the difference.\n\nTo prevent huge differences when observed and expected values are very large, there is an additional step in the computation of $\\chi^2$: Divide the squared differences by the expected value of the appropriate cells.\n\n$$\n\\chi^2 = \\sum\\frac{(observed - expected)^2}{expected}\n$$ {#eq-chi-squared}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-chi-squared-ease-voting}\n: Compute chi-squared for race by ease of voting\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_clean <- base::readRDS(\"data/chap05/vote_clean.rds\")\n\nstats::chisq.test(\n    x = vote_clean$ease_vote,\n    y = vote_clean$race\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tPearson's Chi-squared test\n#> \n#> data:  vote_clean$ease_vote and vote_clean$race\n#> X-squared = 28.952, df = 3, p-value = 2.293e-06\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n## Achievement 4: Interpreting the chi-squared statistic {#sec-chap05-achievement4}\n\nIn contrast to the binomial and normal distribution which both have two parameters (n and p, resp. $\\mu$ and $\\sigma$), the <a class='glossary' title='Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary)'>chi-squared</a> distribution has only one <a class='glossary' title='Unobserved variables are usually called Parameters. (SR2, Chap.2) A parameter is an unknown numerical characteristics of a population that must be estimated. (CDS). They are also numbers that govern statistical models (stats.stackexchange). A parameter is also a number that is a defining characteristic of some population or a feature of a population. (SwR, Glossary)'>parameter</a>: the <a class='glossary' title='Degree of Freedom (df) is the number of pieces of information that are allowed to vary in computing a statistic before the remaining pieces of information are known; degrees of freedom are often used as parameters for distributions (e.g., chi-squared, F). (SwR, Glossary)'>degrees of freedom</a>. The `df` can be used to find the population <a class='glossary' title='The standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. The standard deviation is the square root of its variance. A useful property of the standard deviation is that, unlike the variance, it is expressed in the same unit as the data. Standard deviation may be abbreviated SD, and is most commonly represented in mathematical texts and equations by the lower case Greek letter \\(\\sigma\\) (sigma), for the population standard deviation, or the Latin letter \\(s\\) for the sample standard deviation. (Wikipedia)'>standard deviation</a> for the distribution:\n\n$$\n\\sqrt{2df}\n$$ {#eq-pop-sd-df}\n\n\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap05-chi-squared-dist}\n: Chi-square probability distributions with different degrees of freedom\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### 4 $\\chi^2$ dist extra\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-chi-squared-separately}\n: Four chi-square probability distributions with different degrees of freedom\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define sequence of x-values\ntib <- tibble::tibble(x = seq(0, 30, length.out = 600))\n\ntib <- tib |> \n# Compute density values\n    dplyr::mutate(\n        y1 = stats::dchisq(x, df = 1),\n        y3 = stats::dchisq(x, df = 3),\n        y5 = stats::dchisq(x, df = 5),\n        y7 = stats::dchisq(x, df = 7)\n    )  \nchi_sq1 <- tib |> \n# Plot the Chi-square distribution: df = 1\n    ggplot2::ggplot(ggplot2::aes(x = x, y = y1)) +\n    ggplot2::geom_line(color = \"blue\") +\n    ggplot2::labs(x = \"x\", y = \"Density\", \n      title = paste(\"Chi-square with 1 degree of freedom\")) +\n    ggplot2::theme_bw()\n\nchi_sq3 <- tib |> \n# Plot the Chi-square distribution: df = 3\n    ggplot2::ggplot(ggplot2::aes(x = x, y = y3)) +\n    ggplot2::geom_line(color = \"blue\") +\n    ggplot2::labs(x = \"x\", y = \"Density\", \n      title = paste(\"Chi-square with 3 degrees of freedom\")) +\n    ggplot2::theme_bw()\n\nchi_sq5 <- tib |> \n# Plot the Chi-square distribution: df = 5\n    ggplot2::ggplot(ggplot2::aes(x = x, y = y5)) +\n    ggplot2::geom_line(color = \"blue\") +\n    ggplot2::labs(x = \"x\", y = \"Density\", \n      title = paste(\"Chi-square with 5 degrees of freedom\")) +\n    ggplot2::theme_bw()\n\nchi_sq7 <- tib |> \n# Plot the Chi-square distribution: df = 7\n    ggplot2::ggplot(ggplot2::aes(x = x, y = y7)) +\n    ggplot2::geom_line(color = \"blue\") +\n    ggplot2::labs(x = \"x\", y = \"Density\", \n      title = paste(\"Chi-square with 7 degrees of freedom\")) +\n    ggplot2::theme_bw()\n\ngridExtra::grid.arrange(chi_sq1, chi_sq3, chi_sq5, chi_sq7, ncol = 2)\n```\n\n::: {.cell-output-display}\n![Chi-square probability distributions with different degrees of freedom](05-chi-squared_files/figure-html/fig-chi-squared-dist-1.png){#fig-chi-squared-dist width=672}\n:::\n:::\n\n***\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nWATCH OUT! The graphs have different y scales!\n:::\n::::{.my-watch-out-container}\nThis is the replication of Figure 5.7 from the book.\n\nNote: The first impression --- that all probability distributions have same height --- is wrong! All four graphs have very different density scales! \n\nWe will see that all four distributions overlaid into one graphic will give a different impression.\n::::\n:::::\n\n\n\n\n::::\n:::::\n\n\n###### 4 $\\chi^2$ dist together\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-chi-squared-dist-together}\n: Four chi-square probability distributions with different degrees of freedom in one graph\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define sequence of x-values\ntib_chisq <- tibble::tibble(x = seq(0, 30, length.out = 600))\n\ntib_chisq |> \n# Compute density values\n    dplyr::mutate(\n        y1 = stats::dchisq(x, df = 1),\n        y3 = stats::dchisq(x, df = 3),\n        y5 = stats::dchisq(x, df = 5),\n        y7 = stats::dchisq(x, df = 7)\n    ) |> \n\n    ggplot2::ggplot() +\n    ggplot2::geom_line(\n        ggplot2::aes(x = x, y = y1),\n        color = \"blue\"\n    ) +\n    ggplot2::geom_line(\n        ggplot2::aes(x = x, y = y3),\n        color = \"red\"\n    ) +\n    ggplot2::geom_line(\n    ggplot2::aes(x = x, y = y5),\n    color = \"darkgreen\"\n    ) +\n    ggplot2::geom_line(\n    ggplot2::aes(x = x, y = y7),\n    color = \"black\"\n    ) +\n    ggplot2::ylim(0, .3) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        y = \"Density\"\n    )\n\n# sjPlot::dist_chisq(deg.f = 4) +\n# sjPlot::dist_chisq(deg.f = 6) +\n#     ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Four chi-square probability distributions with different degrees of freedom](05-chi-squared_files/figure-html/fig-chi-squared-dist-together-1.png){#fig-chi-squared-dist-together width=672}\n:::\n:::\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n## Exercises (empty)\n\n## Packages introduced in this chapter \n\n### crosstable\n\n:::::{.my-resource}\n:::{.my-resource-header}\ncrosstable: Crosstables for Descriptive Analyses \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-crosstable}\n\n***\n\n{**crosstable**}: [Crosstables for Descriptive Analyses](https://danchaltiel.github.io/crosstable/) [@crosstable]\n\n::: {layout=\"[10, 30]\" layout-valign=\"center\"}\n![](img/chap05/logoi/logo-crosstable-min.png){width=\"176\"}\n\n\nCrosstable is a package centered on a single function, crosstable, which easily computes descriptive statistics on datasets. It can use the {**tidyverse**} syntax and is interfaced with the package {**officer**} to create automatized reports.\n\n:::\n\nCreate descriptive tables for continuous and categorical variables. Apply summary statistics and counting function, with or without a grouping variable, and create beautiful reports using {**rmarkdown**} or {**officer**}. You can also compute effect sizes and statistical tests if needed.\n\n{**crosstable**}: Crosstables for Descriptive Analyses\n:::\n\n\n***\n::::\n:::::\n\n### DescTools\n\n:::::{.my-resource}\n:::{.my-resource-header}\nDescTools: Tools for Descriptive Statistics \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-DescTools}\n\n***\n\n{**DescTools**}: [Tools for Descriptive Statistics](https://andrisignorell.github.io/DescTools/) [@DescTools]\n\n\n(*There is no hexagon logo for {**DescTools**} available*)\n\n:::\n\nA collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. \n\nThe package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.\n\n{**DescTools**}: Tools for Descriptive Statistics\n:::\n\n***\n::::\n:::::\n\n\n\n### fmsb\n\n:::::{.my-resource}\n:::{.my-resource-header}\nfmsb: Functions for Medical Statistics Book with some Demographic Data \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-fmsb}\n\n***\n\n{**fmsb**}: [Functions for Medical Statistics Book with some Demographic Data](https://cran.r-project.org/package=fmsb) [@fmsb]\n\n(*There is no hexagon logo for {**fmsb**} available*)\n\n\nSeveral utility functions for the book entitled \"Practices of Medical and Health Data Analysis using R\" (Pearson Education Japan, 2007) with Japanese demographic data and some demographic analysis related functions.\n\n{**fmsb**}: Functions for Medical Statistics Book with some Demographic Data\n:::\n\n***\n::::\n:::::\n\n### lsr\n\n:::::{.my-resource}\n:::{.my-resource-header}\nlsr: Companion to \"Learning Statistics with R\" \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-lsr}\n\n***\n\n{**lsr**}: [Companion to \"Learning Statistics with R\"](https://learningstatisticswithr.com/) [@lsr]\n\n(*There is no hexagon logo for {**lsr**} available*)\n\nA collection of tools intended to make introductory statistics easier to teach, including wrappers for common hypothesis tests and basic data manipulation. It accompanies Navarro, D. J. (2015). Learning Statistics with R: A Tutorial for Psychology Students and Other Beginners, Version 0.6. \n\n\n{**lsr**}: Companion to \"Learning Statistics with R\"\n:::\n\n***\n::::\n:::::\n\n### naniar\n\n:::::{.my-resource}\n:::{.my-resource-header}\nnaniar: Data Structures, Summaries, and Visualisations for Missing Data \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-naniar}\n\n***\n\n{**naniar**}: [https://github.com/njtierney/naniar](https://naniar.njtierney.com/) [@naniar]\n\n::: {layout=\"[10, 30]\" layout-valign=\"center\"}\n![](img/chap05/logoi/logo-naniar-min.png){width=\"176\"}\n\n\n{**naniar**} provides principled, tidy ways to summarise, visualise, and manipulate missing data with minimal deviations from the workflows in ggplot2 and tidy data.\n\n:::\n\nMissing values are ubiquitous in data and need to be explored and handled in the initial stages of analysis. {**naniar**} provides data structures and functions that facilitate the plotting of missing values and examination of imputations. This allows missing data dependencies to be  explored with minimal deviation from the common work patterns of 'ggplot2' and tidy data. The work is fully discussed in Tierney & Cook [-@tierney2023].\n\n{**naniar**}: https://github.com/njtierney/naniar\n:::\n\n\n***\n::::\n:::::\n\n\n## Glossary\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Chi-squared </td>\n   <td style=\"text-align:left;\"> Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Degrees of Freedom </td>\n   <td style=\"text-align:left;\"> Degree of Freedom (df) is the number of pieces of information that are allowed to vary in computing a statistic before the remaining pieces of information are known; degrees of freedom are often used as parameters for distributions (e.g., chi-squared, F). (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Parameter </td>\n   <td style=\"text-align:left;\"> Unobserved variables are usually called Parameters. (SR2, Chap.2) A parameter is an unknown numerical characteristics of a population that must be estimated. (CDS). They are also numbers that govern statistical models ([stats.stackexchange](https://stats.stackexchange.com/a/255994/207389)). A parameter is also a number that is a defining characteristic of some population or a feature of a population. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Pew Research Center </td>\n   <td style=\"text-align:left;\"> The Pew Research Center (also simply known as Pew) is a nonpartisan American think tank based in Washington, D.C. It provides information on social issues, public opinion, and demographic trends shaping the United States and the world. It also conducts public opinion polling, demographic research, random sample survey research, and panel based surveys, media content analysis, and other empirical social science research. (&lt;a href=\"https://en.wikipedia.org/wiki/Pew_Research_Center\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Standard Deviation </td>\n   <td style=\"text-align:left;\"> The standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. The standard deviation is the square root of its variance. A useful property of the standard deviation is that, unlike the variance, it is expressed in the same unit as the data. Standard deviation may be abbreviated SD, and is most commonly represented in mathematical texts and equations by the lower case Greek letter $\\sigma$ (sigma), for the population standard deviation, or the Latin letter $s$ for the sample standard deviation. ([Wikipedia] </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Session Info {.unnumbered}\n\n::: my-r-code\n::: my-r-code-header\nSession Info\n:::\n\n::: my-r-code-container\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.3.2 (2023-10-31)\n#>  os       macOS Sonoma 14.3.1\n#>  system   x86_64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Europe/Vienna\n#>  date     2024-03-10\n#>  pandoc   3.1.12.2 @ /usr/local/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  package     * version    date (UTC) lib source\n#>  base64enc     0.1-3      2015-07-28 [1] CRAN (R 4.3.0)\n#>  cli           3.6.2      2023-12-11 [1] CRAN (R 4.3.0)\n#>  colorspace    2.1-1      2024-01-03 [1] R-Forge (R 4.3.2)\n#>  commonmark    1.9.1      2024-01-30 [1] CRAN (R 4.3.2)\n#>  curl          5.2.0      2023-12-08 [1] CRAN (R 4.3.2)\n#>  digest        0.6.34     2024-01-11 [1] CRAN (R 4.3.0)\n#>  dplyr         1.1.4      2023-11-17 [1] CRAN (R 4.3.0)\n#>  evaluate      0.23       2023-11-01 [1] CRAN (R 4.3.0)\n#>  fansi         1.0.6      2023-12-08 [1] CRAN (R 4.3.0)\n#>  farver        2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n#>  fastmap       1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n#>  forcats       1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n#>  generics      0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n#>  ggplot2       3.5.0      2024-02-23 [1] CRAN (R 4.3.2)\n#>  glossary    * 1.0.0.9000 2023-08-12 [1] Github (debruine/glossary@819e329)\n#>  glue          1.7.0      2024-01-09 [1] CRAN (R 4.3.0)\n#>  gridExtra     2.3        2017-09-09 [1] CRAN (R 4.3.0)\n#>  gtable        0.3.4      2023-08-21 [1] CRAN (R 4.3.0)\n#>  haven         2.5.4      2023-11-30 [1] CRAN (R 4.3.2)\n#>  here          1.0.1      2020-12-13 [1] CRAN (R 4.3.0)\n#>  highr         0.10       2022-12-22 [1] CRAN (R 4.3.0)\n#>  hms           1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n#>  htmltools     0.5.7      2023-11-03 [1] CRAN (R 4.3.0)\n#>  htmlwidgets   1.6.4      2023-12-06 [1] CRAN (R 4.3.0)\n#>  janitor       2.2.0      2023-02-02 [1] CRAN (R 4.3.0)\n#>  jsonlite      1.8.8      2023-12-04 [1] CRAN (R 4.3.0)\n#>  kableExtra    1.4.0      2024-01-24 [1] CRAN (R 4.3.2)\n#>  knitr         1.45       2023-10-30 [1] CRAN (R 4.3.0)\n#>  labeling      0.4.3      2023-08-29 [1] CRAN (R 4.3.0)\n#>  labelled      2.12.0     2023-06-21 [1] CRAN (R 4.3.0)\n#>  lifecycle     1.0.4      2023-11-07 [1] CRAN (R 4.3.0)\n#>  lubridate     1.9.3      2023-09-27 [1] CRAN (R 4.3.0)\n#>  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n#>  markdown      1.12       2023-12-06 [1] CRAN (R 4.3.0)\n#>  munsell       0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n#>  naniar        1.0.0      2023-02-02 [1] CRAN (R 4.3.0)\n#>  pillar        1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n#>  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n#>  purrr         1.0.2      2023-08-10 [1] CRAN (R 4.3.0)\n#>  R6            2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n#>  repr          1.1.6      2023-01-26 [1] CRAN (R 4.3.0)\n#>  rlang         1.1.3      2024-01-10 [1] CRAN (R 4.3.0)\n#>  rmarkdown     2.25       2023-09-18 [1] CRAN (R 4.3.0)\n#>  rprojroot     2.0.4      2023-11-05 [1] CRAN (R 4.3.0)\n#>  rstudioapi    0.15.0     2023-07-07 [1] CRAN (R 4.3.0)\n#>  rversions     2.1.2      2022-08-31 [1] CRAN (R 4.3.0)\n#>  scales        1.3.0      2023-11-28 [1] CRAN (R 4.3.2)\n#>  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n#>  skimr         2.1.5      2022-12-23 [1] CRAN (R 4.3.0)\n#>  snakecase     0.11.1     2023-08-27 [1] CRAN (R 4.3.0)\n#>  stringi       1.8.3      2023-12-11 [1] CRAN (R 4.3.0)\n#>  stringr       1.5.1      2023-11-14 [1] CRAN (R 4.3.0)\n#>  svglite       2.1.3      2023-12-08 [1] CRAN (R 4.3.0)\n#>  systemfonts   1.0.5      2023-10-09 [1] CRAN (R 4.3.0)\n#>  tibble        3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n#>  tidyr         1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n#>  tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.3.0)\n#>  timechange    0.3.0      2024-01-18 [1] CRAN (R 4.3.0)\n#>  utf8          1.2.4      2023-10-22 [1] CRAN (R 4.3.0)\n#>  vctrs         0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n#>  viridisLite   0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n#>  visdat        0.6.0      2023-02-02 [1] CRAN (R 4.3.0)\n#>  withr         3.0.0      2024-01-16 [1] CRAN (R 4.3.0)\n#>  xfun          0.42       2024-02-08 [1] CRAN (R 4.3.2)\n#>  xml2          1.3.6      2023-12-04 [1] CRAN (R 4.3.0)\n#>  yaml          2.3.8      2023-12-11 [1] CRAN (R 4.3.0)\n#> \n#>  [1] /Library/Frameworks/R.framework/Versions/4.3-x86_64/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}