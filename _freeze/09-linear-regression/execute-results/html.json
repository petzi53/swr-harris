{
  "hash": "da0806a72037161c4ead8786722188ad",
  "result": {
    "engine": "knitr",
    "markdown": "# Linear regression {#sec-chap09}\n\n\n\n\n\n::: {.callout-note #nte-chap09-differenct-chapter-structure style=\"color: blue;\"}\n### Different chapter structure, especially in <a class='glossary' title='Explorative Data Analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling and thereby contrasts traditional hypothesis testing. (Wikipedia)'>EDA</a> (@sec-chap09-achievement1)\n\nAs I have already read some books on linear regression I will not follow exactly the text in this chapter. I will leave out those passages that are not new for me and where I feel confident. Other passages I will only summarize to have content to consult whenever I would need it.\n:::\n\n\n\n\n\n## Achievements to unlock\n\n\n::: {#obj-chap09}\n::: {.my-objectives}\n::: {.my-objectives-header}\nObjectives for chapter 09\n:::\n\n::: {.my-objectives-container}\n**SwR Achievements**\n\n- **Achievement 1**: Using exploratory data analysis to learn about the data before developing a linear regression model (@sec-chap09-achievement1)\n- **Achievement 2**: Exploring the statistical model for a line (@sec-chap09-achievement2)\n- **Achievement 3**: Computing the slope and intercept in a simple linear regression (@sec-chap09-achievement3)\n- **Achievement 4**: Slope interpretation and significance ($b_{1}$, p-value, CI) (@sec-chap09-achievement4)\n- **Achievement 5**: Model significance and model fit (@sec-chap09-achievement5)\n- **Achievement 6**: Checking assumptions and conducting diagnostics (@sec-chap09-achievement6)\n- **Achievement 7**: Adding variables to the model and using transformation (@sec-chap09-achievement7)\n\n:::\n:::\n\nAchievements for chapter 09\n:::\n\n\n## The needle exchange examination\n\nSome infectious diseases like HIV and Hepatitis C are on the rise again with young people in non-urban areas having the highest increases and needle-sharing being a major factor. Clean needles are distributed by syringe services programs (SSPs), which can also provide a number of other related services including overdose prevention, referrals for substance use treatment, and infectious disease testing. But even there are programs in place --- which is not allowed legally in some US states! --- some people have to travel long distances for health services, especially for services that are specialized, such as needle exchanges.\n\nIn discussing the possible quenstion one could analyse it turned out that for some questions critical data are missing: \n\n- There is a distance-to-syringe-services-program variable among the health services data sources of <a class='glossary' title='amfAR, the Foundation for AIDS Research, known until 2005 as the American Foundation for AIDS Research, is an international nonprofit organization dedicated to the support of AIDS research, HIV prevention, treatment education, and the advocacy of AIDS-related public policy. (Wikipedia)'>amfAR</a> (https://opioid.amfar.org/). \n- Many of the interesting variables were not available for much of the nation, and many of them were only at the state level.\n\nGiven these limitations, the book focuses whether the distance to a syringe program could be explained by \n\n- whether a county is urban or rural, \n- what percentage of the county residents have insurance (as a measure of both access to health care and socioeconomic status [SES]), \n- HIV prevalence, \n- and the number of people with opioid prescriptions.\n\nAs there is no variable for rural or urban status in the amfAR database, the book will tale a variable from the U.S. Department of Agriculture Economic Research Services website (https://www.ers.usda.gov/data-products/county-typology-codes/) that classifies all counties as metro or non-metro.\n\n## Resources & Chapter Outline\n\n### Data, codebook, and R packages {#sec-chap04-data-codebook-packages}\n\n::: {.my-resource}\n::: {.my-resource-header}\n:::::: {#lem-chap09-resources}\n: Data, codebook, and R packages for learning about descriptive statistics\n::::::\n:::\n\n::: {.my-resource-container}\n\n**Data**\n\nTwo options for accessing the data:\n\n1. Download the clean data set `dist_ssp_amfar_ch9.csv` from https://edge.sagepub.com/harris1e.\n2. Follow the instructions in Box 9.1 to import, merge, and clean the data from multiple files or from the original online source \n\n\n\n**Codebook**\n\nTwo options for accessing the codebook: \n\n1. Download the codebook file `opioid_county_codebook.xlsx` from https://edge.sagepub.com/harris1e.\n2. Use the online codebook from the amfAR Opioid & Health Indicators Database website (https://opioid.amfar.org/)\n\n\n**Packages**\n\n1. Packages used with the book (sorted alphabetically)\n\n-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)\n-   {**tableone**}: @pak-tableone (Kazuki Yoshida) \n-   {**lmtest**}: @pak-lmtest (Achim Zeileis) \n-   {**broom**}, @pak-broom (David Robinson and Alex Hayes)\n-   {**car**}, @pak-car (John Fox)\n\n    \n2. My additional packages (sorted alphabetically)\n\n- {**gt**}: @pak-gt (Richard Iannone)\n- {**gtsummary**}: @pak-gtsummary (Daniel D. Sjoberg)\n\n:::\n:::\n\n\n### Get, recode and show data\n\nI will use the data file provided by the book because I am feeling quite confident with reading and recoding the original data. But I will change the columns names so that the variable names conform to the [tidyverse style guide](https://style.tidyverse.org/).\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-data}\n: Data for chapter 9\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Get & recode\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-get-recode-data}\n: Get & recode data for chapter 9\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n## run only once (manually)\ndistance_ssp <- readr::read_csv(\n    \"data/chap09/dist_ssp_amfar_ch9.csv\",\n    show_col_types = FALSE)\n\ndistance_ssp_clean <- distance_ssp |> \n    dplyr::rename(\n        state = \"STATEABBREVIATION\",\n        dist_ssp = \"dist_SSP\",\n        hiv_prevalence = \"HIVprevalence\",\n        opioid_rate = \"opioid_RxRate\",\n        no_insurance = \"pctunins\"\n    ) |> \n    dplyr::mutate(\n        state = forcats::as_factor(state),\n        metro = forcats::as_factor(metro)\n    ) |> \n    dplyr::mutate(\n        hiv_prevalence = dplyr::na_if(\n            x = hiv_prevalence,\n            y = -1\n        )\n    )\n\nsave_data_file(\"chap09\", distance_ssp_clean, \"distance_ssp_clean.rds\")\n```\n:::\n\n\n(*For this R code chunk is no output available*)\n\n::::\n:::::\n\n\n###### Show data\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-show-data}\n: Show data for chapter 9\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {#tbl-chap09-show-data .cell tbl-cap='Descriptive statistics for data of chapter 9'}\n\n```{.r .cell-code}\ndistance_ssp_clean <- base::readRDS(\"data/chap09/distance_ssp_clean.rds\")\n\nskimr::skim(distance_ssp_clean)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |                   |\n|:------------------------|:------------------|\n|Name                     |distance_ssp_clean |\n|Number of rows           |500                |\n|Number of columns        |7                  |\n|_______________________  |                   |\n|Column type frequency:   |                   |\n|character                |1                  |\n|factor                   |2                  |\n|numeric                  |4                  |\n|________________________ |                   |\n|Group variables          |None               |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|county        |         0|             1|  10|  28|     0|      406|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                     |\n|:-------------|---------:|-------------:|:-------|--------:|:------------------------------|\n|state         |         0|             1|FALSE   |       49|TX: 50, GA: 30, NC: 21, TN: 21 |\n|metro         |         0|             1|FALSE   |        2|non: 274, met: 226             |\n\n\n**Variable type: numeric**\n\n|skim_variable  | n_missing| complete_rate|   mean|     sd|   p0|   p25|    p50|    p75|   p100|hist  |\n|:--------------|---------:|-------------:|------:|------:|----:|-----:|------:|------:|------:|:-----|\n|dist_ssp       |         0|          1.00| 107.74|  94.23|  0.0| 35.12|  75.94| 163.83|  510.0|▇▃▂▁▁ |\n|hiv_prevalence |        70|          0.86| 192.89| 213.35| 14.4| 72.30| 118.95| 227.48| 2150.7|▇▁▁▁▁ |\n|opioid_rate    |         0|          1.00|  68.33|  36.81|  0.2| 45.12|  62.40|  89.95|  345.1|▇▆▁▁▁ |\n|no_insurance   |         0|          1.00|  12.18|   4.97|  3.0|  8.60|  11.70|  15.00|   35.9|▅▇▂▁▁ |\n\n\n:::\n:::\n\n\n::::\n:::::\n\n***\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-chap09-codebook}\n::::::\n: Codebook: Explanation of variables used in Chapter 9\n::::\n:::: {.my-bulletbox-body}\n- **county**: the county name \n- **state**: the two-letter abbreviation for the state the county is in \n- **dist_ssp**: distance in miles to the nearest syringe services program \n- **hiv_prevalence**: people age 13 and older living with diagnosed HIV per 100,000\n- **opioid_rate**: number of opioid prescriptions per 100 people \n- **no_insurance**:percentage of the civilian non-institutionalized population with no health insurance coverage \n- **metro**: county is either non-metro, which includes open countryside, rural towns, or smaller cities with up to 49,999 people, or metro\n::::\n:::\n\n###### metro\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-metro}\n: Summary of `metro` variable\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-metro}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance_ssp_clean |> \n    dplyr::group_by(metro) |> \n    skimr::skim()\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |                             |\n|:------------------------|:----------------------------|\n|Name                     |dplyr::group_by(distance_... |\n|Number of rows           |500                          |\n|Number of columns        |7                            |\n|_______________________  |                             |\n|Column type frequency:   |                             |\n|character                |1                            |\n|factor                   |1                            |\n|numeric                  |4                            |\n|________________________ |                             |\n|Group variables          |metro                        |\n\n\n**Variable type: character**\n\n|skim_variable |metro     | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|:---------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|county        |metro     |         0|             1|  10|  28|     0|      201|          0|\n|county        |non-metro |         0|             1|  10|  25|     0|      241|          0|\n\n\n**Variable type: factor**\n\n|skim_variable |metro     | n_missing| complete_rate|ordered | n_unique|top_counts                     |\n|:-------------|:---------|---------:|-------------:|:-------|--------:|:------------------------------|\n|state         |metro     |         0|             1|FALSE   |       46|TX: 20, GA: 15, VA: 12, NC: 11 |\n|state         |non-metro |         0|             1|FALSE   |       42|TX: 30, KS: 18, GA: 15, TN: 13 |\n\n\n**Variable type: numeric**\n\n|skim_variable  |metro     | n_missing| complete_rate|   mean|     sd|   p0|   p25|    p50|    p75|   p100|hist  |\n|:--------------|:---------|---------:|-------------:|------:|------:|----:|-----:|------:|------:|------:|:-----|\n|dist_ssp       |metro     |         0|          1.00|  85.00|  88.00|  0.0| 20.31|  50.37| 123.96|  436.0|▇▂▁▁▁ |\n|dist_ssp       |non-metro |         0|          1.00| 126.50|  95.21|  6.0| 50.61|  96.05| 181.96|  510.0|▇▅▂▁▁ |\n|hiv_prevalence |metro     |        18|          0.92| 245.59| 262.55| 14.4| 89.30| 162.60| 316.35| 2150.7|▇▁▁▁▁ |\n|hiv_prevalence |non-metro |        52|          0.81| 143.51| 136.86| 22.6| 63.65|  96.60| 159.18|  904.3|▇▂▁▁▁ |\n|opioid_rate    |metro     |         0|          1.00|  65.44|  28.65|  4.7| 45.55|  60.10|  87.43|  143.6|▂▇▅▃▁ |\n|opioid_rate    |non-metro |         0|          1.00|  70.71|  42.28|  0.2| 44.60|  65.60|  91.97|  345.1|▇▆▁▁▁ |\n|no_insurance   |metro     |         0|          1.00|  11.17|   4.42|  3.0|  8.22|  10.80|  14.05|   30.2|▅▇▅▁▁ |\n|no_insurance   |non-metro |         0|          1.00|  13.02|   5.25|  3.3|  9.17|  12.15|  15.88|   35.9|▅▇▃▁▁ |\n\n\n:::\n:::\n\nSummary of `metro` variable\n:::\n\n***\n\nFor the exploratory data analysis I need more details about the association between the distance to the next SSP separated for people living in metro and non-metro areas. See \n\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nWATCH OUT! Do missing values have a pattern?\n:::\n::::{.my-watch-out-container}\nWe know from @tbl-chap09-show-data that the variable `hiv_prevalence` has many missing values. In all the forthcoming analyses we will remove those 70 `NAs` and work with complete cases. 70 NA’s in a sample of 500 is with 14% a big proportion from the available data. The question arises: Is there a reason why there are so many missing values? Could it be that this reason is distorting our analysis?\n\nMost of the time I have provided code that suppresses these warnings. This is a dangerous enterprise as it could bias results and conclusions without knowledge of the researcher. I think that a more prudent approach would need an analysis of the missing values. I do not know how to do this yet, but with {**naniar**} (@pak-naniar) there is a package for exploring missing data structures. Its website and package has [several vignettes](https://naniar.njtierney.com/) to learn its functions and there is also an scientific article about the package [@tierney2023].\n\nExploring missing data structures is in the book no planned achievement, therefore it is here enough to to get rid of the NA’s and to follow the books outline. But I am planning coming back to this issue and learn how to address missing data structures appropriately.\n\n::::\n:::::\n\n\n## Achievement 1: Explorative Data Analysis {#sec-chap09-achievement1}\n\n### Introduction\n\nInstead following linearly the chapter I will try to compute my own <a class='glossary' title='Explorative Data Analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling and thereby contrasts traditional hypothesis testing. (Wikipedia)'>EDA</a>. I will try three different method:\n\n1. Manufacturing the data and graphs myself. Writing own functions and using {**tidyverse**} packages to provide summary plots and statistics.\n2. Trying out the `graphics::pairs()` function.\n3. Experimenting with {**GGally**}, an extension package to {**ggplot2**} where one part (`GGally::ggpairs()`) is the equivalent to the base R `graphics::pairs()` function.\n\n### Steps for EDA\n\nI will apply the following steps:\n\n:::::{.my-procedure}\n:::{.my-procedure-header}\n:::::: {#prp-chap09-eda-steps}\n: Some useful steps to explore data for regression analysis\n::::::\n:::\n::::{.my-procedure-container}\nOrder and completeness of the following tasks is not mandatory.\n\n1. **Browse the data**: \n    - **RStudio Data Explorer**: I am always using the data explorer in RStudio to get my first impression of the data. Although this step is not reproducible it forms my frame of mind what EDA steps I should follow and if there are issues I need especially to care about. \n    - **Skim data**: Look at the data with `skimr::skim()` to get a holistic view of the data: names, data types, missing values, ordered (categorical) minimum, maximum, mean, sd, distribution (numerical).\n    - **Read the codebook:** It is important to understand what the different variables mean.\n    - **Check structure:** Examine with `utils::str()` if the dataset has special structures, e.g. labelled data, attributes etc.\n    - **Glimpse actual data**: To get a feeling about data types and actual values use `dplyr::glimpse()`.\n    - **Glance at example rows**: As an alternative of `utils::head()` / `utils::tails()` get random row examples including first and last row of the dataset with my own function `glance_data()`.\n2. **Check normality assumption**:\n    - **Draw histograms of numeric variables**: To get a better idea I have these histogram overlaid with the theoretical normal distribution and the density curve of the current data. The difference between these two curves gives a better impression if normality is met or not.\n    - **Draw Q-Q plots of numeric variables**: <a class='glossary' title='A quantile-quantile plot is a visualization of data using probabilities to show how closely a variable follows a normal distribution. (SwR, Glossary) This plot is made up of points below which a certain percentage of the observations fall. On the x-axis are normally distributed values with a mean of 0 and a standard deviation of 1. On the y-axis are the observations from the data. If the data are normally distributed, the values will form a diagonal line through the graph. (SwR, chapter 6)'>Q-Q plots</a> gives even a more detailed picture if normality is met.\n    - **Compute normality tests**: If your data has less than 5.000 rows then use the <a class='glossary' title='The Shapiro-Wilk test is a statistical test to determine or confirm whether a variable has a normal distribution; it is sensitive to small deviations from normality and not useful for sample sizes above 5,000 because it will nearly always find non-normality. (SwR, Glossary)'>Shapiro-Wilk test</a>, otherwise the <a class='glossary' title='The Anderson-Darling Goodness of Fit Test (AD-Test) is a measure of how well your data fits a specified distribution. It’s commonly used as a test for normality. (Statistics How-To)'> Anderson-Darling test</a>. \n3. **Check homogeneity assumption**: If the normality assumption is not met, then test if the homogeneity of variance assumption between groups is met with <a class='glossary' title='Levene’s test is a statistical test to determine whether observed data meet the homogeneity of variances assumption; Levene’s test is used to test this assumption for t-tests and analysis of variance. (SwR, Glossary)'>Levene’s test</a> or with the more robust <a class='glossary' title='The Fligner-Killeen test is a non-parametric test for homogeneity of group variances based on ranks. It is useful when the data is non-normal or when there are outliers. (Real Statistics Using Excel)'>Fligner-Killeen’s test</a>. In the following steps use always median instead of mean and do not compute the <a class='glossary' title='Pearson’s r is a statistic that indicates the strength and direction of the relationship between two numeric variables that meet certain assumptions. (SwR, Glossary)'>Pearson’s r</a> but the <a class='glossary' title='Spearman’s rho a statistical test used to examine the strength, direction, and significance of the relationship between two numeric variables when they do not meet the assumptions for [Pearson]’s r. (SwR, Glossary)'>Spearman’s rho</a> coefficient. \n4. **Compute correlation coefficient**: Apply either Pearson’s r or the Spearman’s rho coefficient. There are function like `graphics::pairs()` or `GGally::ggpairs()` (@pak-GGally) that provide a graphical and statistical representation of all combinations of bivariate relationships.\n5. **Explore categorical data with box plots or violin plots**: Box plots work well between a numerical and categorical variable. You could also overlaid the data and violin plots to maximize the information in one single graph.\n::::\n:::::\n\n### Executing EDA for chapter 9\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-eda}\n: Explorative Data Analysis for chapter 9\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n\n###### tableone\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-tableone}\n: Descriptive statics with the {**tableone**} package\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#tbl-eda-tableone .cell tbl-cap='Descriptive statics with the \\'tableone\\' package'}\n\n```{.r .cell-code}\ntableone::CreateTableOne(data = distance_ssp_clean,\n                         vars = c('dist_ssp', 'hiv_prevalence',\n                                  'opioid_rate', 'no_insurance',\n                                  'metro'))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                             \n#>                              Overall        \n#>   n                             500         \n#>   dist_ssp (mean (SD))       107.74 (94.23) \n#>   hiv_prevalence (mean (SD)) 192.89 (213.35)\n#>   opioid_rate (mean (SD))     68.33 (36.81) \n#>   no_insurance (mean (SD))    12.18 (4.97)  \n#>   metro = non-metro (%)         274 (54.8)\n```\n\n\n:::\n:::\n\n***\n\n`skimr::skim()` with @tbl-chap09-show-data is a much better alternative! The second version of {**tableone**} in the book with the median instead of the mean is not necessary because it is in `skimr::skim()` integrated.\n::::\n:::::\n\n\n###### Histograms\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-histograms}\n: Histograms of numeric variables\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist_distance <- my_hist_dnorm(\n    df = distance_ssp_clean,\n    v = distance_ssp_clean$dist_ssp,\n    n_bins = 30,\n    x_label = \"Nearest syringe services program in miles\"\n) \n\nhist_hiv <- my_hist_dnorm(\n    df = distance_ssp_clean,\n    v = distance_ssp_clean$hiv_prevalence,\n    n_bins = 30,\n    x_label = \"People with diagnosed HIV per 100,000\"\n) \n\nhist_opioid <- my_hist_dnorm(\n    df = distance_ssp_clean,\n    v = distance_ssp_clean$opioid_rate,\n    n_bins = 30,\n    x_label = \"Opioid prescriptions per 100 people\"\n)\n\nhist_insurance <- my_hist_dnorm(\n    df = distance_ssp_clean,\n    v = distance_ssp_clean$no_insurance,\n    n_bins = 30,\n    x_label = \"Percentage with no health insurance coverage\"\n)\n\ngridExtra::grid.arrange(\n   hist_distance, hist_hiv, hist_opioid, hist_insurance, nrow = 2\n)\n```\n\n::: {.cell-output-display}\n![Histograms for numeric variables of chapter 9](09-linear-regression_files/figure-html/fig-eda-histograms-1.png){#fig-eda-histograms width=672}\n:::\n:::\n\n\n***\nI developed a function where I can overlay the theoretical normal distribution and the density of the current data. The difference between the two curves gives an indication if we have a normal distribution.\n\nFrom our data we see that the biggest difference is between SPP distance and HIV prevalence. This right skewed distribution could also be detected from other indicator already present in the `skimr::skim()`view of @tbl-chap09-show-data:\n- The small histogram on the right is the most right skewed distribution.\n- The standard deviation of `hiv_prevalence` is the only one, that is bigger than the mean of the variable. \n- There is a huge difference between mean and the median (p50) where the mean is much bigger than the median (= right skewed distribution), e.g. there is a long tail to the right as can also be seen in the tiny histogram.\n\nAside from `hiv_prevalence` the variable `distance_ssp` is almost equally right skewed. The situation seems better for the rest of the numeric variables. But let's manufacture <a class='glossary' title='A quantile-quantile plot is a visualization of data using probabilities to show how closely a variable follows a normal distribution. (SwR, Glossary) This plot is made up of points below which a certain percentage of the observations fall. On the x-axis are normally distributed values with a mean of 0 and a standard deviation of 1. On the y-axis are the observations from the data. If the data are normally distributed, the values will form a diagonal line through the graph. (SwR, chapter 6)'>Q-Q plots</a> for all of them to see more in detail if they are normally distributed or not.\n\n\n\n\n\n::::\n:::::\n\n\n###### Q-Q plots\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-qq-plots}\n: Q-Q plots of numeric variables\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqq_distance <- my_qq_plot(\n    df = distance_ssp_clean,\n    v  = distance_ssp_clean$dist_ssp,\n    col_qq = \"Distance to SSP\"\n)\n\nqq_hiv <- my_qq_plot(\n    df = distance_ssp_clean,\n    v  = distance_ssp_clean$hiv_prevalence,\n    col_qq = \"HIV diagnosed\"\n)\n\nqq_opioid <- my_qq_plot(\n    df = distance_ssp_clean,\n    v  = distance_ssp_clean$opioid_rate,\n    col_qq = \"Opioid prescriptions\"\n)\n\nqq_insurance <- my_qq_plot(\n    df = distance_ssp_clean,\n    v  = distance_ssp_clean$no_insurance,\n    col_qq = \"Health insurance\"\n)\n\n\ngridExtra::grid.arrange(\n   qq_distance, qq_hiv, qq_opioid, qq_insurance, nrow = 2\n)\n```\n\n::: {.cell-output-display}\n![Q-Q plots for numeric variables of chapter 9](09-linear-regression_files/figure-html/fig-eda-qq-plots-1.png){#fig-eda-qq-plots width=672}\n:::\n:::\n\n\n***\nIt turned out that all four numeric variables are not normally distributed. Some of them looked in the histograms quite OK, because the differences to the normal distribution on the lower and upper end of the data compensate each other.\n\nTesting normality with <a class='glossary' title='The Shapiro-Wilk test is a statistical test to determine or confirm whether a variable has a normal distribution; it is sensitive to small deviations from normality and not useful for sample sizes above 5,000 because it will nearly always find non-normality. (SwR, Glossary)'>Shapiro-Wilk</a> or <a class='glossary' title='The Anderson-Darling Goodness of Fit Test (AD-Test) is a measure of how well your data fits a specified distribution. It’s commonly used as a test for normality. (Statistics How-To)'>Anderson-Darling</a> test will show that they are definitely not normally distributed.\n\n::::\n:::::\n\n###### Normality\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-test-normality}\n: Normality checking with Shapiro-Wilk & Anderson-Darling tests\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#tbl-chap09-eda-test-normality .cell tbl-cap='Testing normality with Shapiro-Wilk & Anderson-Darling tests'}\n\n```{.r .cell-code}\ndist_test <-  stats::shapiro.test(distance_ssp_clean$dist_ssp)\nhiv_test <-  stats::shapiro.test(distance_ssp_clean$hiv_prevalence)\nopioid_test <- stats::shapiro.test(distance_ssp_clean$opioid_rate)\ninsurance_test <- stats::shapiro.test(distance_ssp_clean$no_insurance)\n\ndist_test2 <-  nortest::ad.test(distance_ssp_clean$dist_ssp)\nhiv_test2 <-  nortest::ad.test(distance_ssp_clean$hiv_prevalence)\nopioid_test2 <- nortest::ad.test(distance_ssp_clean$opioid_rate)\ninsurance_test2 <- nortest::ad.test(distance_ssp_clean$no_insurance)\n\n\nnormality_test <- \n    dplyr::bind_rows(\n        broom:::glance.htest(dist_test),\n        broom:::glance.htest(hiv_test),\n        broom:::glance.htest(opioid_test),\n        broom:::glance.htest(insurance_test),\n        broom:::glance.htest(dist_test2),\n        broom:::glance.htest(hiv_test2),\n        broom:::glance.htest(opioid_test2),\n        broom:::glance.htest(insurance_test2)\n    ) |> \n    dplyr::bind_cols(\n        variable = c(\"dist_ssp\", \"hiv_prevalence\",\n                     \"opioid_rate\", \"no_insurance\",\n                     \"dist_ssp\", \"hiv_prevalence\",\n                     \"opioid_rate\", \"no_insurance\")\n    ) |> \n    dplyr::relocate(variable)\n\nnormality_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 8 × 4\n#>   variable       statistic  p.value method                         \n#>   <chr>              <dbl>    <dbl> <chr>                          \n#> 1 dist_ssp           0.874 1.10e-19 Shapiro-Wilk normality test    \n#> 2 hiv_prevalence     0.649 8.72e-29 Shapiro-Wilk normality test    \n#> 3 opioid_rate        0.938 1.55e-13 Shapiro-Wilk normality test    \n#> 4 no_insurance       0.946 1.85e-12 Shapiro-Wilk normality test    \n#> 5 dist_ssp          18.0   3.7 e-24 Anderson-Darling normality test\n#> 6 hiv_prevalence    37.0   3.7 e-24 Anderson-Darling normality test\n#> 7 opioid_rate        2.68  9.14e- 7 Anderson-Darling normality test\n#> 8 no_insurance       3.43  1.39e- 8 Anderson-Darling normality test\n```\n\n\n:::\n:::\n\n\n***\n\nThe <a class='glossary' title='The p-value is the probability that the test statistic is at least as big as it is under the null hypothesis (SwR, Glossary)'>p-values</a> from both tests are for all four variables very small, e.g. statistically significant. Therefore we have to reject the Null that they are normally distributed.\n\n\n::::\n:::::\n\n\n::: {.callout-tip}\nIt turned out that all four variable are not normally distributed. We can't therefore not use <a class='glossary' title='Pearson’s r is a statistic that indicates the strength and direction of the relationship between two numeric variables that meet certain assumptions. (SwR, Glossary)'>Pearson’s r coefficient</a>. \n:::\n\nBefore we are going to use <a class='glossary' title='Spearman’s rho a statistical test used to examine the strength, direction, and significance of the relationship between two numeric variables when they do not meet the assumptions for [Pearson]’s r. (SwR, Glossary)'>Spearman’s rho</a> let's check the homogeneity of variance assumption (<a class='glossary' title='Homoscedasticity is [homogeneity of variances], contrast is [Heteroscedasticity]. Homoscedasticity is an assumption of correlation and linear regression that requires that the variance of y be constant across all the values of x; visually, this assumption would show points along a fit line between x and y being evenly spread on either side of the line for the full range of the relationship. (SwR, Glossary)'>homoscedasticity</a>) with a scatterplot with `lm` and `loess` curve  and using <a class='glossary' title='Levene’s test is a statistical test to determine whether observed data meet the homogeneity of variances assumption; Levene’s test is used to test this assumption for t-tests and analysis of variance. (SwR, Glossary)'>Levene’s Test</a> and the <a class='glossary' title='The Fligner-Killeen test is a non-parametric test for homogeneity of group variances based on ranks. It is useful when the data is non-normal or when there are outliers. (Real Statistics Using Excel)'>Fligner-Killeen’s test</a>.\n\n###### Scatterplots\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-scatterplots}\n: Scatterplots of numeric variables\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nscatter_dist_hiv <-  my_scatter(\n    df = distance_ssp_clean,\n    v =  distance_ssp_clean$hiv_prevalence,\n    w =  distance_ssp_clean$dist_ssp,\n    x_label = \"HIV prevalence\",\n    y_label = \"Distance to SSP\"\n)\n\nscatter_dist_opioid <-  my_scatter(\n    df = distance_ssp_clean,\n    v =  distance_ssp_clean$opioid_rate,\n    w =  distance_ssp_clean$dist_ssp,\n    x_label = \"Opioid rate\",\n    y_label = \"Distance to SSP\"\n)\n\nscatter_dist_insurance <-  my_scatter(\n    df = distance_ssp_clean,\n    v =  distance_ssp_clean$no_insurance,\n    w =  distance_ssp_clean$dist_ssp,\n    x_label = \"No insurance\",\n    y_label = \"Distance to SSP\"\n)\n\ngridExtra::grid.arrange(\n   scatter_dist_hiv, scatter_dist_opioid, scatter_dist_insurance, nrow = 3\n)\n```\n\n::: {.cell-output-display}\n![Scatterplots of numeric variables](09-linear-regression_files/figure-html/fig-eda-scatterplots-1.png){#fig-eda-scatterplots width=672}\n:::\n:::\n\n\n::::\n:::::\n\n\n\n\n\n###### Homogeneity\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-test-homogeneity}\n: Testing homogeneity of variances with Levene’s and Fligner-Killeen’s test\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#tbl-chap09-eda-test-homogeneity .cell tbl-cap='Homogeneity of variances tested with Levene’s and Fligner-Killeen’s test'}\n\n```{.r .cell-code}\nhiv_test <-  stats::fligner.test(\n    distance_ssp_clean$dist_ssp,\n    distance_ssp_clean$hiv_prevalence\n    )\nopioid_test <- stats::fligner.test(\n    distance_ssp_clean$dist_ssp,\n    distance_ssp_clean$opioid_rate\n    )\ninsurance_test <- stats::fligner.test(\n    distance_ssp_clean$dist_ssp,\n    distance_ssp_clean$no_insurance\n    )\n\nhiv_test2 <-  car::leveneTest(\n    distance_ssp_clean$dist_ssp,\n    forcats::as_factor(distance_ssp_clean$hiv_prevalence)\n    )\nopioid_test2 <- car::leveneTest(\n    distance_ssp_clean$dist_ssp,\n    forcats::as_factor(distance_ssp_clean$opioid_rate)\n    )\ninsurance_test2 <- car::leveneTest(\n    distance_ssp_clean$dist_ssp,\n    forcats::as_factor(distance_ssp_clean$no_insurance)\n    )\n\n\nhomogeneity_test <- \n    dplyr::bind_rows(\n        broom::tidy(hiv_test2),\n        broom::tidy(opioid_test2),\n        broom::tidy(insurance_test2)\n    ) |> \n    dplyr::mutate(method = \"Levene's Test for Homogeneity of Variance\") |> \n    dplyr::bind_rows(\n        broom:::glance.htest(hiv_test),\n        broom:::glance.htest(opioid_test),\n        broom:::glance.htest(insurance_test),\n    ) |> \n    dplyr::bind_cols(\n        variable = c(\"dist_hiv\",\n                     \"dist_opioid\", \n                     \"dist_insurance\",\n                     \"dist_hiv\",\n                     \"dist_opioid\", \n                     \"dist_insurance\"\n                 )\n    ) |> \n    dplyr::relocate(variable)\n\nhomogeneity_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 6 × 7\n#>   variable       statistic p.value    df df.residual method            parameter\n#>   <chr>              <dbl>   <dbl> <int>       <int> <chr>                 <dbl>\n#> 1 dist_hiv           0.493  0.999    395          34 Levene's Test fo…        NA\n#> 2 dist_opioid        0.893  0.770    406          93 Levene's Test fo…        NA\n#> 3 dist_insurance     0.750  0.983    171         328 Levene's Test fo…        NA\n#> 4 dist_hiv         408.     0.312     NA          NA Fligner-Killeen …       395\n#> 5 dist_opioid      451.     0.0609    NA          NA Fligner-Killeen …       406\n#> 6 dist_insurance   170.     0.502     NA          NA Fligner-Killeen …       171\n```\n\n\n:::\n:::\n\n***\n\nAll p-values are higher than the threshold of .05 and are therefore not statistically significant. The Null must not rejected, the homogeneity of variance assumption for all variables is met.\n::::\n:::::\n\n###### Correlations\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-cor}\n: Correlations for numeric variables of chapter 9\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#tbl-chap09-cor .cell tbl-cap='Correlations for numeric variables of chapter 9'}\n\n```{.r .cell-code}\ncor_pearson <- distance_ssp_clean |> \n    dplyr::summarize(\n        hiv_cor = stats::cor(\n        x = dist_ssp,\n        y = hiv_prevalence,\n        use = \"complete.obs\",\n        method = \"pearson\"\n        ),\n        opioid_cor = stats::cor(\n        x = dist_ssp,\n        y = opioid_rate,\n        use = \"complete.obs\",\n        method = \"pearson\"\n        ),\n        insurance_cor = stats::cor(\n        x = dist_ssp,\n        y = no_insurance,\n        use = \"complete.obs\",\n        method = \"pearson\"\n        ),\n        `n (sample)` = dplyr::n()\n    )\n\ncor_spearman <- distance_ssp_clean |> \n    dplyr::summarize(\n        hiv_cor = stats::cor(\n        x = dist_ssp,\n        y = hiv_prevalence,\n        use = \"complete.obs\",\n        method = \"spearman\"\n        ),\n        opioid_cor = stats::cor(\n        x = dist_ssp,\n        y = opioid_rate,\n        use = \"complete.obs\",\n        method = \"spearman\"\n        ),\n        insurance_cor = stats::cor(\n        x = dist_ssp,\n        y = no_insurance,\n        use = \"complete.obs\",\n        method = \"spearman\"\n        ),\n        `n (sample)` = dplyr::n()\n    )\n\ncor_kendall <- distance_ssp_clean |> \n    dplyr::summarize(\n        hiv_cor = stats::cor(\n        x = dist_ssp,\n        y = hiv_prevalence,\n        use = \"complete.obs\",\n        method = \"kendall\"\n        ),\n        opioid_cor = stats::cor(\n        x = dist_ssp,\n        y = opioid_rate,\n        use = \"complete.obs\",\n        method = \"kendall\"\n        ),\n        insurance_cor = stats::cor(\n        x = dist_ssp,\n        y = no_insurance,\n        use = \"complete.obs\",\n        method = \"kendall\"\n        ),\n        `n (sample)` = dplyr::n()\n    )\n\ncor_chap09 <- dplyr::bind_rows(cor_pearson, cor_spearman, cor_kendall)\ncor_chap09 <- dplyr::bind_cols(\n    method = c(\"Pearson\", \"Spearman\", \"Kendall\"), cor_chap09)\ncor_chap09\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 3 × 5\n#>   method   hiv_cor opioid_cor insurance_cor `n (sample)`\n#>   <chr>      <dbl>      <dbl>         <dbl>        <int>\n#> 1 Pearson  -0.0240   -0.0998          0.413          500\n#> 2 Spearman  0.0855   -0.0164          0.345          500\n#> 3 Kendall   0.0600   -0.00918         0.234          500\n```\n\n\n:::\n:::\n\n***\n\nHere I have computed for a comparison all three correlation coefficients of the nearest distance to the next <a class='glossary' title='SSP stands for Syringe Services Program (SwR)'>SSP</a> with the numeric variabeles of the dataset. \n\n- Pearson’s $r$ is not allowed for all of the three variables, because our data didn't meet the normality assumption. \n- Using Spearman’s $\\rho$ or Kendall’s $\\tau$ instead of Pearson’s $r$ results in big differences. For instance: the correlation of distance to the next SSP and HIV prevalence reverses it direction.\n- Kendall’s tau $\\tau$ is more conservative (smaller) than Spearman’s rho and it is also preferred in most scenarios. (Kendall’s tau is not mentioned in the book. Maybe the reason is --- as far as I understand -- that Spearman’s  is the most widely used correlation coefficient?)\n\n***\n\nI want to confirm my internet research with the following quotes:\n\n**First quote**\n\n> In the normal case, Kendall correlation is more robust and efficient than Spearman correlation. It means that Kendall correlation is preferred when there are small samples or some outliers. ([Pearson vs Spearman vs Kendall](https://datascience.stackexchange.com/questions/64260/pearson-vs-spearman-vs-kendall)) [@pluviophile2019].\n\n**Second quote**\n\n> Kendall’s Tau: usually smaller values than Spearman’s rho correlation. Calculations based on concordant and discordant pairs. Insensitive to error. P values are more accurate with smaller sample sizes.\n>\n> Spearman’s rho: usually have larger values than Kendall’s Tau.  Calculations based on deviations.  Much more sensitive to error and discrepancies in data.\n>\n> The main advantages of using Kendall’s tau are as follows:\n>\n> - The distribution of Kendall’s tau has better statistical properties.\n> - The interpretation of Kendall’s tau in terms of the probabilities of observing the agreeable (concordant) and non-agreeable (discordant) pairs is very direct.\n> - In most of the situations, the interpretations of Kendall’s tau and Spearman’s rank correlation coefficient are very similar and thus invariably lead to the same inferences. ([Kendall’s Tau and Spearman’s Rank Correlation Coefficient](https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/kendalls-tau-and-spearmans-rank-correlation-coefficient/)) [@statisticssolutionsn.d] \n\n**Third quote**\n\n> - Kendall Tau-b is more accurate for small sample sizes with strong correlations.\n> - Spearman’s rho is preferred for weak correlations in small datasets.\n> - In large samples, Kendall Tau-b’s reliability surpasses Spearman’s rho.\n> - Kendall’s Tau is a robust estimator against outliers and non-normality.\n> - Overall, Kendall Tau-b outperforms Spearman for most statistical scenarios [Kendall Tau-b vs Spearman: Which Correlation Coefficient Wins?](https://statisticseasily.com/kendall-tau-b-vs-spearman/) [@learnstatisticseasily2024]\n\n:::::{.my-resource}\n:::{.my-resource-header}\n:::::: {#lem-chap09-corr-coefficient}\nUnderstanding the different correlation coefficients\n::::::\n:::\n::::{.my-resource-container}\n- [Kendall Tau-b vs Spearman: Which Correlation Coefficient Wins?](https://statisticseasily.com/kendall-tau-b-vs-spearman/): This important article wxplains the decisive factors in choosing the proper non-parametric correlation coefficient (Kendall Tau-b vs Spearman) for your data analysis. [@learnstatisticseasily2024]\n- [Pearson, Spearman and Kendall correlation coefficients by hand](https://statsandr.com/blog/pearson-spearman-kendall-correlation-by-hand/#introduction): This articles illustrates how to compute the Pearson, Spearman and Kendall correlation coefficients by hand and under two different scenarios (i.e., with and without ties). [@soetewey2023]\n- [Chapter 22: Correlation Types and When to Use Them](https://ademos.people.uic.edu/Chapter22.html): This chapter of [@demos2024] covers the strengths, weaknesses, and when or when not to use three common types of correlations (Pearson, Spearman, and Kendall). It’s part statistics refresher, part R tutorial. [@sarmenton.d]\n\n::::\n:::::\n\n\n\n\n\n\n::::\n:::::\n\n###### metro\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-metro}\n: Distance in miles to nearest syringe programs by metro or non-metro status for a sample of 500 counties\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#tbl-chap09-eda-violin-boxplot .cell tbl-cap='Distance in miles to nearest syringe programs by metro or non-metro status for a sample of 500 counties'}\n\n```{.r .cell-code}\ndistance_ssp_clean |>\n    dplyr::group_by(metro) |>\n    dplyr::summarize(mean.dist = base::mean(dist_ssp),\n                     median.dist = stats::median(dist_ssp),\n                     min.dist = base::min(dist_ssp),\n                     max.dist = base::max(dist_ssp)\n                     )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 2 × 5\n#>   metro     mean.dist median.dist min.dist max.dist\n#>   <fct>         <dbl>       <dbl>    <dbl>    <dbl>\n#> 1 metro          85.0        50.4        0      436\n#> 2 non-metro     126.         96.0        6      510\n```\n\n\n:::\n:::\n\n***\n\nThe big difference between mean and median reflects a right skewed distribution. There are some people living extremely far from the next <a class='glossary' title='SSP stands for Syringe Services Program (SwR)'>SSP</a> both in non-metro *and* metro areas. \n\nIt is no surprise that the distance for people living in a non-metro area is much longer than for people in big city. But what certainly surprised me, is that even in big cities half of people live more than 50 miles form the next SSP.\n\n\n::::\n:::::\n\n###### Violin\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-eda-violin-plot}\n: Distance in miles to nearest syringe programs by metro or non-metro status for a sample of 500 counties\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance_ssp_clean |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = metro, \n          y = dist_ssp, \n          fill = metro\n          )\n      ) +\n  ggplot2::geom_violin(\n      ggplot2::aes(\n          color = metro\n          ), \n      fill = \"white\", \n      alpha = .8\n      ) +\n  ggplot2::geom_boxplot(\n      ggplot2::aes(\n          fill = metro, \n          color = metro\n          ), \n      width = .2, \n      alpha = .3\n      ) +\n  ggplot2::geom_jitter(\n      ggplot2::aes(\n          color = metro\n          ), \n      alpha = .4\n      ) +\n  ggplot2::labs(\n      x = \"Type of county\",\n      y = \"Miles to syringe program\"\n      ) +\n  ggplot2::scale_fill_manual(\n      values = c(\"#78A678\", \"#7463AC\"), \n      guide = \"none\") +\n  ggplot2::scale_color_manual(\n      values = c(\"#78A678\", \"#7463AC\"), \n      guide = \"none\") +\n  ggplot2::coord_flip()\n```\n\n::: {.cell-output-display}\n![Distance in miles to nearest syringe programs by metro or non-metro status for a sample of 500 counties](09-linear-regression_files/figure-html/fig-chap09-eda-violin-boxplot-1.png){#fig-chap09-eda-violin-boxplot width=672}\n:::\n:::\n\n***\n\n\n\n\n::::\n:::::\n\n###### pairs\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-plot-pairs}\n: Scatterplots of variable pairs from dataset of chapter 9\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nlt_purple <- t_col(\"purple3\", perc = 50, name = \"lt.purple\")\n\npanel.hist <- function(x, ...)\n{\n    usr <- par(\"usr\")\n    par(usr = c(usr[1:2], 0, 1.5) )\n    h <- hist(x, plot = FALSE)\n    breaks <- h$breaks; nB <- length(breaks)\n    y <- h$counts; y <- y/max(y)\n    rect(breaks[-nB], 0, breaks[-1], y, col = \"grey80\", ...)\n}\n\n\ngraphics::pairs(distance_ssp_clean[3:6], \n                pch = 23, \n                panel = panel.smooth,\n                cex = 1.5, \n                bg = lt_purple, \n                horOdd = TRUE,\n                diag.panel = panel.hist, \n                cex.labels = 2, \n                font.labels = 2,\n                gap = 0\n                )\n```\n\n::: {.cell-output-display}\n![Scatterplots of variable pairs from dataset of chapter 9](09-linear-regression_files/figure-html/fig-plot-pairs-1.png){#fig-plot-pairs width=960}\n:::\n:::\n\n\n::::\n:::::\n\n###### metro\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-plot-pairs-metro}\n: Distance to SSP with different numeric variable and metro/nonmetro location\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\npanel.hist <- function(x, ...) {\n    usr <- par(\"usr\")\n    par(usr = c(usr[1:2], 0, 1.5) )\n    h <- hist(x, plot = FALSE)\n    breaks <- h$breaks; nB <- length(breaks)\n    y <- h$counts; y <- y/max(y)\n    rect(breaks[-nB], 0, breaks[-1], y, col = \"grey80\", ...)\n}\n\ngraphics::pairs(distance_ssp_clean[3:6], \n                main = \"Distance to SSP -- Metro (red) & Nonmetro (blue)\",\n                panel = panel.smooth,\n                horOdd = TRUE,\n                diag.panel = panel.hist, \n                pch = 21, \n                gap = 0,\n                bg = c(\"red\", \"blue\")[unclass(distance_ssp_clean$metro)])\n```\n\n::: {.cell-output-display}\n![Distance to SSP -- Metro (red) & Nonmetro (blue)](09-linear-regression_files/figure-html/fig-plot-pairs-metro-1.png){#fig-plot-pairs-metro width=960}\n:::\n:::\n\n\n::::\n:::::\n\n###### ggpairs\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-plot-ggpairs}\n: Scatterplots of variable pairs from dataset of chapter 9\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nGGally::ggpairs(distance_ssp_clean,\n                columns = 3:7)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Registered S3 method overwritten by 'GGally':\n#>   method from   \n#>   +.gg   ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\n#> Removed 70 rows containing missing values\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Removed 70 rows containing missing values or values outside the scale range\n#> (`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Removed 70 rows containing non-finite outside the scale range\n#> (`stat_density()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\n#> Removed 70 rows containing missing values\n\n#> Warning in ggally_statistic(data = data, mapping = mapping, na.rm = na.rm, :\n#> Removed 70 rows containing missing values\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Removed 70 rows containing non-finite outside the scale range\n#> (`stat_boxplot()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Removed 70 rows containing missing values or values outside the scale range\n#> (`geom_point()`).\n#> Removed 70 rows containing missing values or values outside the scale range\n#> (`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Removed 70 rows containing non-finite outside the scale range\n#> (`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Scatterplots of variable pairs from dataset of chapter 9](09-linear-regression_files/figure-html/fig-plot-ggpairs-1.png){#fig-plot-ggpairs width=960}\n:::\n:::\n\n\n::::\n:::::\n\n\n\n\n:::\n\n::::\n:::::\n\n## Achivement 2: Exploring line model {#sec-chap09-achievement2}\n\n### Introduction\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-line-model}\n: Equation for linear model\n::::::\n:::\n::::{.my-theorem-container}\n\n\n$$\n\\begin{align*}\ny = &m_{x}+b \\\\\ny = &b_{0}+b_{1}x \\\\\ny = &c+b_{1}x\n\\end{align*}\n$$ {#eq-chap09-linear-model}\n\n***\n\n- $m, b_{1}$: <a class='glossary' title='The slope is the increase in the dependent variable when the independent variable increases with one unit and all other independent variables remain the same. (Intercept, Slope in Regression)'>slope</a> of the line \n- $b, b_{0}, c$: y-<a class='glossary' title='The intercept is the value of the dependent variables if all independent variables have the value zero. (Intercept, Slope in Regression)'>intercept</a> of the line, or the value of y when x = 0\n- $x, y$: the coordinates of each point along the line\n\nSometimes $b^*$ is used. This means that the variable had been standardized, or transformed into z-scores, before the regression model was estimated.\n\n\n::::\n:::::\n\nAn example of a linear equation would be $y = 3 + 2x$.\n\n::: {.callout-important #imp-variable-names-linear-equation}\n\n## Variable names and the difference between deterministic and stochastic\n\n- The y variable on the left-hand side of the equation is called the dependent or outcome variable. \n- The x variable(s) on the right-hand side of the equation is/are called the independent or predictor variable(s).\n\n***\n\n- A deterministic equation, or model, has one precise value for y for each value of x. Some equation in physics are deterministic, e.g., $e = mc^2$.\n- In a stochastic equation, or model, you cannot predict or explain something exactly. Most of the time, there is some variability that cannot be fully explained or predicted. This unexplained variability is represented by an error term that is added to the equation. Relationships measured in social science are typically stochastic.\n\n:::\n\n@eq-chap09-linear-model can be re-written with these terms:\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-linear-model}\n: Equation of a linear model (rewritten)\n::::::\n:::\n::::{.my-theorem-container}\n\n$$\n\\begin{align*}\noutcome = &b_{0} + b_{1} \\times predictor \\\\\noutcome = &b_{0} + b_{1} \\times predictor + error \\\\\n\\end{align*}\n$$ {#eq-chap09-lm-rewritten}\n\n::::\n:::::\n\n### Plotting an example\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-example-lm}\n: Example of a linear model\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### deterministic\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-example-lm-water-weeks}\n: Example of a deterministic linear model with gallons of water needed as an outcome and weeks as a predictor \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make a vector called weeks that has the values 1 through 12 in it\nweeks <- 1:12\n\n# use the regression model to make a vector called gallons with\n# weeks as the values\ngallons <- 3 + 2 * weeks\n\n# make a data frame of weeks and gallons\nwater <- data.frame(weeks, gallons)\n\n# Make a plot (Figure 9.9)\nwater |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = weeks, \n          y = gallons\n          )\n      ) +\n  ggplot2::geom_line(\n      ggplot2::aes(\n          linetype = \"Linear model\\ngallons=3+2*weeks\"\n          ), \n      color = \"gray60\", \n      linewidth = 1\n      ) + \n  ggplot2::geom_point(\n      ggplot2::aes(\n          color = \"Observation\"\n          ), \n      size = 4, \n      alpha = .6\n      ) +\n  ggplot2::labs(\n      x = \"Weeks\", \n      y = \"Gallons of water needed\"\n      ) +\n  ggplot2::scale_linetype_manual(values = 2, name = \"\") +\n  ggplot2::scale_color_manual(values = \"#7463AC\", name = \"\")\n```\n\n::: {.cell-output-display}\n![Example of a linear model with gallons of water needed as an outcome and weeks as a predictor](09-linear-regression_files/figure-html/fig-example-lm-water-weeks-1.png){#fig-example-lm-water-weeks width=672}\n:::\n:::\n\n***\n\nThere is nothing new in this code chunk, therefore I have just taken the code from the book only adapted with changes resulting from newer versions of {**ggplot2**} (e.g., `linewidth` instead of `size`). \n\nIt is important to know that the graph does not use the calculation of a linear model with `ggplot2::geom_smooth()` but merely uses `ggplot2::geom_line` to connect the points. We are using #eq-chap09-linear-model, e.g. a <a class='glossary' title='A deterministic equation, or model, has one precise value for y for each value of x. (SwR, Chap09)'>deterministic</a> formula.\n\n\n::::\n:::::\n\n\n###### stochastic\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-example-lm-water-weeks-with-errors}\n: Example of a stochastic linear model with gallons of water needed as an outcome and weeks as a predictor \n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make a vector called weeks that has the values 1 through 12 in it\nweeks <- 1:12\n\n# use the regression model to make a vector called gallons with\n# weeks as the values \n# but this time with simulated residuals\n\nset.seed(1001) # for reproducibility\ngallons <- 3 + (2 * weeks) + rnorm(12, 0, 2.5)\n\n# make a data frame of weeks and gallons\nwater <- data.frame(weeks, gallons)\n\n# calculate the residuals from the linear model\nres <- base::summary(\n    stats::lm(gallons ~ weeks, data = water)\n    )$residuals\n\n\nwater |> \n      ggplot2::ggplot(\n          ggplot2::aes(\n                x = weeks,\n                y = gallons\n          )\n      ) +\n      ggplot2::geom_point(\n            ggplot2::aes(\n                color = \"Observation\"\n          ), \n          size = 4, \n          alpha = .6\n      ) +\n      ggplot2::geom_smooth(\n          formula = y ~ x,\n          method = \"lm\",\n          se = FALSE,\n          ggplot2::aes(\n                linetype = \"Linear model\\ngallons=3+2*weeks\"\n          ), \n          color = \"gray60\", \n          linewidth = 1\n      ) +\n      ggplot2::geom_segment(\n          ggplot2::aes(\n              x = weeks,\n              y = gallons,\n              xend = weeks,\n              yend = gallons - res\n          )\n      )  +\n      ggplot2::labs(\n          x = \"Weeks\", \n          y = \"Gallons of water needed\"\n          ) +\n      ggplot2::scale_linetype_manual(values = 2, name = \"\") +\n      ggplot2::scale_color_manual(values = \"#7463AC\", name = \"\")\n```\n\n::: {.cell-output-display}\n![Example of a linear model with gallons of water needed as an outcome and weeks as a predictor with deviations (errors)](09-linear-regression_files/figure-html/fig-example-lm-water-weeks-with-errors-1.png){#fig-example-lm-water-weeks-with-errors width=672}\n:::\n:::\n\n***\n\nThis is my replication of book’s Figure 9.10, where no R example code is available. I am proud to state that I did this graph without looking ahead or to read the tutorial by Jackson [-@jackson2016] that is recommended later in the book. To draw this graph I had to take three new actions:\n\n1. I had to simulate with `stats::rnorm()` residuals to change from @eq-chap09-linear-model to the second line of @eq-chap09-lm-rewritten.\n2. I had to calculate a linear model to get the residuals with `base::summary(stats::lm())`.\n3. I had this time to compute the line for the linear model with `ggplot2::geom_smooth()`.\n\nWithout these three code addition, I wouldn’t have been able to draw the vertical lines from the observations to the line of the linear model. \n\n\n\n\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n\n\nAlthough I managed to create @fig-example-lm-water-weeks-with-errors myself I mixed up in the explaining text the concepts of errors and residuals.\n\n::: {.callout-important #imp-errors-residuals}\n##### Errors vs. Residuals\n\nErrors and residuals are two closely related and easily confused measures:\n\n- The error of an observation is the deviation of the observed value from the true value of a quantity of interest (for example, a population mean). \n- The residual is the difference between the observed value and the estimated value of the quantity of interest (for example, a sample mean).\n:::\n\n\n## Achievement 3: Slope and Intercept {#sec-chap09-achievement3}\n\n### Introduction\n\nA <a class='glossary' title='Simple does not mean easy; instead, it is the term used for a statistical model used to predict or explain a continuous outcome by a single predictor. (SwR, Glossary, Chap09)'>simple linear regression</a> model could be used to examine the relationship between the percentage of people without health insurance and the distance to a syringe program for a county.\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-formula-distance-insurance}\n: Regression of people without health insurance and the distance to SSP\n::::::\n:::\n::::{.my-theorem-container}\n$$\ndistance = b_{0} + b_{1} \\times \\text{no\\_insurance}\n$$ {#eq-chap09-distance-insurance-regression}\n::::\n:::::\n\n### Computing the slope\n\nThe slope formula in @eq-chap09-slope is adding up the product of differences between the observed values and mean value of percentage uninsured (`no_insurance`) and the observed values and mean value of distance to syringe program (`dist_ssp`) for each of the 500 counties. This value is divided by the summed squared differences between the observed and mean values of `no_insurance` for each county.\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-slope}\n: Computing the slope\n::::::\n:::\n::::{.my-theorem-container}\n$$\nb_{1} = \\frac{\\sum_{i = 1}^n (x_{i}-m_{x})(y_{i}-m_{y})}{\\sum_{i = 1}^n (x_{i}-m_{x})^2}\n$$ {#eq-chap09-slope}\n\n***\n\n- $i$: individual observation, in this case a county\n- $n$: sample size, in this case 500\n- $x_{i}$: mean value of `no_insurance` for the sample\n- $y_{i}$: value of `dist_ssp` for $i$\n- $m_{y}$: mean value of `dist_ssp` for the sample\n- $\\sum$: symbol for the sum\n- $b_{i}$: slope\n\n::::\n:::::\n\n### Computing the intercept\n\nOnce the slope is computed, the intercept can be computed by putting the slope and the values of $m_{x}$ and $m_{y}$ into the equation for the line with x and y replaced by $m_{x}$ and $m_{y}$, $m_{y} = b_{0} + b_{1} times m_{x}$, and solving it for $b_{0}$, which is the y-intercept. Because this method of computing the slope and intercept relies on the squared differences and works to minimize the residuals overall, it is often called ordinary least squares or <a class='glossary' title='Ordinary least square regression (OLS) is a method of estimating a linear regression model that finds the regression line by minimizing the squared differences between each data point and the regression line. (Swr; Glossary)'>OLS</a> regression.\n\n### Estimating the linear regression model with R\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-ID-text}\n: Numbered Example Title\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### lm9.1\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-lm-distance-uninsured}\n: Linear regression of distance to syringe program by percent uninsured\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-lm-distance-uninsured}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## linear regression of distance to syringe program by percent uninsured\n\nlm9.1  <-  stats::lm(\n        formula = dist_ssp ~ no_insurance,\n        data = distance_ssp_clean, \n        na.action = na.exclude\n        )\n\nsave_data_file(\"chap09\", lm9.1, \"lm9.1.rds\")\n\nlm9.1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> stats::lm(formula = dist_ssp ~ no_insurance, data = distance_ssp_clean, \n#>     na.action = na.exclude)\n#> \n#> Coefficients:\n#>  (Intercept)  no_insurance  \n#>       12.480         7.819\n```\n\n\n:::\n:::\n\n\nLinear regression of distance to syringe program by percent uninsured\n:::\n***\n\nThe books does not go into details of the results from `stats::lm()` but recommends immediately to use `base::summary(stats::lm())` to get the best results. The reason is that the summary output of the linear model has much more details (See lst-chap09-summary-lm-distance-uninsured). But I think that it is important to know that there are many different aspects of the result incorporated in the `lm` object that are not reported. \n\n![Screenshot of the lm9.1 object](img/chap09/lm9.1-screenshot-min.png){#fig-chap09-lm9.1-screenshot \nfig-alt=\"The screenshot lists different aspects of the result. From top to bottom: coefficients, residuals, effects, rank, fitted.values, assign, qr, df.residual, xlevels, call, terms, model\" fig-align=\"center\" \nwidth=\"95%\"}\n\n***\nHidden in the object are important results:\n\n- <a class='glossary' title='Residuals are the differences between the observed values and the predicted values. (SwR, Glossary)'>residuals</a>: In @sec-chap09-understanding-residuals I have used the computed residuals from the `lm9.1` object to draw the vertical lines from the observation points (`dist_ssp`) to the regression line in @lst-chap09-regression-with-residuals.\n- `fitted.values`: These values build the regression line and are identical with the results from `stats::predict(lm9.1)` used in @lst-chap09-predict-all-values.\n- `effects`: There is also a vector the size of the sample (500) called `effects`. I have looked up what this mean and came to the following definition which I do not (up to now) understand:\n\n> For a linear model fitted by lm or aov, the effects are the uncorrelated single-degree-of-freedom values obtained by projecting the data onto the successive orthogonal subspaces generated by the QR decomposition during the fitting process. The first r (the rank of the model) are associated with coefficients and the remainder span the space of residuals (but are not associated with particular residuals). ([effects: Effects from Fitted Model](https://rdrr.io/r/stats/effects.html))\n\nSome help what effects are why they are important is the explanation of orthogonal in a statistical context. After reading ([Orthogonal: Models, Definition & Finding](https://statisticsbyjim.com/regression/orthogonality/)) I got some first vague ideas about the meaning of effects. Hopefully I will learn later was they mean in details and how they are computed.\n\n::::\n:::::\n\n###### summary lm9.1\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-summary-lm-distance-uninsured}\n: Estimating the linear regression model of people without health insurance and the distance to SSP using R\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-summary-lm-distance-uninsured}\n\n::: {.cell}\n\n```{.r .cell-code}\n# linear regression of distance to syringe program by percent uninsured\n\nbase::summary(lm9.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> stats::lm(formula = dist_ssp ~ no_insurance, data = distance_ssp_clean, \n#>     na.action = na.exclude)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -217.71  -60.86  -21.61   47.73  290.77 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   12.4798    10.1757   1.226    0.221    \n#> no_insurance   7.8190     0.7734  10.110   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 85.91 on 498 degrees of freedom\n#> Multiple R-squared:  0.1703,\tAdjusted R-squared:  0.1686 \n#> F-statistic: 102.2 on 1 and 498 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nSummary of linear regression of distance to syringe program by percent uninsured\n:::\n***\n\n- <a class='glossary' title='The intercept is the value of the dependent variables if all independent variables have the value zero. (Intercept, Slope in Regression)'>Intercept</a>: The $y$-intercept of 12.48 is the $y$-value when $x$ is zero. The model predicts that a county with 0% of people being uninsured would have a distance to the nearest syringe program of 12.48 miles.\n- <a class='glossary' title='The slope is the increase in the dependent variable when the independent variable increases with one unit and all other independent variables remain the same. (Intercept, Slope in Regression)'>Slope</a>: The slope of 7.82 is the change in $y$ for every one-unit change in $x$. If the percent uninsured goes up by 1% in a county, the distance in miles to a syringe program would change by 7.82 miles.\n\n***\n\n$$\n\\begin{align*}\ndistance = 12.48 + 7.82 \\times \\text{no\\_insurance} \\\\\ndistance = 12.48 + 7.82 \\times 10 = 90.68\n\\end{align*}\n$$\nBased on the linear regression model, a county with 10% of people uninsured would be 90.68 miles from the nearest syringe program.\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n\n\n### Understanding residuals {#sec-chap09-understanding-residuals}\n\nIn @fig-example-lm-water-weeks-with-errors I have already graphed a demonstration how the residuals relate to the regression line. The regression line minimizes the residual differences between the values predicted by the regression line and the observed values. \n\nThis is how <a class='glossary' title='Ordinary least square regression (OLS) is a method of estimating a linear regression model that finds the regression line by minimizing the squared differences between each data point and the regression line. (Swr; Glossary)'>OLS</a> works. OLS minimizes those distances captured in @fig-example-lm-water-weeks-with-errors by the solid vertical lines: It minimizes the <a class='glossary' title='Residuals are the differences between the observed values and the predicted values. (SwR, Glossary)'>residuals</a>.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap05-regression-with-residuals}\n: Regression with residuals between percentage without health insurance and distance to nearest SSP\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-regression-with-residuals}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## for a later calculation\ndist_mean <- base::mean(distance_ssp_clean$dist_ssp)\n\n## provide all data into one data frame\n## to check which column to subtract from what column\ndf_lm <- distance_ssp_clean |>\n    dplyr::mutate(\n        lm_residuals = lm9.1$residuals,\n        lm_fitted_values = lm9.1$fitted.values,\n        lm_mean = dist_ssp - dist_mean\n    )\n\nsave_data_file(\"chap09\", df_lm, \"df_lm.rds\")\n\ngg_residuals <- df_lm |> \n      ggplot2::ggplot(\n          ggplot2::aes(\n                y = dist_ssp,\n                x = no_insurance\n          )\n      ) +\n      ggplot2::geom_smooth(\n          formula = y ~ x,\n          method = \"lm\",\n          se = FALSE,\n          ggplot2::aes(\n                linetype = \"Linear model\"\n          ), \n          color = \"gray60\", \n          linewidth = 1\n      ) +\n      ggplot2::geom_point(\n            ggplot2::aes(\n                color = \"Observation\"\n          ), \n          size = 1, \n          alpha = .6\n      ) +\n      ggplot2::geom_segment(\n          ggplot2::aes(\n              x = no_insurance,\n              y = dist_ssp,\n              xend = no_insurance,\n              yend = dist_ssp - lm_residuals,\n              linewidth = \"Residuals\"\n          ),\n          linetype = \"solid\",\n          color = \"grey\",\n          alpha = .6\n      )  +\n      ggplot2::labs(\n          y = \"Distance to nearest SSP facility\", \n          x = \"Percentage of people without health insurance \"\n          ) +\n      ggplot2::scale_linetype_manual(values = 2, name = \"\") +\n      ggplot2::scale_linewidth_manual(values = .5, name = \"\") +\n      ggplot2::scale_color_manual(values = \"#7463AC\", name = \"\")\n\ngg_residuals\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/regression-with-residuals-1.png){width=672}\n:::\n:::\n\n\nRelationship between percentage without health insurance and distance to nearest syringe program in 500 counties with residuals (vertical lines)\n:::\n\n***\n\nThis is the replication of Figure 9.12, where no example code is available. After I had calculated the linear model I needed either the position on the regression line (`lm_fitted_values` in my case) or the values of the residuals (`lm_residuals`). I couldn't use `base::summary(stats::lm())` because `fitted.values` are calculated only for the `lm` object (in my case `lm_dist`), which also has the residuals computed and included. \n\nIn the end I decided to subtract the residuals from the distance to get the position of the regression line (and the end of the vertical line from the observation).\n::::\n:::::\n\n## Achievement 4: Slope interpretation and significance {#sec-chap09-achievement4}\n\n### Interpreting statistical significance of the slope\n\nThe output of @lst-chap09-lm-distance-uninsured for the linear model included a <a class='glossary' title='The p-value is the probability that the test statistic is at least as big as it is under the null hypothesis (SwR, Glossary)'>p-value</a> for the <a class='glossary' title='The slope is the increase in the dependent variable when the independent variable increases with one unit and all other independent variables remain the same. (Intercept, Slope in Regression)'>slope</a> (<2e16) and a p-value for the <a class='glossary' title='The intercept is the value of the dependent variables if all independent variables have the value zero. (Intercept, Slope in Regression)'>intercept</a> (0.221). \nThe statistical significance of the slope in linear regression is tested using a <a class='glossary' title='Wald test is the statistical test for comparing the value of the coefficient in linear or logistic regression to the hypothesized value of zero; the form is similar to a one-sample t-test, although some Wald tests use a t-statistic and others use a z-statistic as the test statistic. (SwR, Glossary)'>Wald test</a>, which is like a <a class='glossary' title='One-sample t-test, also known as the single-parameter t-test or single-sample t-test, is an inferential statistical test comparing the mean of a numeric variable to a population or hypothesized mean. (SwR, Glossary)'>one-sample t-test</a> where the hypothesized value of the slope is zero. To get the p-value from the regression model of distance to syringe program, the slope of 12.48 was compared to a hypothesized value of zero using the Wald test.\n\n\n#### NHST Step 1\n\nWrite the null and alternate hypotheses:\n\n::: {.callout-note}\n- **H0**: The slope of the line is equal to zero.\n- **HA**: The slope of the line is not equal to zero.\n:::\n\n#### NHST Step 2\n\nCompute the test statistic. \n\nThe test statistic for the Wald test in <a class='glossary' title='Ordinary least square regression (OLS) is a method of estimating a linear regression model that finds the regression line by minimizing the squared differences between each data point and the regression line. (Swr; Glossary)'>OLS</a> regression is the <a class='glossary' title='The T-Statistic is used in a T test when you are deciding if you should support or reject the null hypothesis. It’s very similar to a Z-score and you use it in the same way: find a cut off point, find your t score, and compare the two. You use the t statistic when you have a small sample size, or if you don’t know the population standard deviation. (Statistics How-To)'>t-statistic</a>.\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-wald-test}\n: Formula for the for the Wald test in OLS regression\n::::::\n:::\n::::{.my-theorem-container}\n$$\n\\begin{align*}\nt = &\\frac{b_{1}-0}{se_{b_{1}}} \\\\\nt = &\\frac{7.8190-0}{0.7734} = 10.11\n\\end{align*}\n$$ {#eq-chap09-wald-test}\n\n***\n\nNote that the formula is the same as the formula for the one-sample t-test from @eq-chap06-t-statistic, but with the slope of the regression model instead of the mean. The t-statistic, that was computed manually in @eq-chap09-wald-test can also be found in the model output of @lst-chap09-lm-distance-uninsured.\n\n::::\n:::::\n\n#### NHST Step 3\n\nReview and interpret the test statistics: \nCalculate the probability that your test statistic is at least as big as it is if there is no relationship (i.e., the null is true).\n\nThe p-value of the slope in @lst-chap09-lm-distance-uninsured is < 2e-16.\n\n#### NHST Step 4\n\nConclude and write report.\n\nThe p-value is < 0.01 and therefore the null hypothesis is rejected in favor of the alternate hypothesis that the slope is not equal to zero.\n\n::: {.callout#rep-chap09-lm9.1-1}\n## Interpretation of the linear regression model `lm9.1` after NHST (first draft)\n\nThe percentage of uninsured residents in a county is a statistically significant predictor of the distance to the nearest syringe program (b = 7.82; p < .05) in our sample. For every 1% increase in uninsured residents in a county, the predicted distance to the nearest syringe program increases by 7.82 miles.\n:::\n\n### Computing confidence intervals\n\n`stats::confint()` computes the confidence interval for the intercept and the slope.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-compute-confint}\n: Confidence interval for regression parameters\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-compute-confint}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstats::confint(lm9.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                  2.5 %    97.5 %\n#> (Intercept)  -7.512773 32.472391\n#> no_insurance  6.299493  9.338435\n```\n\n\n:::\n:::\n\nConfidence interval for regression parameters\n:::\n\n***\n\nThe intercept is often reported but not interpreted because it does not usually contribute much to answering the research question.\n\n\n\n::: {.callout #rep-chap09-lm9.1-2}\n## Interpretation of the linear regression model `lm9.1` after statistical significance and confidence intervals (second draft)\n\nThe percentage of uninsured residents in a county is a statistically significant predictor of the distance to the nearest syringe program (b = 7.82; p < .05). For every 1% increase in uninsured residents in a county, the predicted distance to the nearest syringe program increases by 7.82 miles. The value of the slope in the sample is 7.82, and the value of the slope is likely between 6.30 and 9.34 in the population that the sample came from (95% CI: 6.30–9.34). With every 1% increase in uninsured residents in a county, the nearest syringe program is between 6.30 and 9.34 more miles away. These results suggest that counties with a larger percentage of uninsured are farther from this resource, which may exacerbate existing health disparities.\n:::\n\n\n::::\n:::::\n\n### Making predcitions\n\nPredicted values of $y$ are called `y-hat` and denoted $\\hat{y}$. The `stats::predict()` function can be used to find the predicted values for all observations, or for a specific value of the independent variable.\n\n::: {.callout-important #imp-ID}\n## `stats::predict()` as a generic function \n\n`stats::predict()` is a generic function for predictions from the results of various model fitting functions. The function invokes particular methods which depend on the class of the first argument. \n\nIn our case we have to consult the help page of `stats::predict.lm()`. R knows which method to apply so just using `stats::predict()` is enough to invoke the correct computation. But for us users to know which arguments to apply we need the specified help page and not the explanation of the generic command.\n\nMost prediction methods which are similar to those for linear models have an argument `newdata` specifying the first place to look for explanatory variables to be used for prediction. \n:::\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-prediction}\n: Using the model to make prediction\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Predict value\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-predict-one-value}\n: Predict distance for a county where 10% of people are uninsured\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {#lst-chap09-predict-one-value}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstats::predict(\n    lm9.1,\n    newdata = data.frame(no_insurance = 10),\n    interval = \"confidence\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>        fit      lwr      upr\n#> 1 90.66945 82.42356 98.91534\n```\n\n\n:::\n:::\n\n\nPredicted distance for a county where 10% of people are uninsured\n:::\n\n***\n\nThe predicted distance to a syringe program from a county with 10% of people uninsured is 90.67 miles with a confidence interval for the prediction (sometimes called a prediction interval) of 82.42 to 98.92 miles.\n\n::::\n:::::\n\n\n###### Predict all\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-predict-all-values}\n: Find predictions for all observed values\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-predict-all-values}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_all <- tibble::as_tibble(\n    stats::predict(\n        lm9.1,\n        interval = \"confidence\"\n    )\n)\n\nglance_data(pred_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10 × 4\n#>      obs   fit   lwr   upr\n#>    <int> <dbl> <dbl> <dbl>\n#>  1     1  52.4  39.2  65.5\n#>  2    49 245.  218.  273. \n#>  3    74  93.0  84.9 101. \n#>  4   122  78.9  69.5  88.3\n#>  5   146  87.5  79.0  96.1\n#>  6   153  75.0  65.2  84.9\n#>  7   228  78.2  68.7  87.6\n#>  8   321  82.1  73.0  91.1\n#>  9   485 160.  148.  173. \n#> 10   500  56.3  43.7  68.8\n```\n\n\n:::\n:::\n\n\nPredicted values for all observed x\n:::\n\n\n***\n\nThis is the same code as in @lst-chap09-predict-one-value but without the `newdata` line.\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n***\n\n## Achievement 5: Model fit {#sec-chap09-achievement5}\n\n### Introduction\n\nThere is another <a class='glossary' title='The p-value is the probability that the test statistic is at least as big as it is under the null hypothesis (SwR, Glossary)'>p-value</a> toward the bottom of @lst-chap09-summary-lm-distance-uninsured. This p-value was from a test statistic that measures how much better the regression line is at getting close to the data points compared to the mean value of the outcome. Essentially, the question asked to produce this p-value is: Are the predicted values shown by the regression line in Figure 9.13 better than the mean value of the distance to the syringe program at capturing the relationship between `no_insurance` and `dist_ssp`?\n\n\n::: {.callout-important #imp-chap07-f-statistic}\n## F-statistic for linear regression\n\nLike the <a class='glossary' title='The T-Statistic is used in a T test when you are deciding if you should support or reject the null hypothesis. It’s very similar to a Z-score and you use it in the same way: find a cut off point, find your t score, and compare the two. You use the t statistic when you have a small sample size, or if you don’t know the population standard deviation. (Statistics How-To)'>t-statistic</a> is the test statistic for a <a class='glossary' title='A t-test is a type of statistical analysis used to compare the averages of two groups and determine whether the differences between them are more likely to arise from random chance. (Wikipedia)'>t-test</a> comparing two means, the <a class='glossary' title='F-statistic is a test statistic comparing explained and unexplained variance in [ANOVA] and linear regression. The F-statistic is a ratio where the variation between the groups is compared to the variation within the groups. (SwR, Glossary)'>F-statistic</a> is the test statistic for linear regression comparing the regression line to the mean.\n\nIt is the same F-statistic that we have seen working with <a class='glossary' title='Analysis of variance is a statistical method used to compare means across groups to determine whether there is a statistically significant difference among the means; typically used when there are three or more means to compare. (SwR, Glossary)'>ANOVA</a> in @sec-chap07. ANOVA is actually a special type of linear model where all the predictors are categorical.\n:::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-mean-vs-regression}\n: Distance to mean versus regression line\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-mean-vs-regression}\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_means <- df_lm |> \n    ggplot2::ggplot(\n      ggplot2::aes(\n            y = dist_ssp,\n            x = no_insurance\n        )\n    ) +\n    ggplot2::geom_point(\n            ggplot2::aes(\n                color = \"County\"\n        ), \n        size = 1, \n        alpha = .6\n    ) +\n    ggplot2::geom_hline(\n        ggplot2::aes(\n            linewidth = \"Mean observed\\ndistance to SSP\",\n            yintercept = dist_mean,\n        ),\n        color = \"grey60\",\n        alpha = .6\n    ) +\n    ggplot2::geom_segment(\n      ggplot2::aes(\n          x = no_insurance,\n          y = dist_ssp,\n          xend = no_insurance,\n          yend = dist_ssp - lm_mean,\n          linetype = \"Difference from mean\\nto observed\"\n      ),\n      color = \"grey\",\n      alpha = .6\n    )  +\n    ggplot2::labs(\n      y = \"Miles to syringe program\", \n      x = \"Percentage of people without health insurance \"\n      ) +\n    \n    ggplot2::scale_linewidth_manual(values = 1, name = \"\") +\n    ggplot2::scale_linetype_manual(values = c(2, 2), name = \"\") +\n    ggplot2::scale_color_manual(values = \"#7463AC\", name = \"\")\n\n\ngg_residuals2 <- df_lm |>\n      ggplot2::ggplot(\n          ggplot2::aes(\n                y = dist_ssp,\n                x = no_insurance\n          )\n      ) +\n      ggplot2::geom_smooth(\n          formula = y ~ x,\n          method = \"lm\",\n          se = FALSE,\n          ggplot2::aes(\n                linetype = \"Predicted distance to\\nSSP (regression line)\"\n          ),\n          color = \"gray60\",\n          linewidth = 1\n      ) +\n      ggplot2::geom_point(\n            ggplot2::aes(\n                color = \"County\"\n          ),\n          size = 1,\n          alpha = .6\n      ) +\n      ggplot2::geom_segment(\n          ggplot2::aes(\n              x = no_insurance,\n              y = dist_ssp,\n              xend = no_insurance,\n              yend = dist_ssp - lm_residuals,\n              linewidth = \"Residuals (diff from\\npredicted to observe)\"\n          ),\n          linetype = \"dashed\",\n          color = \"grey\",\n          alpha = .6\n      )  +\n      ggplot2::labs(\n          y = \"Miles to syringe program\",\n          x = \"Percentage of people without health insurance \"\n          ) +\n      ggplot2::scale_linetype_manual(values = 1, name = \"\") +\n      ggplot2::scale_linewidth_manual(values = .5, name = \"\") +\n      ggplot2::scale_color_manual(values = \"#7463AC\", name = \"\")\n\npatchwork:::\"/.ggplot\"(\n    gg_residuals2,\n    gg_means\n)\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/mean-vs-regression-1.png){width=672}\n:::\n:::\n\n\nWhat is smaller? Sum of distances to regression line or distances to mean?\n:::\n\n::::\n:::::\n\n\n### Understanding F-statistic\n\nThe F-statistic is a ratio of explained information (in the numerator) to unexplained information (in the denominator). If a model explains more than it leaves unexplained, the numerator is larger and the F-statistic is greater than 1. F-statistics that are much greater than 1 are explaining much more of the variation in the outcome than they leave unexplained. Large F-statistics are more likely to be statistically significant.\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-f-statistic}\n: F-statistic for the linear regression\n::::::\n:::\n::::{.my-theorem-container}\n$$\n\\begin{align*}\nF = \\frac{\\frac{\\sum_{i=1}^{n}(\\hat{y}-m_{y})^2}{p-1}}{\\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y_{i}})^2}{n-p}}\n\\end{align*}\n$$ {#eq-chap09-f-statistic}\n\n***\n\n- $i$: individual observation, in this case a county\n- $n$: sample size, or total number of counties, in this case 500\n- $p$: number of parameters in the model; slope and intercept are parameters\n- $y_{i}$: observed outcome of distance to syringe program for county $i$\n- $\\hat{y_{i}}$: predicted value of distance to syringe program for county $i$\n- $m_{y}$: mean of the observed outcomes of distance to syringe program\n\n**Numerator**: How much differ the predicted values from the observed mean on average. ($MS_{regression}$)\n**Denominator**: How much differ the predicted values from the actual observed values on average. ($MS_{residual}$)\n\n::::\n:::::\n\nThe <a class='glossary' title='F-statistic is a test statistic comparing explained and unexplained variance in [ANOVA] and linear regression. The F-statistic is a ratio where the variation between the groups is compared to the variation within the groups. (SwR, Glossary)'>F-statistic</a> is how much a predicted value differs from the mean value on average --- which is explained variance, or how much better (or worse) the prediction is than the mean at explaining the outcome --- divided by how much an observed value differs from the predicted value on average, which is the residual information or unexplained variance. Or: Explained variance divided by residual information resp. unexplained variance,\n\nSometimes, these relationships are referred to in similar terminology to <a class='glossary' title='Analysis of variance is a statistical method used to compare means across groups to determine whether there is a statistically significant difference among the means; typically used when there are three or more means to compare. (SwR, Glossary)'>ANOVA</a>: the numerator is the $MS_{regression}$ (where MS stands for <a class='glossary' title='Mean square is the mean of the squared differences between two values; mean squares are used to compute the F-statistic in analysis of variance and linear regression. (Swr, Glossary)'>mean square</a>) divided by the $MS_{residual}$.\n\n::: {.my-bulletbox }\n\n::::{.my-bulletbox-header} \n::::: {.my-bulletbox-icon}\n:::::\n::::::  {#bul-f-statistic}\n:::::: \n: Features of the F-statistic\n::::\n\n:::: {.my-bulletbox-body } \n- The F-statistic is always positive, due to the squaring of the terms in the numerator and denominator.\n- The F-statistic starts at 0 where the regression line is exactly the same as the mean.\n- The larger the F-statistic gets the more the model explains the variation in the outcome.\n- F-statistics with large values are less likely to occur when there is no relationship between the variables.\n- The shape of the F-distribution depends on the number of parameters in the statistical model and the sample size, which determine two <a class='glossary' title='Degree of Freedom (df) is the number of pieces of information that are allowed to vary in computing a statistic before the remaining pieces of information are known; degrees of freedom are often used as parameters for distributions (e.g., chi-squared, F). (SwR, Glossary)'>degrees of freedom</a> (df) values.\n\n***\nFor instance in the last line of @lst-chap09-summary-lm-distance-uninsured we see that the value of the F-statistic is 102.2 with 1 (p - 1 = 2 - 1 = 1) and 498 (n - p = 500 - 2 = 498) df.\n::::\n\n:::\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-graph-f-statistic}\n: F-distributions\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Examples for F-distributions\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-f-statistic-examples}\n: Examples of the distribution of probability density for $F$\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {#lst-chap09-f-statistic-examples}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot() +\n    ggplot2::xlim(0, 5) +\n    ggplot2::stat_function(\n        fun = df,\n        geom = \"line\",\n        args = list(df1 = 1, df2 = 20),\n        ggplot2::aes(color = \"F(1, 20)\")\n    ) +\n        ggplot2::stat_function(\n        fun = df,\n        geom = \"line\",\n        args = list(df1 = 2, df2 = 50),\n        ggplot2::aes(color = \"F(2, 50)\")\n    ) +\n        ggplot2::stat_function(\n        fun = df,\n        geom = \"line\",\n        args = list(df1 = 5, df2 = 100),\n        ggplot2::aes(color = \"F(5, 100)\")\n    ) +\n        ggplot2::stat_function(\n        fun = df,\n        geom = \"line\",\n        args = list(df1 = 10, df2 = 200),\n        ggplot2::aes(color = \"F(10, 200\")\n    ) +\n    ggplot2::scale_color_manual(\n        name = \"Distribution\",\n        values = c(\"darkgreen\", \"darkred\", \"darkblue\", \"darkorange\")\n    )\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/f-statistic-examples-1.png){width=672}\n:::\n:::\n\n\nExamples of the distribution of probability density for $F$\n:::\n\n***\nThis is the replication of Figure 9.15.\n\n::::\n:::::\n\n\n###### F-distribution `lm9.1`\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-f-dist-lm9.1}\n: F-distribution for model `lm9.1`\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-f-dist-lm9.1}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::ggplot() +\n    ggplot2::xlim(0, 110) +\n    ggplot2::stat_function(\n        fun = df,\n        geom = \"line\",\n        args = list(df1 = 1, df2 = 448),\n        ggplot2::aes(color = \"F(1, 448) distribution\")\n    ) +\n    ggplot2::geom_vline(\n        ggplot2::aes(\n            xintercept = 102.2,\n            color = \"F(1, 498) = 102.2\"\n        )\n    ) +\n    ggplot2::scale_color_manual(\n        name = \"\",\n        values = c(\"blue\", \"red\")\n    )\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/f-dist-lm9.1-1.png){width=672}\n:::\n:::\n\n\nF-distribution with 1 and 498 degrees of freedom for model of distance to syringe program by uninsured\n:::\n\n*** \n\nThis is the replication of Figure 9.16 of the book.\n\nThere is very little space under the curve from F = 102.2 to the right, which is consistent with the tiny p-value (p < .001) in @lst-chap09-summary-lm-distance-uninsured.\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n### Understanding $R^2$ measure of model fit\n\nThe measure[^linear-regression-1] how well the <a class='glossary' title='Model fit means how well the model captures the relationship in the observed data. (SwR, Glossary)'>model fits</a> is $R^2$ or <a class='glossary' title='R-squared is the percent of variance in a numeric variable that is explained by one or more other variables; the r-squared is also known as the coefficient of determination and is used as a measure of model fit in linear regression and an effect size in correlation analyses. (SwR, Glossary)'>R-squared</a>. \n\n[^linear-regression-1]: Maybe one should say that $R^2$ is not *the* but only *one* measure of model fit?\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-chap09-r2}\n::::::\n: Features of R-squared and adjusted R-squared\n::::\n:::: {.my-bulletbox-body}\n\n- $R^2$ is the amount of variation in the outcome that the model explains and is reported as a measure of model fit. \n- When the model predicts values that are close to the observed values, the correlation is high and the $R^2$ is high. \n- To get the percentage of variance explained by the model, multiply $R^2$ by 100.\n- Subtracting $R^2$ from 1 (1 – $R^2$) and multiplying by 100 for a percent will give the percent of variance *not* explained by the model.\n- The value of $R^2$ tends to increase with each additional variable added to the model, whether the variable actually improves the model or not.\n- <a class='glossary' title='Adjusted R-squared is a measure of model fit for ordinary least squares linear regression that penalizes the R-squared, or percentage of variance explained, for the number of variables in the model (SwR, Glossary)'>Adjusted $R^2$</a> ($R^2_{adj}$) penalizes the value of $R^2$ a small amount for each additional variable added to the model to ensure that the only increases when the additional predictors explain a notable amount of the variation in the outcome.\n\n***\n\n$R^2$ is computed by squaring the value of the <a class='glossary' title='Correlation coefficients are a standardized measure of how two variables are related, or co-vary. They are used to measure how strong a relationship is between two variables. There are several types of correlation coefficient, but the most popular is Pearson’s. Pearson’s correlation (also called Pearson’s R) is a correlation coefficient commonly used in linear regression. (Statistics How To)'>correlation</a> between the observed distance to syringe programs in the 500 counties and the values of distance to syringe programs predicted for the 500 counties by the model.\n\nFor the relationship between uninsured percentage and distance to syringe program in @lst-chap09-summary-lm-distance-uninsured, the $R^2$ is 0.1703. To get the percentage of variance explained by the model, multiply by 100, so 17.03% of the variation in distance to syringe programs is explained by the percentage of uninsured people living in a county.\n::::\n:::\n\n::: {.callout-important style=\"color: red;\" #imp-r2adj}\n###### $R^2_{adj}$ is more commonly reported than $R^2$\n:::\n\n### Reproting linear regression results\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-chap09-regression-report}\n::::::\n: Simple linear regression analysis results to report\n::::\n:::: {.my-bulletbox-body}\n- Interpretation of the value of the slope (b) \n- Significance of the slope (t and p, confidence intervals) \n- Significance of the model (F and p) \n- Model fit ($R^2$ or better $R_{adj}^2$)\n::::\n:::\n\nThe following report is for our linear model lm9.1 example takein into account information from the\n\n- summary of the computed model (@lst-chap09-summary-lm-distance-uninsured) and the\n- computed confidence intervals (@lst-chap09-compute-confint).\n\n::: {.callout #rep-chap09-lm9.1-3}\n##### Interpretation of the linear regression model `lm9.1` after model fit (third draft)\n\nA simple linear regression analysis found that the percentage of uninsured residents in a county is a statistically significant predictor of the distance to the nearest syringe program (b = 7.82; p < .001). For every 1% increase in uninsured residents, the predicted distance to the nearest syringe program increases by 7.82 miles. The value of the slope is likely between 6.30 and 9.34 in the population that the sample came from (95% CI: 6.30–9.34). With every 1% increase in uninsured residents in a county, there is likely a 6.30- to 9.34-mile increase to the nearest syringe program. The model was statistically significantly better than the baseline model (the mean of the distance to syringe program) at explaining distance to syringe program [F(1, 498) = 102.2; p < .001] and explained 16.86% of the variance in the outcome ($R_{adj}^2$ = .1686). These results suggest that counties with lower insurance rates are farther from this resource, which may exacerbate existing health disparities.\n:::\n\n## Achievement 6: Conducting diagnostics {#sec-chap09-achievement6}\n\n### Introduction\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-chap09-lm-assumptions}\n::::::\n: Assumptions of simple linear regression\n::::\n:::: {.my-bulletbox-body}\n- Observations are independent. \n- The outcome is continuous.\n- The relationship between the two variables is linear (<a class='glossary' title='Linearity is the assumption of some statistical models that requires the outcome, or transformed outcome, to have a linear relationship with numeric predictors, where linear relationships are relationships that are evenly distributed around a line. (SwR, Glossary)'>linearity</a>).\n- The variance is constant with the points distributed equally around the line (<a class='glossary' title='Homoscedasticity is [homogeneity of variances], contrast is [Heteroscedasticity]. Homoscedasticity is an assumption of correlation and linear regression that requires that the variance of y be constant across all the values of x; visually, this assumption would show points along a fit line between x and y being evenly spread on either side of the line for the full range of the relationship. (SwR, Glossary)'>homoscedasticity</a>). \n- The <a class='glossary' title='Standardized residuals are the standardized differences between observed and expected values in a chi-squared analysis; a large standardized residual indicates that the observed and expected values were very different. (SwR, Glossary)'>residuals</a> are independent.\n- The residuals are normally distributed.\n::::\n:::\n\n\n### Linearity {#sec-chap09-check-linearity}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-linearity}\n: Check linearity with loess curve\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-check-linearity}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance_ssp_clean  |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = no_insurance, \n          y = dist_ssp)) +\n  ggplot2::geom_point(\n      ggplot2::aes(\n          size = \"County\"\n          ), \n      color = \"#7463AC\", \n      alpha = .6\n      ) +\n  ggplot2::geom_smooth(\n      formula = y ~ x,\n      ggplot2::aes(\n          color = \"Linear fit line\"\n          ), \n      method = \"lm\", \n      se = FALSE) +\n  ggplot2::geom_smooth(\n      formula = y ~ x,\n      ggplot2::aes(\n          color = \"Loess curve\"\n          ), \n      method = \"loess\",\n      se = FALSE\n      ) +\n  ggplot2::labs(\n      y = \"Miles to syringe program\", \n      x = \"Percent uninsured\") +\n  ggplot2::scale_color_manual(\n      values = c(\"gray60\", \"deeppink\"), \n      name = \"\"\n      ) +\n  ggplot2::scale_size_manual(values = 2, name = \"\")\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/check-linearity-1.png){width=672}\n:::\n:::\n\n\nChecking the linearity assumption\n\n:::\n\n***\n\nThe linearity assumption is met if a scatterplot of the two variables shows a relationship that falls along a line. An example where this assumption is met in the author’s opinion is @fig-graph1-cor. The route of the loess curve follows not exact the regression line, but there are only small deviations from the regression line. \n\nThe situation in @lst-chap09-check-linearity is a little different: Here the loess line is curved and shows deviation from the linear relationship especially at the lower level of the predictor but also at the zeniths of the two arcs. Harris therefore decided that in @lst-chap09-check-linearity the linearity assumption has failed. \n\n:::::{.my-remark}\n:::{.my-remark-header}\n:::::: {#rem-chap09-linearity-assumption}\n: How to check the linearity assumption more objectively?\n::::::\n:::\n::::{.my-remark-container}\nI think that these kinds of linearity judgements are quite subjective. It is easy to assess that both examples failed or vice versa have met the assumption. It would be nice to have a more objective test, similar to the <a class='glossary' title='Breusch-Pagan is a statistical test for determining whether variance is constant, which is used to test the assumption of homoscedasticity; Breusch-Pagan relies on the [chi-squared] distribution and is used during assumption checking for [homoscedasticity] in [linear regression]. (SwR, Glossary)'>Breusch-Pagan test</a> for the <a class='glossary' title='Homoscedasticity is [homogeneity of variances], contrast is [Heteroscedasticity]. Homoscedasticity is an assumption of correlation and linear regression that requires that the variance of y be constant across all the values of x; visually, this assumption would show points along a fit line between x and y being evenly spread on either side of the line for the full range of the relationship. (SwR, Glossary)'>homoscedasticity</a> assumption in @lst-chap09-check-homoscedasticity-breusch-pagan or generally the <a class='glossary' title='The Shapiro-Wilk test is a statistical test to determine or confirm whether a variable has a normal distribution; it is sensitive to small deviations from normality and not useful for sample sizes above 5,000 because it will nearly always find non-normality. (SwR, Glossary)'>Shapiro-Wilk</a> or <a class='glossary' title='The Anderson-Darling Goodness of Fit Test (AD-Test) is a measure of how well your data fits a specified distribution. It’s commonly used as a test for normality. (Statistics How-To)'>Anderson-Darling</a> tests for the normality assumption.\n\nDiagnostics are very important for linear regression models. I have not (yet) much experience but I am pretty sure there exist some tests for the linearity assumption of linear models. For instance I have found a reference in [Linear Regression Assumptions and Diagnostics in R: Essentials](http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials#regression-diagnostics-reg-diag) [@kassambara2018] to functions for plotting a collection of four diagnostic tests either in base R with `stats::plot(<model name>)` or using {**ggplot2**} with {**ggfortify**} with .\n\n\nTo give you an example of the power of these functions consider the following graph created with only 4 lines of code including calculating the model from scratch:\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-test-ggfortify}\n: Applying {**ggfortify**} to model and diagnose our model `lm9.1`\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-test-ggfortify}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggfortify)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Loading required package: ggplot2\n```\n\n\n:::\n\n```{.r .cell-code}\ngraphics::par(mfrow = c(1, 2))\nm <- stats::lm(dist_ssp ~ no_insurance, data = df_lm)\n\nggplot2::autoplot(m, which = 1:6, ncol = 3, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/test-ggfortify-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbase::detach(\"package:ggfortify\", unload = TRUE)\nbase::detach(\"package:ggplot2\", unload = FALSE)\n```\n:::\n\n\nApplying {**ggfortify**} to model and diagnose our model `lm9.1`\n:::\n\n::::\n:::::\n\n::::\n:::::\n\n\n**Conclusion**: The linearity assumption is *not* met.\n\n::::\n:::::\n\n\n### Checking homoscedasticity {#sec-chap09-check-homoscedasticity}\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-check-homoscedasticity}\n: Checking homoscedasticity\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Breusch-Pagan\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-homoscedasticity-breusch-pagan}\n: Check homoscedasticity with Breusch-Pagan test\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-check-homoscedasticity-breusch-pagan}\n\n::: {.cell}\n\n```{.r .cell-code}\nlmtest::bptest(formula = lm9.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tstudentized Breusch-Pagan test\n#> \n#> data:  lm9.1\n#> BP = 46.18, df = 1, p-value = 1.078e-11\n```\n\n\n:::\n:::\n\n\nChecking the homoscedasticity with the Breusch-Pagan test\n\n:::\n\n***\n\nThe assumption of <a class='glossary' title='Homoscedasticity is [homogeneity of variances], contrast is [Heteroscedasticity]. Homoscedasticity is an assumption of correlation and linear regression that requires that the variance of y be constant across all the values of x; visually, this assumption would show points along a fit line between x and y being evenly spread on either side of the line for the full range of the relationship. (SwR, Glossary)'>homoscedasticity</a> requires the data points are evenly distributed around the regression line. One way would be to check again @lst-chap09-check-linearity: The points seem closer to the line on the far left and then are more spread out around the line at the higher values of percentage uninsured. Zhis is an indicator that the assumption has failed.\n\nBut the <a class='glossary' title='Breusch-Pagan is a statistical test for determining whether variance is constant, which is used to test the assumption of homoscedasticity; Breusch-Pagan relies on the [chi-squared] distribution and is used during assumption checking for [homoscedasticity] in [linear regression]. (SwR, Glossary)'>Breusch-Pagan test</a> is another -- more objective -- way to test the homoscedasticity assumption. The tiny p-value confirm our first impression: The Null assumption, that the data points are evenly distributed around the regression line has to be rejected.\n\n**Conclusion**: The homoscedasticity assumption is *not* met.\n\n\n::::\n:::::\n\n\n###### predicted values vs. residuals\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-homoscedasticity-residuals}\n: Check homoscedasticity assumption plotting predicted values vs. residuals\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-check-homoscedasticity-residuals}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## scatterplot with mean as reference line\ngg_scatter_mean <- df_lm |> \n      ggplot2::ggplot(\n          ggplot2::aes(\n                x = lm_fitted_values,\n                y = lm_residuals\n          )\n      ) +\n      ggplot2::geom_point(\n            ggplot2::aes(\n                color = \"County\"\n          ), \n          size = 1, \n          alpha = .6\n      ) +\n      ggplot2::geom_hline(\n          ggplot2::aes(\n              yintercept = base::mean(lm_residuals),\n              linetype = \"Perfect prediction\\npredicted = observed\"\n          )\n      ) +\n      ggplot2::labs(\n          x = \"Predicted values of miles to syringe program\", \n          y = \"Residuals (distance between observed\\nand predicted value)\"\n          ) +\n      ggplot2::scale_linetype_manual(values = 2, name = \"\") +\n      ggplot2::scale_color_manual(values = \"#7463AC\", name = \"\")\n\ngg_scatter_mean\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/check-homoscedasticity-residuals-1.png){width=672}\n:::\n:::\n\nPredicted values and residuals from linear regression model of distance to syringe program by percentage uninsured in a county\n\n:::\n***\n\nAnother (third) way to examine the constant error variance assumption is plotting the predicted values versus the residuals. In @lst-chap09-check-homoscedasticity-residuals a dashed line is shown to indicate no relationship between the fitted (or predicted) values and the residuals, which would be the ideal situation to meet the assumption. This line is a helpful reference point for looking at these types of graphs.\n\nFor the homoscedasticity assumption to be met, the points should be roughly evenly distributed around the dashed line with no clear patterns. It should look like a cloud or random points on the graph with no distinguishable patterns. \n\nIn @lst-chap09-check-homoscedasticity-residuals, there is a clear pattern. Under the dashed line the distribution of the points suggest a negative correlation whereas above the line the points are distributed more randomly. This finding confirms the Breusch-Pagan test result.\n\nConclusion: The homoscedasticity assumption of the residuals is **not** met.\n\n\n::::\n:::::\n\n:::\n\n::::\n:::::\n\n### Independent residuals {#sec-chap09-check-residuals-independence}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-residuals-independence}\n: Testing the independence of residuals with the Durbin-Watson test\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-check-residuals-independence}\n\n::: {.cell}\n\n```{.r .cell-code}\nlmtest::dwtest(formula = lm9.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tDurbin-Watson test\n#> \n#> data:  lm9.1\n#> DW = 2.0103, p-value = 0.5449\n#> alternative hypothesis: true autocorrelation is greater than 0\n```\n\n\n:::\n:::\n\n\nTesting the independence of residuals with the Durbin-Watson test\n:::\n***\n\nResiduals have to be independent or unrelated to each other. Residuals that are independent do not follow a pattern. Conceptually, residuals are the variation in the outcome that the regression line does not explain. If the residuals form a pattern then the regression model is doing better for certain types of observations and worse for others.\n\nThe independence assumption of the residuals can be checked with the <a class='glossary' title='Durbin-Watson test is a statistical test that is used to check the assumption of independent residuals in linear regression; a Durbin-Watson statistic of 2 indicates that the residuals are independent. (SwR, Glossary)'>Durbin-Watson test</a>. A Durbin-Watson (`DW`, or `D-W`) statistic of 2 indicates perfectly independent residuals, meaning that the null hypothesis of the test (that the residuals are independet) cannot be rejected. An this in fact the case in @lst-chap09-check-residuals-independence, as the DW-value is very near to 2.\n\n**Conclusion**: The independence of residuals assumption *is* met.\n\n::::\n:::::\n\n### Normality of residuals {#sec-chap09-check-normality-residuals}\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-check-normality-residuals}\n: Testing the normality of residuals assumption\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### hist\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-normality-residuals-hist}\n: Histogramm of residuals\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-check-normality-residuals-hist}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_hist_dnorm(\n    df = df_lm, \n    v = df_lm$lm_residuals, \n    n_bins = 30,\n    x_label = \"Residuals (distance between observed\\nand predicted value)\"\n    )\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/check-normality-residuals-hist-1.png){width=672}\n:::\n:::\n\nTesting the normality of residuals assumption with a histogram of the residuals\n:::\n\n***\n\nThe histogram with the overlaid density curve of the theoretical normal distribution in @lst-chap09-check-normality-residuals-hist shows a right skewed distribution. This is an indicator that the normality assumption is not met.\n\nConclusion: The normality assumption of the residuals is *not* met\n::::\n:::::\n\n\n###### q-q plot\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-normality-residuals-qq-plot}\n: Checking normality assumption of the residuals with a Q-Q plot\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {#lst-chap09-check-normality-residuals-qq-plot}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_qq_plot(\n    df = df_lm,\n    v = df_lm$lm_residuals,\n    x_label = \"Theoretical normal distribution\",\n    y_label = \"Observed residuals (distance between\\nobserved and prdicted miles\\nto syringe program)\"\n)\n```\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/check-normality-residuals-qq-plot-1.png){width=672}\n:::\n:::\n\n\nTesting the normality of residuals assumption with a q-q plot\n:::\n\nThe q-q plot in @lst-chap09-check-normality-residuals-qq-plot shows some deviation form the normal distribution. Although it is again a quite subjective decision (See @rem-chap09-linearity-assumption) it seems that the assumption of normality has failed.\n\n**Conclusion**: The normality assumption of the residuals is *not* met.\n\n::::\n:::::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-normality-residuals-shapiro-wilk}\n: Checking normality assumption of the residuals with the Shapiro-Wilk normality test\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-normality-residuals-shapiro-wilk}\n\n::: {.cell}\n\n```{.r .cell-code}\nstats::shapiro.test(df_lm$lm_residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tShapiro-Wilk normality test\n#> \n#> data:  df_lm$lm_residuals\n#> W = 0.94357, p-value = 7.437e-13\n```\n\n\n:::\n:::\n\n\nChecking normality assumption of the residuals of linear model `lm9.1` with the Shapiro-Wilk normality test\n:::\n\nThis method is not mentioned, but I believe that you can also use the <a class='glossary' title='The Shapiro-Wilk test is a statistical test to determine or confirm whether a variable has a normal distribution; it is sensitive to small deviations from normality and not useful for sample sizes above 5,000 because it will nearly always find non-normality. (SwR, Glossary)'>Shapiro-Wilk test</a> for testing the normal distribution of residuals. At least the very tiny p-value rejects the Null (that the residuals have a normal distribution) and suggest the same conclusion as the other two (visually decided) tests.\n\n**Conclusion**: The normality assumption of the residuals is *not* met.\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n### Interpreting the assumption tests\n\n:::{.my-bulletbox}\n:::: {.my-bulletbox-header}\n::::: {.my-bulletbox-icon}\n:::::\n:::::: {#bul-chap09-lm-assumptions-lm9.1}\n::::::\n: Checking simple linear regression assumptions for model `lm9.1m`\n::::\n:::: {.my-bulletbox-body}\n- Observations are independent. **No**: Counties in the same state are not really independent. (This is a general problem for geographical data analysis.)\n- The outcome is continuous. **Yes**: The distance to a syringe program is measured in miles and can take any value of zero or higher.\n- The relationship between the two variables is linear (<a class='glossary' title='Linearity is the assumption of some statistical models that requires the outcome, or transformed outcome, to have a linear relationship with numeric predictors, where linear relationships are relationships that are evenly distributed around a line. (SwR, Glossary)'>linearity</a>). **No**: See: @sec-chap09-check-linearity\n- The variance is constant with the points distributed equally around the line (<a class='glossary' title='Homoscedasticity is [homogeneity of variances], contrast is [Heteroscedasticity]. Homoscedasticity is an assumption of correlation and linear regression that requires that the variance of y be constant across all the values of x; visually, this assumption would show points along a fit line between x and y being evenly spread on either side of the line for the full range of the relationship. (SwR, Glossary)'>homoscedasticity</a>). **No**: See @lst-chap09-check-homoscedasticity-breusch-pagan and @lst-chap09-check-homoscedasticity-residuals.\n- The <a class='glossary' title='Standardized residuals are the standardized differences between observed and expected values in a chi-squared analysis; a large standardized residual indicates that the observed and expected values were very different. (SwR, Glossary)'>residuals</a> are independent. **Yes**: See @sec-chap09-check-residuals-independence.\n- The residuals are normally distributed. **No**: See @lst-chap09-check-normality-residuals-hist and @lst-chap09-check-normality-residuals-qq-plot.\n::::\n:::\n\nBecause linear model `lm9.1` does not meet all the assumptions, the model has to be considered biased and should be interpreted with caution. Specifically, the results of a biased model are not usually considered generalizable to the population.\n\n### Using models diagnostics\n\nWe are not quite done checking model quality using <a class='glossary' title='Diagnostics in linear and logistic regression are a set of tests to identify outliers and influential values among the observations. (SwR, Glossary)'>diagnostics</a>. In addition to testing assumptions, we need to identify problematic observations: <a class='glossary' title='Outliers are observations with unusual values. (SwR, Glossary)'>outliers</a> or other <a class='glossary' title='An influential observation is an observation that changes the slope of a regression line. (SwR, Glossary)'>influential observations</a>.\n\nThere are several measures: \n\n- standardized residuals, \n- df-betas, \n- Cook’s distance, and \n- leverage. \n\nOne good strategy for identifying the truly problematic observations is to identify those observations that are outliers or influential observations on two or more of these four measures.\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-models-diagnostics}\n: Using models diagnostics to find outliers and influential values\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Standardizing residuals\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-standardize-residuals}\n: Standardize residuals to find outliers with `stats::rstandard()`\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-standardize-residuals}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf2_lm <- df_lm |> \n    dplyr::mutate(\n        standard_res = stats::rstandard(model = lm9.1),\n        predicted = stats::predict(object = lm9.1)\n    ) \n\nsave_data_file(\"chap09\", df2_lm, \"df2_lm.rds\")\n\nlm9.1_std_res <- df2_lm |> \n    dplyr::filter(base::abs(standard_res) > 1.96) |> \n    dplyr::select(c(county, state, dist_ssp, \n                    no_insurance, standard_res, predicted)) |> \n    dplyr::arrange(standard_res)\n\nprint(lm9.1_std_res, n = 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 26 × 6\n#>    county           state dist_ssp no_insurance standard_res predicted\n#>    <chr>            <fct>    <dbl>        <dbl>        <dbl>     <dbl>\n#>  1 gaines county    TX       49.7          32.6        -2.58     267. \n#>  2 wyandotte county KS        7.25         21          -1.98     177. \n#>  3 harlan county    NE      266.           10.9         1.96      97.7\n#>  4 caledonia county VT      224.            5.3         1.99      53.9\n#>  5 meade county     SD      268.           10.7         2.00      96.1\n#>  6 brazos county    TX      305.           14.1         2.12     123. \n#>  7 falls county     TX      343            18.9         2.13     160. \n#>  8 lampasas county  TX      326.           16.2         2.18     139. \n#>  9 pawnee county    KS      262             7.9         2.19      74.2\n#> 10 kiowa county     KS      272.            8.9         2.21      82.1\n#> 11 webb county      TX      436            30.2         2.21     249. \n#> 12 gonzales county  TX      386.           22.6         2.31     189. \n#> 13 lincoln county   ME      303.           11.4         2.35     102. \n#> 14 burnet county    TX      342            15.8         2.40     136. \n#> 15 lee county       TX      339.           14.6         2.48     127. \n#> 16 garfield county  NE      300             8.8         2.55      81.3\n#> 17 starr county     TX      510            35.1         2.66     287. \n#> 18 duval county     TX      461.           27.7         2.72     229. \n#> 19 kennebec county  ME      316.            8.5         2.76      78.9\n#> 20 waldo county     ME      344.           11.9         2.78     106. \n#> 21 comal county     TX      367.           13.9         2.86     121. \n#> 22 coryell county   TX      341.           10.2         2.90      92.2\n#> 23 dewitt county    TX      388.           14.8         3.03     128. \n#> 24 guadalupe county TX      387.           14.5         3.04     126. \n#> 25 jim wells county TX      456            21           3.26     177. \n#> 26 brooks county    TX      487            23.5         3.41     196.\n```\n\n\n:::\n:::\n\n\nStandardizing residuals to find outliers with `stats::rstandard`\n:::\n\n***\n\nStandardized <a class='glossary' title='Standardized residuals are the standardized differences between observed and expected values in a chi-squared analysis; a large standardized residual indicates that the observed and expected values were very different. (SwR, Glossary)'>residuals</a> are <a class='glossary' title='A z-score (also called a standard score) gives you an idea of how far from the mean a data point is. But more technically it’s a measure of how many standard deviations below or above the population mean a raw score is. (StatisticsHowTo)'>z-scores</a> for the residual values. \n\n\n\n::: {.callout-caution  #cau-diagnostics-standardize-residuals}\n##### Filter counties with absolute values of the residuals greater than 1.96\n\nIn my first trial, I forgot to filter using the *absolute* standardized residual values. I got a list of 24 counties -- the two counties at the top of the list with negative values were missing.\n:::\n\nThat there are only two counties with negative values means that most counties had 2018 distances to syringe programs that were farther away than predicted. Another observation: Most of the outlier counties are situated in Texas, including one that is nearer than predicted.\n\n::::\n:::::\n\nThere are 26 counties with outlier values, e.g., standardized residuals with an absolute value greater than 1.96.\n\n\n###### Standardizing residuals 2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-standardize-residuals2}\n: Standardize residuals manually to find outliers\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-standardize-residuals2}    \n\n::: {.cell}\n\n```{.r .cell-code}\ndf2a_lm <- df_lm |> \n    dplyr::mutate(\n        standard_res = (lm_residuals - \n            base::mean(lm_residuals)) / stats::sd(lm_residuals),\n        predicted = stats::predict(object = lm9.1)\n    ) \n\nlm9.1_outlier2 <- df2a_lm |> \n    dplyr::filter(base::abs(standard_res) > 1.96) |> \n    dplyr::select(c(county, state, dist_ssp, \n                    no_insurance, standard_res, predicted)) |> \n    dplyr::arrange(standard_res)\n\nprint(lm9.1_outlier2, n = 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 26 × 6\n#>    county           state dist_ssp no_insurance standard_res predicted\n#>    <chr>            <fct>    <dbl>        <dbl>        <dbl>     <dbl>\n#>  1 gaines county    TX       49.7          32.6        -2.54     267. \n#>  2 wyandotte county KS        7.25         21          -1.97     177. \n#>  3 harlan county    NE      266.           10.9         1.96      97.7\n#>  4 caledonia county VT      224.            5.3         1.99      53.9\n#>  5 meade county     SD      268.           10.7         2.00      96.1\n#>  6 brazos county    TX      305.           14.1         2.12     123. \n#>  7 falls county     TX      343            18.9         2.13     160. \n#>  8 lampasas county  TX      326.           16.2         2.18     139. \n#>  9 webb county      TX      436            30.2         2.18     249. \n#> 10 pawnee county    KS      262             7.9         2.19      74.2\n#> 11 kiowa county     KS      272.            8.9         2.21      82.1\n#> 12 gonzales county  TX      386.           22.6         2.30     189. \n#> 13 lincoln county   ME      303.           11.4         2.35     102. \n#> 14 burnet county    TX      342            15.8         2.40     136. \n#> 15 lee county       TX      339.           14.6         2.48     127. \n#> 16 garfield county  NE      300             8.8         2.55      81.3\n#> 17 starr county     TX      510            35.1         2.60     287. \n#> 18 duval county     TX      461.           27.7         2.70     229. \n#> 19 kennebec county  ME      316.            8.5         2.76      78.9\n#> 20 waldo county     ME      344.           11.9         2.78     106. \n#> 21 comal county     TX      367.           13.9         2.86     121. \n#> 22 coryell county   TX      341.           10.2         2.90      92.2\n#> 23 dewitt county    TX      388.           14.8         3.03     128. \n#> 24 guadalupe county TX      387.           14.5         3.04     126. \n#> 25 jim wells county TX      456            21           3.25     177. \n#> 26 brooks county    TX      487            23.5         3.39     196.\n```\n\n\n:::\n:::\n\n\nFind outliers with standardized residuals computed manually\n:::\n\n***\nWith @lst-chap09-diagnostics-standardize-residuals2 I have standardized residuals manually through `(lm_residuals - base::mean(lm_residuals)) / stats::sd(lm_residuals)`. There are small rounding differences in some counties but the list of outlier counties is identical.\n\n::::\n:::::\n\n###### dfbeta\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-dfbeta}\n: Using `dfbeta` to find influential values\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-dfbeta}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf3a_lm <- df2_lm |> \n    dplyr::mutate(\n        dfbeta_intercept = stats::dfbeta(model = lm9.1)[, 1],\n        dfbeta_slope = stats::dfbeta(model = lm9.1)[, 2]\n    ) \n\nsave_data_file(\"chap09\", df3a_lm, \"df3a_lm.rds\")\n\nlm9.1_dfbeta <- df3a_lm |> \n    dplyr::filter(base::abs(dfbeta_intercept) > 2 | \n                      base::abs(dfbeta_slope) > 2) |> \n    dplyr::select(c(county, state, dist_ssp, \n                    no_insurance, predicted, \n                    dfbeta_intercept, dfbeta_slope))\n\nprint(lm9.1_dfbeta, n = 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 7 × 7\n#>   county     state dist_ssp no_insurance predicted dfbeta_intercept dfbeta_slope\n#>   <chr>      <fct>    <dbl>        <dbl>     <dbl>            <dbl>        <dbl>\n#> 1 webb coun… TX       436           30.2      249.            -3.04        0.282\n#> 2 starr cou… TX       510           35.1      287.            -4.82        0.434\n#> 3 hendry co… FL        84.3         29.8      245.             2.55       -0.236\n#> 4 presidio … TX       171.          35.9      293.             2.75       -0.247\n#> 5 brooks co… TX       487           23.5      196.            -2.70        0.270\n#> 6 gaines co… TX        49.7         32.6      267.             4.10       -0.374\n#> 7 duval cou… TX       461.          27.7      229.            -3.15        0.298\n```\n\n\n:::\n:::\n\n\nComputing `dfbeta` to find influential values with `dfbeta` > 2\n:::\n\n***\n\nComputing `dfbeta` is a method to find influential values. `df_beta` removes each observation from the data frame, conducts the analysis again, and compares the intercept and slope for the model with and without the observation. Observations with high `dfbeta` values may be influencing the model. The book recommends a cutoff of 2.\n\n\n\n::: {.callout-warning #wrn-chap09-diagnostics-df-beta}\n##### Difference between `dfbeta` and `dfbetas`\n\nReading other resources [@zach2020a; @goldstein-greenwood2022] I noticed that they used another threshold: Instead of using 2 they recommended $2 / \\sqrt{n}$, where `n` is the sample size. But this would result in a cutoff value of $2 / \\sqrt{500}$ = 0.0894427 with the absurd high number of 343 counties as influential values.\n\nBut later I became aware that these resources are talking from `dfbetas` (plural) and not `dfbeta` (singular). Between these two measure there is a big difference: `dfbetas` are the standardized values, whereas `dfbeta` values depend on the scale of the data. \n\n> Consequently, some analysts opt to standardize DFBETA values—in which case they’re referred to as DFBETAS --- by dividing each DFBETA by the standard error estimate for $\\hat{\\beta_{j}}$ [Detecting Influential Points in Regression with DFBETA(S)](https://library.virginia.edu/data/articles/detecting-influential-points-in-regression-with-dfbetas) [@goldstein-greenwood2022]\n\n:::\n\n::::\n:::::\n\nThe result is a list of seven counties, six situated in Texas and one in Florida. All of them are listed because of higher absolute `dfbeta` intercept values.\n\n###### dfbetas\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-dfbetas}\n: Using `dfbetas` to find influential values\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-dfbetas}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf3b_lm <- df3a_lm |> \n    dplyr::mutate(\n        dfbetas_intercept = stats::dfbetas(model = lm9.1)[, 1],\n        dfbetas_slope = stats::dfbetas(model = lm9.1)[, 2]\n    ) \n\nsave_data_file(\"chap09\", df3b_lm, \"df3b_lm.rds\")\n\nlm9.1_dfbetas <- df3b_lm |> \n    dplyr::filter(base::abs(dfbetas_intercept) > (2 / base::sqrt(dplyr::n())) | \n                  base::abs(dfbetas_slope) > (2 / base::sqrt(dplyr::n()))) |> \n    dplyr::select(c(county, state, dist_ssp, \n                    no_insurance, predicted, \n                    dfbetas_intercept, dfbetas_slope))\n\nprint(lm9.1_dfbetas, n = 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 40 × 7\n#>    county  state dist_ssp no_insurance predicted dfbetas_intercept dfbetas_slope\n#>    <chr>   <fct>    <dbl>        <dbl>     <dbl>             <dbl>         <dbl>\n#>  1 gilles… TX      313            18.2     155.            -0.0617        0.100 \n#>  2 webb c… TX      436            30.2     249.            -0.300         0.365 \n#>  3 garfie… NE      300             8.8      81.3            0.116        -0.0782\n#>  4 starr … TX      510            35.1     287.            -0.476         0.564 \n#>  5 hendry… FL       84.3          29.8     245.             0.251        -0.307 \n#>  6 scott … KS      210             4.1      44.5            0.164        -0.142 \n#>  7 addiso… VT      166.            5.2      53.1            0.0992       -0.0830\n#>  8 bennin… VT      149.            4.8      50.0            0.0911       -0.0772\n#>  9 mcpher… KS      173.            6        59.4            0.0908       -0.0739\n#> 10 presid… TX      171.           35.9     293.             0.271        -0.320 \n#> 11 wyando… KS        7.25         21       177.             0.113        -0.158 \n#> 12 concor… LA       71.3          26.4     219.             0.178        -0.224 \n#> 13 antelo… NE      245.            8.6      79.7            0.0906       -0.0625\n#> 14 coryel… TX      341.           10.2      92.2            0.0978       -0.0522\n#> 15 hill c… TX      326.           19.7     167.            -0.0856        0.127 \n#> 16 orange… VT      202.            6.1      60.2            0.113        -0.0912\n#> 17 mitche… KS      198.            6.6      64.1            0.0992       -0.0786\n#> 18 jack c… TX      296.           18.9     160.            -0.0620        0.0959\n#> 19 suffol… MA      173.            4.4      46.9            0.121        -0.104 \n#> 20 essex … MA      191.            3.5      39.8            0.158        -0.139 \n#> 21 pawnee… KS      262             7.9      74.2            0.116        -0.0849\n#> 22 carrol… IA      152.            3.3      38.3            0.121        -0.107 \n#> 23 jim we… TX      456            21       177.            -0.187         0.263 \n#> 24 kinney… TX      291            22.8     191.            -0.0845        0.113 \n#> 25 llano … TX      318            17.8     152.            -0.0584        0.0986\n#> 26 somerv… TX      329.           19.5     165.            -0.0848        0.127 \n#> 27 kenneb… ME      316.            8.5      78.9            0.132        -0.0922\n#> 28 dallam… TX      106.           24.9     207.             0.106        -0.136 \n#> 29 gonzal… TX      386.           22.6     189.            -0.163         0.219 \n#> 30 kiowa … KS      272.            8.9      82.1            0.0983       -0.0657\n#> 31 lamb c… TX       54            21       177.             0.0816       -0.114 \n#> 32 brooks… TX      487            23.5     196.            -0.268         0.353 \n#> 33 gaines… TX       49.7          32.6     267.             0.405        -0.486 \n#> 34 el pas… TX       33.5          23.8     199.             0.156        -0.204 \n#> 35 maveri… TX      330            31.1     256.            -0.126         0.152 \n#> 36 bosque… TX      339            20.7     174.            -0.105         0.149 \n#> 37 falls … TX      343            18.9     160.            -0.0839        0.130 \n#> 38 duval … TX      461.           27.7     229.            -0.312         0.387 \n#> 39 caledo… VT      224.            5.3      53.9            0.149        -0.124 \n#> 40 hamilt… TX      314.           17.4     149.            -0.0514        0.0908\n```\n\n\n:::\n:::\n\n\nComputing `dfbetas` to find influential values with `dfbetas` > $ 2 / \\sqrt(500)$\n:::\n\n\n::::\n:::::\n\nInstead of seven we got now a bigger list with 40 counties.\n\n###### Cook’s D\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-cooks-d}\n: Using Cook’s distance to find influential values\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-cooks-d}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf4_lm <- df3b_lm |> \n    dplyr::mutate(\n        cooks_d = stats::cooks.distance(model = lm9.1)\n    ) \n\nsave_data_file(\"chap09\", df4_lm, \"df4_lm.rds\")\n\nlm9.1_cooks_d <- df4_lm |> \n    dplyr::filter(cooks_d > (4 / dplyr::n())) |> \n    dplyr::select(c(county, state, dist_ssp, \n                    no_insurance, predicted, \n                    cooks_d))\n\nprint(lm9.1_cooks_d, n = 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 32 × 6\n#>    county           state dist_ssp no_insurance predicted cooks_d\n#>    <chr>            <fct>    <dbl>        <dbl>     <dbl>   <dbl>\n#>  1 gillespie county TX      313            18.2     155.  0.00845\n#>  2 webb county      TX      436            30.2     249.  0.0713 \n#>  3 garfield county  NE      300             8.8      81.3 0.00954\n#>  4 starr county     TX      510            35.1     287.  0.165  \n#>  5 hendry county    FL       84.3          29.8     245.  0.0505 \n#>  6 scott county     KS      210             4.1      44.5 0.0137 \n#>  7 presidio county  TX      171.           35.9     293.  0.0533 \n#>  8 wyandotte county KS        7.25         21       177.  0.0164 \n#>  9 concordia parish LA       71.3          26.4     219.  0.0281 \n#> 10 coryell county   TX      341.           10.2      92.2 0.00977\n#> 11 hill county      TX      326.           19.7     167.  0.0115 \n#> 12 essex county     MA      191.            3.5      39.8 0.0127 \n#> 13 pawnee county    KS      262             7.9      74.2 0.00838\n#> 14 dewitt county    TX      388.           14.8     128.  0.0118 \n#> 15 jim wells county TX      456            21       177.  0.0446 \n#> 16 llano county     TX      318            17.8     152.  0.00862\n#> 17 somervell county TX      329.           19.5     165.  0.0117 \n#> 18 kennebec county  ME      316.            8.5      78.9 0.0118 \n#> 19 dallam county    TX      106.           24.9     207.  0.0107 \n#> 20 gonzales county  TX      386.           22.6     189.  0.0291 \n#> 21 guadalupe county TX      387.           14.5     126.  0.0113 \n#> 22 lamb county      TX       54            21       177.  0.00860\n#> 23 brooks county    TX      487            23.5     196.  0.0727 \n#> 24 comal county     TX      367.           13.9     121.  0.00918\n#> 25 burnet county    TX      342            15.8     136.  0.00885\n#> 26 gaines county    TX       49.7          32.6     267.  0.124  \n#> 27 el paso county   TX       33.5          23.8     199.  0.0245 \n#> 28 maverick county  TX      330            31.1     256.  0.0124 \n#> 29 bosque county    TX      339            20.7     174.  0.0147 \n#> 30 falls county     TX      343            18.9     160.  0.0129 \n#> 31 duval county     TX      461.           27.7     229.  0.0816 \n#> 32 caledonia county VT      224.            5.3      53.9 0.0116\n```\n\n\n:::\n:::\n\n\nUsing Cook’s distance to find influential values\n:::\n\n***\n\n<a class='glossary' title='Cook’s distance (often abbreviated Cook’s D) is used in Regression Analysis to find influential outliers in a set of predictor variables. IIt is a way to identify points that negatively affect the regression model. (Statistics How To)'>Cook’s D</a> is computed in a very similar way as `dfbeta(s)`. That is, each observation is removed and the model is re-estimated without it. Cook’s D then combines the differences between the models with and without an observation for all the parameters together instead of one at a time like the `dfbeta(s)`.\n\nThe cutoff for a high Cook’s D value is usually $4/n$.\n\n\n::::\n:::::\n\nThirty-two counties had a high Cook’s D. Most were in Texas (TX), but a few were in Maine (ME), Massachusetts (MA), and Vermont (VT).\n\n###### leverage\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-leverage}\n: Using leverage to find influential values\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-leverage}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf5_lm <- df4_lm |> \n    dplyr::mutate(\n        leverage = stats::hatvalues(model = lm9.1)\n    ) \n\nsave_data_file(\"chap09\", df5_lm, \"df5_lm.rds\")\n\nlm9.1_leverage <- df5_lm |> \n    dplyr::filter(leverage > 2 * 2 / dplyr::n()) |> \n    dplyr::select(c(county, state, dist_ssp, \n                    no_insurance, predicted, \n                    leverage))\n\nprint(lm9.1_leverage, n = 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 28 × 6\n#>    county                state dist_ssp no_insurance predicted leverage\n#>    <chr>                 <fct>    <dbl>        <dbl>     <dbl>    <dbl>\n#>  1 berkshire county      MA      104.            3        35.9  0.00883\n#>  2 webb county           TX      436            30.2     249.   0.0283 \n#>  3 starr county          TX      510            35.1     287.   0.0446 \n#>  4 hendry county         FL       84.3          29.8     245.   0.0271 \n#>  5 val verde county      TX      248.           22.8     191.   0.0111 \n#>  6 presidio county       TX      171.           35.9     293.   0.0476 \n#>  7 wyandotte county      KS        7.25         21       177.   0.00830\n#>  8 caldwell parish       LA      116.           21.2     178.   0.00859\n#>  9 concordia parish      LA       71.3          26.4     219.   0.0184 \n#> 10 essex county          MA      191.            3.5      39.8  0.00811\n#> 11 carroll county        IA      152.            3.3      38.3  0.00839\n#> 12 jim wells county      TX      456            21       177.   0.00830\n#> 13 kinney county         TX      291            22.8     191.   0.0111 \n#> 14 nicollet county       MN       17.8           3.5      39.8  0.00811\n#> 15 sabine county         TX      168.           22.1     185.   0.00997\n#> 16 bremer county         IA       86.7           3.4      39.1  0.00825\n#> 17 kodiak island borough AK      150            22.7     190.   0.0110 \n#> 18 dallam county         TX      106.           24.9     207.   0.0151 \n#> 19 gonzales county       TX      386.           22.6     189.   0.0108 \n#> 20 lamb county           TX       54            21       177.   0.00830\n#> 21 brooks county         TX      487            23.5     196.   0.0124 \n#> 22 jefferson county      TX      177.           21.5     181.   0.00903\n#> 23 gaines county         TX       49.7          32.6     267.   0.0358 \n#> 24 dawson county         TX       77            20.8     175.   0.00802\n#> 25 el paso county        TX       33.5          23.8     199.   0.0129 \n#> 26 maverick county       TX      330            31.1     256.   0.0310 \n#> 27 brantley county       GA      226.           24.4     203.   0.0141 \n#> 28 duval county          TX      461.           27.7     229.   0.0215\n```\n\n\n:::\n:::\n\n\nUsing leverage to find influential values\n:::\n\n***\n\nLeverage is determined by the difference between the value of an observation for a predictor and the mean value of the predictor. The farther away an observed value is from the mean for a predictor, the more likely the observation will be influential. Leverage values range between 0 and 1. A threshold of $2p / n$ is often used with `p` being the number of parameters and `n` being the sample size.\n\nThe leverage values to find influential states are computed by using the `stats::hatvalues()` function, because the predicted value of $y$ is often depicted as $\\hat{y}$.\n\n::::\n:::::\n\nThis time we got a list of 28 counties.\n\n:::\n\n::::\n:::::\n\n### Summarizing outliers and influential values\n\nIt would be useful to have all the counties identified by at least two of these four measures in a single list or table to more easily see all the counties that seemed problematic.\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-diagnostics-summary}\n: Summarizing outliers and influential values\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Outliers 1\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-summary1}\n: Summarizing diagnostics for outliers and influential values with `dfbeta`\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-summary1}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_lm_diag1 <- df5_lm |> \n    dplyr::mutate(outliers = \n       as.numeric(x = leverage > 2 * 2 / dplyr::n()) +\n       as.numeric(x = cooks_d > 4 / dplyr::n()) +\n       as.numeric(x = abs(x = dfbeta_intercept) > 2) +\n       as.numeric(x = abs(x = dfbeta_slope) > 2) +\n       as.numeric(x = abs(x = standard_res) > 1.96)) |> \n    dplyr::filter(outliers >= 2) |> \n    dplyr::select(county, state, dist_ssp, \n                  no_insurance, predicted, outliers) |> \n    dplyr::mutate(county = stringr::word(county, 1))\n    \ndf_print1 <- df_lm_diag1 |> \n    DT::datatable(\n        class = \"compact\",\n        options = list(\n            paging = FALSE,\n            searching = FALSE\n            ),\n        filter = \"top\",\n        colnames = c(\"ID\" = 1)\n    ) |> \n    DT::formatRound(c(\"dist_ssp\", \"predicted\"), 2) |> \n    DT::formatRound(\"no_insurance\", 1)\n    \n\ndf_print1\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-008ccd84c8368fd92a29\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-008ccd84c8368fd92a29\">{\"x\":{\"filter\":\"top\",\"vertical\":false,\"filterHTML\":\"<tr>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"factor\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"width: 100%; display: none;\\\">\\n      <select multiple=\\\"multiple\\\" style=\\\"width: 100%;\\\" data-options=\\\"[&quot;MN&quot;,&quot;GA&quot;,&quot;MO&quot;,&quot;IN&quot;,&quot;OK&quot;,&quot;TX&quot;,&quot;MS&quot;,&quot;IA&quot;,&quot;NM&quot;,&quot;IL&quot;,&quot;MA&quot;,&quot;NC&quot;,&quot;SC&quot;,&quot;AR&quot;,&quot;KY&quot;,&quot;MI&quot;,&quot;PA&quot;,&quot;LA&quot;,&quot;TN&quot;,&quot;NE&quot;,&quot;WV&quot;,&quot;SD&quot;,&quot;NY&quot;,&quot;AL&quot;,&quot;OH&quot;,&quot;VA&quot;,&quot;FL&quot;,&quot;KS&quot;,&quot;WA&quot;,&quot;MD&quot;,&quot;AZ&quot;,&quot;CA&quot;,&quot;DE&quot;,&quot;VT&quot;,&quot;CT&quot;,&quot;MT&quot;,&quot;CO&quot;,&quot;UT&quot;,&quot;OR&quot;,&quot;WI&quot;,&quot;ND&quot;,&quot;NJ&quot;,&quot;NV&quot;,&quot;AK&quot;,&quot;ID&quot;,&quot;ME&quot;,&quot;DC&quot;,&quot;RI&quot;,&quot;WY&quot;]\\\"><\\/select>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"7.25\\\" data-max=\\\"510\\\" data-scale=\\\"2\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"3.5\\\" data-max=\\\"35.9\\\" data-scale=\\\"1\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"39.846183275937\\\" data-max=\\\"293.180620359593\\\" data-scale=\\\"14\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"2\\\" data-max=\\\"4\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n<\\/tr>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\"],[\"webb\",\"garfield\",\"starr\",\"hendry\",\"presidio\",\"wyandotte\",\"concordia\",\"coryell\",\"essex\",\"pawnee\",\"dewitt\",\"jim\",\"kennebec\",\"dallam\",\"gonzales\",\"guadalupe\",\"lamb\",\"brooks\",\"comal\",\"burnet\",\"gaines\",\"el\",\"maverick\",\"falls\",\"duval\",\"caledonia\"],[\"TX\",\"NE\",\"TX\",\"FL\",\"TX\",\"KS\",\"LA\",\"TX\",\"MA\",\"KS\",\"TX\",\"TX\",\"ME\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"VT\"],[436,300,510,84.33,170.67,7.25,71.33,341.1,190.65,262,388.5,456,315.54,106.33,386.5,386.71,54,487,366.71,342,49.67,33.47,330,343,460.6,224.29],[30.2,8.800000000000001,35.1,29.8,35.9,21,26.4,10.2,3.5,7.9,14.8,21,8.5,24.9,22.6,14.5,21,23.5,13.9,15.8,32.6,23.8,31.1,18.9,27.7,5.3],[248.612524946728,81.28669304579442,286.9254490735773,245.4849393037199,293.1806203595935,176.6780551575416,218.900461338151,92.23324279632277,39.84618327593702,74.24962534902618,128.200477690916,176.6780551575416,78.94100381353833,207.1720151768706,189.188397729574,125.8547884586599,176.6780551575416,196.2254654263423,121.1634099941478,136.0194417984362,267.3780388047766,198.5711546585983,255.6495926434963,160.258230531749,229.0651146779274,53.92031866947349],[4,2,4,3,3,3,2,2,2,2,2,3,2,2,3,2,2,4,2,2,4,2,2,2,4,2]],\"container\":\"<table class=\\\"compact\\\">\\n  <thead>\\n    <tr>\\n      <th>ID<\\/th>\\n      <th>county<\\/th>\\n      <th>state<\\/th>\\n      <th>dist_ssp<\\/th>\\n      <th>no_insurance<\\/th>\\n      <th>predicted<\\/th>\\n      <th>outliers<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"paging\":false,\"searching\":false,\"columnDefs\":[{\"targets\":4,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 1, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"targets\":3,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"targets\":5,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"className\":\"dt-right\",\"targets\":[3,4,5,6]},{\"name\":\" \",\"targets\":0},{\"name\":\"county\",\"targets\":1},{\"name\":\"state\",\"targets\":2},{\"name\":\"dist_ssp\",\"targets\":3},{\"name\":\"no_insurance\",\"targets\":4},{\"name\":\"predicted\",\"targets\":5},{\"name\":\"outliers\",\"targets\":6}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[\"options.columnDefs.0.render\",\"options.columnDefs.1.render\",\"options.columnDefs.2.render\"],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\nListing of all counties with influential values at least in two tests (using `dfbeta` like in the book)\n:::\n\n***\n\nHere I have use the threshold for the non-standardized `dfbeta` values, which in my opinion is the wrong option.\n\nI have used the R datatable package {**DT**} (see: @pak-DT), so you can experiment with the listed counties, for example sorting after certain columns or filtering certain states.\n\n::::\n:::::\n\n###### Outliers 2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-summary2}\n: Summarizing diagnostics for outliers and influential values with `dfbetas`\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-summary2}    \n\n::: {.cell}\n\n```{.r .cell-code}\ndf_lm_diag2 <- df5_lm |> \n    dplyr::mutate(outliers = \n       as.numeric(x = leverage > 2 * 2 / dplyr::n()) +\n       as.numeric(x = cooks_d > 4 / dplyr::n()) +\n       as.numeric(x = abs(x = dfbetas_intercept) > 2 / sqrt(dplyr::n())) +\n       as.numeric(x = abs(x = dfbetas_slope) > 2 / sqrt(dplyr::n())) +\n       as.numeric(x = abs(x = standard_res) > 1.96)) |> \n    dplyr::filter(outliers >= 2) |> \n    dplyr::select(county, state, dist_ssp, \n                  no_insurance, predicted, outliers)  |> \n    dplyr::mutate(county = stringr::word(county, 1))\n    \ndf_print2 <- df_lm_diag2 |> \n    DT::datatable(\n        class = \"compact\",\n        options = list(\n            paging = FALSE,\n            searching = FALSE\n            ),\n        filter = \"top\",\n        colnames = c(\"ID\" = 1)\n    ) |> \n    DT::formatRound(c(\"dist_ssp\", \"predicted\"), 2) |> \n    DT::formatRound(\"no_insurance\", 1)\n    \n\ndf_print2\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-29f760fab89c1872be1f\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-29f760fab89c1872be1f\">{\"x\":{\"filter\":\"top\",\"vertical\":false,\"filterHTML\":\"<tr>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"character\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"factor\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"width: 100%; display: none;\\\">\\n      <select multiple=\\\"multiple\\\" style=\\\"width: 100%;\\\" data-options=\\\"[&quot;MN&quot;,&quot;GA&quot;,&quot;MO&quot;,&quot;IN&quot;,&quot;OK&quot;,&quot;TX&quot;,&quot;MS&quot;,&quot;IA&quot;,&quot;NM&quot;,&quot;IL&quot;,&quot;MA&quot;,&quot;NC&quot;,&quot;SC&quot;,&quot;AR&quot;,&quot;KY&quot;,&quot;MI&quot;,&quot;PA&quot;,&quot;LA&quot;,&quot;TN&quot;,&quot;NE&quot;,&quot;WV&quot;,&quot;SD&quot;,&quot;NY&quot;,&quot;AL&quot;,&quot;OH&quot;,&quot;VA&quot;,&quot;FL&quot;,&quot;KS&quot;,&quot;WA&quot;,&quot;MD&quot;,&quot;AZ&quot;,&quot;CA&quot;,&quot;DE&quot;,&quot;VT&quot;,&quot;CT&quot;,&quot;MT&quot;,&quot;CO&quot;,&quot;UT&quot;,&quot;OR&quot;,&quot;WI&quot;,&quot;ND&quot;,&quot;NJ&quot;,&quot;NV&quot;,&quot;AK&quot;,&quot;ID&quot;,&quot;ME&quot;,&quot;DC&quot;,&quot;RI&quot;,&quot;WY&quot;]\\\"><\\/select>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"7.25\\\" data-max=\\\"510\\\" data-scale=\\\"2\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"3.3\\\" data-max=\\\"35.9\\\" data-scale=\\\"1\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"38.282390454433\\\" data-max=\\\"293.180620359593\\\" data-scale=\\\"14\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n  <td data-type=\\\"number\\\" style=\\\"vertical-align: top;\\\">\\n    <div class=\\\"form-group has-feedback\\\" style=\\\"margin-bottom: auto;\\\">\\n      <input type=\\\"search\\\" placeholder=\\\"All\\\" class=\\\"form-control\\\" style=\\\"width: 100%;\\\"/>\\n      <span class=\\\"glyphicon glyphicon-remove-circle form-control-feedback\\\"><\\/span>\\n    <\\/div>\\n    <div style=\\\"display: none;position: absolute;width: 200px;opacity: 1\\\">\\n      <div data-min=\\\"2\\\" data-max=\\\"5\\\"><\\/div>\\n      <span style=\\\"float: left;\\\"><\\/span>\\n      <span style=\\\"float: right;\\\"><\\/span>\\n    <\\/div>\\n  <\\/td>\\n<\\/tr>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\"],[\"gillespie\",\"webb\",\"garfield\",\"starr\",\"hendry\",\"scott\",\"presidio\",\"wyandotte\",\"concordia\",\"coryell\",\"hill\",\"orange\",\"suffolk\",\"essex\",\"pawnee\",\"dewitt\",\"carroll\",\"jim\",\"kinney\",\"llano\",\"somervell\",\"kennebec\",\"dallam\",\"gonzales\",\"kiowa\",\"guadalupe\",\"lamb\",\"brooks\",\"comal\",\"burnet\",\"gaines\",\"el\",\"maverick\",\"bosque\",\"falls\",\"duval\",\"caledonia\"],[\"TX\",\"TX\",\"NE\",\"TX\",\"FL\",\"KS\",\"TX\",\"KS\",\"LA\",\"TX\",\"TX\",\"VT\",\"MA\",\"MA\",\"KS\",\"TX\",\"IA\",\"TX\",\"TX\",\"TX\",\"TX\",\"ME\",\"TX\",\"TX\",\"KS\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"TX\",\"VT\"],[313,436,300,510,84.33,210,170.67,7.25,71.33,341.1,325.8,202.29,172.97,190.65,262,388.5,151.82,456,291,318,328.67,315.54,106.33,386.5,271.67,386.71,54,487,366.71,342,49.67,33.47,330,339,343,460.6,224.29],[18.2,30.2,8.800000000000001,35.1,29.8,4.1,35.9,21,26.4,10.2,19.7,6.1,4.4,3.5,7.9,14.8,3.3,21,22.8,17.8,19.5,8.5,24.9,22.6,8.9,14.5,21,23.5,13.9,15.8,32.6,23.8,31.1,20.7,18.9,27.7,5.3],[154.7849556564849,248.612524946728,81.28669304579442,286.9254490735773,245.4849393037199,44.53756174044918,293.1806203595935,176.6780551575416,218.900461338151,92.23324279632277,166.5134018177653,60.1754899554897,46.88325097270526,39.84618327593702,74.24962534902618,128.200477690916,38.28239045443296,176.6780551575416,190.7521905510781,151.6573700134768,164.9496089962612,78.94100381353833,207.1720151768706,189.188397729574,82.06858945654643,125.8547884586599,176.6780551575416,196.2254654263423,121.1634099941478,136.0194417984362,267.3780388047766,198.5711546585983,255.6495926434963,174.3323659252855,160.258230531749,229.0651146779274,53.92031866947349],[2,5,3,5,4,3,4,5,4,3,2,2,2,4,3,2,3,5,2,2,2,4,4,5,2,2,3,5,2,2,5,4,4,3,3,5,4]],\"container\":\"<table class=\\\"compact\\\">\\n  <thead>\\n    <tr>\\n      <th>ID<\\/th>\\n      <th>county<\\/th>\\n      <th>state<\\/th>\\n      <th>dist_ssp<\\/th>\\n      <th>no_insurance<\\/th>\\n      <th>predicted<\\/th>\\n      <th>outliers<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"paging\":false,\"searching\":false,\"columnDefs\":[{\"targets\":4,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 1, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"targets\":3,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"targets\":5,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"className\":\"dt-right\",\"targets\":[3,4,5,6]},{\"name\":\" \",\"targets\":0},{\"name\":\"county\",\"targets\":1},{\"name\":\"state\",\"targets\":2},{\"name\":\"dist_ssp\",\"targets\":3},{\"name\":\"no_insurance\",\"targets\":4},{\"name\":\"predicted\",\"targets\":5},{\"name\":\"outliers\",\"targets\":6}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[\"options.columnDefs.0.render\",\"options.columnDefs.1.render\",\"options.columnDefs.2.render\"],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\nListing of all counties with influential values at least in two tests (using `dfbetas`, different from the book)\n:::\n\n***\n\nHere I have use the threshold for the standardized `dfbetas` values, which in my opinion is the correct option. Although there is a big difference in the number of counties with cutoff `dfbeta` (7 counties) to `dfbetas`(40 counties) in the end the difference is only 11 counties. The listing shows some counties exceeding the threshold 5 times. The reason is that counties can have outliers corresponding to `dfbetas` intercept and `dfbetas` slope.\n\nI have used the R datatable package {**DT**} (see: @pak-DT), so you can experiment with the listed counties, for example sorting after certain columns or filtering certain states. If you sort for instance the distances to the next syringe program you will see that there are some counties with similar values that are not included in @lst-chap09-diagnostics-summary1, like kiowa county with similar values as garfied county.\n\n::::\n:::::\n\n###### difference\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-diagnostics-dfbetas-diff}\n: Difference between `dfbeta` and `dfbetas` results\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-diagnostics-dfbetas-diff}\n\n::: {.cell}\n\n```{.r .cell-code}\ncounty_join <- dplyr::full_join(df_lm_diag1, df_lm_diag2, by = c(\"county\", \"state\"))\ncounty_diff <- county_join |> dplyr::filter(is.na(dist_ssp.x)) |> \n    dplyr::select(-(3:6)) |> \n    dplyr::arrange(desc(dist_ssp.y))\n\nprint(county_diff, n = 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 11 × 6\n#>    county    state dist_ssp.y no_insurance.y predicted.y outliers.y\n#>    <chr>     <fct>      <dbl>          <dbl>       <dbl>      <dbl>\n#>  1 bosque    TX          339            20.7       174.           3\n#>  2 somervell TX          329.           19.5       165.           2\n#>  3 hill      TX          326.           19.7       167.           2\n#>  4 llano     TX          318            17.8       152.           2\n#>  5 gillespie TX          313            18.2       155.           2\n#>  6 kinney    TX          291            22.8       191.           2\n#>  7 kiowa     KS          272.            8.9        82.1          2\n#>  8 scott     KS          210             4.1        44.5          3\n#>  9 orange    VT          202.            6.1        60.2          2\n#> 10 suffolk   MA          173.            4.4        46.9          2\n#> 11 carroll   IA          152.            3.3        38.3          3\n```\n\n\n:::\n:::\n\n\nAdditional counties calculated with the standardized `dfbetas` (and not `dfbeta`)\n:::\n\n***\n\nThese 11 counties have not been included in the book’s version because of a different method (using unstandardized `dfbeta` with an undocumented threshold of 2 versus standardized `dfbetas` with the in several resource documented cutoff $2 / \\sqrt{n = samplesize}$.\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\nWhen an observation is identified as an outlier or influential value, it is worth looking at the data to see if there is anything that seems unusual. Sometimes, the observations are just different from the rest of the data, and other times, there is a clear data entry or coding error.\n\n\n::: {.callout #rep-chap09-lm9.1-4}\n##### Interpretation of the linear regression model `lm9.1` after diagnostics (final version)\n\nA simple linear regression analysis found that the percentage of uninsured residents in a county is a statistically significant predictor of the distance to the nearest syringe program (b = 7.82; p < .001). For every 1% increase in uninsured residents, the distance to the nearest syringe program is expected to increase by 7.82 miles. The value of the slope is likely between 6.30 and 9.34 in the population that the sample came from (95% CI: 6.30–9.34), so with every 1% increase in uninsured residents, there is likely a 6.30- to 9.34-mile increase in distance to the nearest syringe program. The model was statistically significantly better than the baseline at explaining distance to syringe program (F[1, 498] = 102.2; p < .001) and explained 16.86% of the variance in the outcome ($R_{adj}^2$ = .1686). These results suggest that counties with lower insurance rates are farther from this type of resource, which may exacerbate existing health disparities. \n\nAn examination of the underlying assumptions found that the data fail several of the assumptions for linear regression, and so the model should be interpreted with caution; the results do not necessarily generalize to other counties beyond the sample. In addition, regression diagnostics found a number of counties that were outliers or influential observations. Many of these counties were in Texas, which may suggest that counties in Texas are unlike the rest of the sample.\n:::\n\n\n## Achievement 7: Adding variables and transformation {#sec-chap09-achievement7}\n\n### Adding a binary variable `metro` to the model\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap09-lm9.2}\n: Adding binary variable `metro` to the model\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### Compute lm9.2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-lm9.2}\n: Linear regression: Distance to syringe program by uninsured percent and metro status\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-lm9.2}\n\n::: {.cell}\n\n```{.r .cell-code}\nlm9.2 <- stats::lm(formula = dist_ssp ~ no_insurance + metro,\n                   data = distance_ssp_clean)\n\nsave_data_file(\"chap09\", lm9.2, \"lm9.2.rds\")\n\nbase::summary(lm9.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> stats::lm(formula = dist_ssp ~ no_insurance + metro, data = distance_ssp_clean)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -219.80  -60.07  -18.76   48.33  283.96 \n#> \n#> Coefficients:\n#>                Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)      3.4240    10.3621   0.330 0.741212    \n#> no_insurance     7.3005     0.7775   9.389  < 2e-16 ***\n#> metronon-metro  28.0525     7.7615   3.614 0.000332 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 84.89 on 497 degrees of freedom\n#> Multiple R-squared:  0.1915,\tAdjusted R-squared:  0.1883 \n#> F-statistic: 58.88 on 2 and 497 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nLinear regression: Distance to syringe program by uninsured percent and metro status\n:::\n\n- Small p-values indicate that percentage uninsured and metro status both statistically significantly help to explain the distance to a syringe program.\n- The model is statistically significant, with an <a class='glossary' title='F-statistic is a test statistic comparing explained and unexplained variance in [ANOVA] and linear regression. The F-statistic is a ratio where the variation between the groups is compared to the variation within the groups. (SwR, Glossary)'>F-statistic</a> of F(2, 497) = 58.88 and a p-value of < .001.\n- $R_{adj}^2$ indicates that 18.83% of the variation in distance to syringe program is accounted for by this model with `no_insurance` and `metro` in it. This is somewhat higher than the $R_{adj}^2$ of 16.86 from the simple linear model with just `no_insurance` in it.\n- The coefficient for no_insurance of 7.30 means that for a county with 1% more uninsured people the distance to SSP grows by 7.30 miles.\n- `metronon-metro` is confusing because it combines two aspects: The variable name (here `metro`) and the category to which the coefficient refers (here `non-metro`). The other group name `metro` is the reference group for the `metro` variable[^linear-regression-2]. The non-metro counties are 28.05 miles farther away from the nearest syringe program than the metro counties.\n\n[^linear-regression-2]: Especially confusing here is that the variable has the same name as one group and additionally it is puzzling the the other group `non-metro` has a dash in its name that separates the second part with exactly the same name as variable and group coefficient. Another example to make things clearer: Imagine a binary variable `region` that consists of the two categories `urban` and `countryside` then we would see `regionurban` instead of `metronon-metro`.\n\n::::\n:::::\n\n\n###### Plot lm9.2\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-plot-lm9.2}\n: Graphing the regression model `lm9.2` with percent uninsured and metro\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-plot-lm9.2}    \n\n::: {.cell}\n\n```{.r .cell-code}\ndistance_ssp_clean |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = no_insurance, \n          y = dist_ssp, \n          group = metro)\n      ) +\n  ggplot2::geom_line(\n      data = broom::augment(x = lm9.2),\n      ggplot2::aes(\n          y = .fitted, \n          linetype = metro\n          )\n      ) +\n  ggplot2::geom_point(\n      ggplot2::aes(\n          text = county,\n          color = metro\n          ), \n      size = 2\n      ) +\n  ggplot2::labs(\n      y = \"Miles to nearest syringe program\",\n      x = \"County percent uninsured\"\n      ) +\n  ggokabeito::scale_color_okabe_ito(\n      order = c(1,3),\n      alpha = .4,\n      name = \"County\"\n      ) +\n  ggplot2::scale_linetype_manual(\n      values = c(1, 2), \n      name = \"Regression line\\n(predicted values)\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning in ggplot2::geom_point(ggplot2::aes(text = county, color = metro), :\n#> Ignoring unknown aesthetics: text\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](09-linear-regression_files/figure-html/plot-lm9.2-1.png){width=672}\n:::\n:::\n\n\nRegression model `lm9.2` with percent uninsured and metro\n:::\n\n*** \n\nThis is my reproduction of Figure 9.21. There are two differences noteworthy:\n\n- I used the colorblind friendly palette `scale_color_okabe_ito()` from the {**ggokabeito**} package (See: @ggokabeito). Therefore my colors are different from Figure 9.21. `scale_color_okabe_ito()` has 9 colors (default = `order = 1:9`). With the `order` argument you determine which colors you want to use. In my case the first and third color. `order = c(1, 3)`.\n- @lst-chap09-plot-lm9.2 is the first time that I have used the `augment()` function from the {**broom**} package (See: @pak-broom). I have already used `broom::glance()` and `broom::tidy()` in this chapter but I have not understood why and when to use one of these three functions. Therefore I am exploring how to apply these {**broom**} function in @sec-chap09-broom-exeriments.\n\n::::\n:::::\n\n###### interactive plot (experiment)\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-plot-interactive-lm9.2}\n: Graphing the regression model `lm9.2` as an interactive plot (experiment)\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-plot-interactive-lm9.2}    \n\n::: {.cell}\n\n```{.r .cell-code}\ntest_plot <- distance_ssp_clean |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = no_insurance, \n          y = dist_ssp, \n          group = metro)\n      ) +\n  ggplot2::geom_line(\n      data = broom::augment(x = lm9.2),\n      ggplot2::aes(\n          y = .fitted, \n          linetype = metro\n          )\n      ) +\n  ggplot2::geom_point(\n      ggplot2::aes(\n          text = county,\n          color = metro\n          ), \n      size = 2\n      ) +\n  ggplot2::labs(\n      y = \"Miles to nearest syringe program\",\n      x = \"County percent uninsured\"\n      ) +\n  ggokabeito::scale_color_okabe_ito(\n      order = c(1,3),\n      alpha = .4,\n      name = \"County\"\n      ) +\n  ggplot2::scale_linetype_manual(\n      values = c(1, 2), \n      name = \"Regression line\\n(predicted values)\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning in ggplot2::geom_point(ggplot2::aes(text = county, color = metro), :\n#> Ignoring unknown aesthetics: text\n```\n\n\n:::\n\n```{.r .cell-code}\nplotly::ggplotly(\n    p = test_plot,\n    tooltip = c(\"dist_ssp\", \"no_insurance\", \"text\")\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-50ed0d6e05f7ae2abda4\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-50ed0d6e05f7ae2abda4\">{\"x\":{\"data\":[{\"x\":[3,3.3999999999999999,3.5,3.5,3.8999999999999999,4,4.2000000000000002,4.4000000000000004,4.4000000000000004,4.4000000000000004,4.5999999999999996,4.7999999999999998,4.7999999999999998,5.0999999999999996,5.0999999999999996,5.0999999999999996,5.2000000000000002,5.2000000000000002,5.2000000000000002,5.2000000000000002,5.2999999999999998,5.2999999999999998,5.4000000000000004,5.5999999999999996,5.5999999999999996,5.5999999999999996,5.7000000000000002,5.9000000000000004,6,6.2000000000000002,6.2000000000000002,6.2999999999999998,6.5,6.5999999999999996,6.5999999999999996,6.7000000000000002,6.7000000000000002,6.7999999999999998,6.9000000000000004,6.9000000000000004,6.9000000000000004,7.0999999999999996,7.2000000000000002,7.2999999999999998,7.4000000000000004,7.5999999999999996,7.5999999999999996,7.7000000000000002,7.7000000000000002,7.7000000000000002,7.7999999999999998,7.7999999999999998,7.9000000000000004,8,8,8.1999999999999993,8.1999999999999993,8.3000000000000007,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.5,8.5,8.5999999999999996,8.5999999999999996,8.5999999999999996,8.6999999999999993,8.6999999999999993,8.8000000000000007,8.8000000000000007,8.8000000000000007,8.9000000000000004,8.9000000000000004,8.9000000000000004,8.9000000000000004,9,9,9.0999999999999996,9.0999999999999996,9.0999999999999996,9.1999999999999993,9.1999999999999993,9.3000000000000007,9.3000000000000007,9.3000000000000007,9.5,9.5,9.5999999999999996,9.5999999999999996,9.5999999999999996,9.5999999999999996,9.6999999999999993,9.9000000000000004,10.1,10.1,10.1,10.199999999999999,10.199999999999999,10.300000000000001,10.300000000000001,10.4,10.4,10.5,10.6,10.699999999999999,10.699999999999999,10.800000000000001,10.800000000000001,10.800000000000001,10.9,11,11.1,11.1,11.1,11.199999999999999,11.300000000000001,11.4,11.5,11.5,11.5,11.5,11.5,11.6,11.6,11.699999999999999,11.699999999999999,11.699999999999999,11.699999999999999,11.699999999999999,11.800000000000001,11.9,11.9,12,12,12.1,12.1,12.199999999999999,12.199999999999999,12.300000000000001,12.300000000000001,12.5,12.5,12.6,12.699999999999999,12.800000000000001,13,13,13,13.199999999999999,13.199999999999999,13.300000000000001,13.300000000000001,13.300000000000001,13.300000000000001,13.4,13.5,13.6,13.800000000000001,13.800000000000001,13.800000000000001,13.9,13.9,13.9,13.9,14.1,14.1,14.199999999999999,14.199999999999999,14.5,14.5,14.5,14.6,14.6,14.699999999999999,14.699999999999999,14.699999999999999,15,15.199999999999999,15.300000000000001,15.4,15.4,15.6,15.6,15.6,15.6,15.699999999999999,15.699999999999999,15.800000000000001,15.9,16,16,16.199999999999999,16.199999999999999,16.300000000000001,16.399999999999999,16.399999999999999,16.600000000000001,16.800000000000001,16.800000000000001,16.899999999999999,17,17.100000000000001,17.199999999999999,17.5,17.600000000000001,17.800000000000001,18,18.100000000000001,18.199999999999999,18.300000000000001,18.399999999999999,18.899999999999999,19.199999999999999,19.5,20,20.399999999999999,21,21.5,23.800000000000001,24.399999999999999,30.199999999999999],\"y\":[25.325446673062444,28.245641336240503,28.975690002035023,28.975690002035023,31.895884665213075,32.625933331007595,34.08603066259662,35.546127994185653,35.546127994185653,35.546127994185653,37.006225325774679,38.466322657363712,38.466322657363712,40.65646865474725,40.65646865474725,40.65646865474725,41.38651732054177,41.38651732054177,41.38651732054177,41.38651732054177,42.116565986336283,42.116565986336283,42.846614652130803,44.306711983719829,44.306711983719829,44.306711983719829,45.036760649514342,46.496857981103375,47.226906646897888,48.687003978486921,48.687003978486921,49.417052644281434,50.877149975870459,51.607198641664972,51.607198641664972,52.337247307459492,52.337247307459492,53.067295973254005,53.797344639048525,53.797344639048525,53.797344639048525,55.257441970637544,55.987490636432064,56.717539302226577,57.447587968021097,58.907685299610122,58.907685299610122,59.637733965404635,59.637733965404635,59.637733965404635,60.367782631199148,60.367782631199148,61.097831296993668,61.827879962788181,61.827879962788181,63.287977294377207,63.287977294377207,64.018025960171727,64.74807462596624,64.74807462596624,64.74807462596624,64.74807462596624,64.74807462596624,64.74807462596624,64.74807462596624,64.74807462596624,65.478123291760753,65.478123291760753,66.208171957555265,66.208171957555265,66.208171957555265,66.938220623349778,66.938220623349778,67.668269289144291,67.668269289144291,67.668269289144291,68.398317954938804,68.398317954938804,68.398317954938804,68.398317954938804,69.128366620733317,69.128366620733317,69.85841528652783,69.85841528652783,69.85841528652783,70.588463952322343,70.588463952322343,71.31851261811687,71.31851261811687,71.31851261811687,72.778609949705896,72.778609949705896,73.508658615500408,73.508658615500408,73.508658615500408,73.508658615500408,74.238707281294921,75.698804612883961,77.158901944472973,77.158901944472973,77.158901944472973,77.888950610267486,77.888950610267486,78.618999276062013,78.618999276062013,79.349047941856526,79.349047941856526,80.079096607651039,80.809145273445552,81.539193939240064,81.539193939240064,82.269242605034592,82.269242605034592,82.269242605034592,82.999291270829104,83.729339936623617,84.45938860241813,84.45938860241813,84.45938860241813,85.189437268212643,85.919485934007156,86.649534599801669,87.379583265596182,87.379583265596182,87.379583265596182,87.379583265596182,87.379583265596182,88.109631931390695,88.109631931390695,88.839680597185207,88.839680597185207,88.839680597185207,88.839680597185207,88.839680597185207,89.569729262979735,90.299777928774247,90.299777928774247,91.02982659456876,91.02982659456876,91.759875260363273,91.759875260363273,92.489923926157786,92.489923926157786,93.219972591952313,93.219972591952313,94.680069923541339,94.680069923541339,95.410118589335852,96.140167255130365,96.870215920924878,98.330313252513903,98.330313252513903,98.330313252513903,99.790410584102929,99.790410584102929,100.52045924989746,100.52045924989746,100.52045924989746,100.52045924989746,101.25050791569197,101.98055658148648,102.71060524728099,104.17070257887003,104.17070257887003,104.17070257887003,104.90075124466455,104.90075124466455,104.90075124466455,104.90075124466455,106.36084857625356,106.36084857625356,107.09089724204807,107.09089724204807,109.28104323943163,109.28104323943163,109.28104323943163,110.01109190522614,110.01109190522614,110.74114057102065,110.74114057102065,110.74114057102065,112.9312865684042,114.39138389999323,115.12143256578774,115.85148123158226,115.85148123158226,117.31157856317128,117.31157856317128,117.31157856317128,117.31157856317128,118.04162722896579,118.04162722896579,118.77167589476032,119.50172456055483,120.23177322634935,120.23177322634935,121.69187055793837,121.69187055793837,122.4219192237329,123.1519678895274,123.1519678895274,124.61206522111644,126.07216255270546,126.07216255270546,126.80221121849996,127.53225988429449,128.26230855008902,128.99235721588352,131.18250321326707,131.9125518790616,133.37264921065062,134.83274654223965,135.56279520803417,136.29284387382867,137.0228925396232,137.7529412054177,141.40318453439028,143.59333053177383,145.78347652915738,149.43371985812993,152.35391452130798,156.73420651607509,160.38444984504767,177.17556915832151,181.55586115308859,223.89868376917045],\"text\":[\"no_insurance:  3.0\",\"no_insurance:  3.4\",\"no_insurance:  3.5\",\"no_insurance:  3.5\",\"no_insurance:  3.9\",\"no_insurance:  4.0\",\"no_insurance:  4.2\",\"no_insurance:  4.4\",\"no_insurance:  4.4\",\"no_insurance:  4.4\",\"no_insurance:  4.6\",\"no_insurance:  4.8\",\"no_insurance:  4.8\",\"no_insurance:  5.1\",\"no_insurance:  5.1\",\"no_insurance:  5.1\",\"no_insurance:  5.2\",\"no_insurance:  5.2\",\"no_insurance:  5.2\",\"no_insurance:  5.2\",\"no_insurance:  5.3\",\"no_insurance:  5.3\",\"no_insurance:  5.4\",\"no_insurance:  5.6\",\"no_insurance:  5.6\",\"no_insurance:  5.6\",\"no_insurance:  5.7\",\"no_insurance:  5.9\",\"no_insurance:  6.0\",\"no_insurance:  6.2\",\"no_insurance:  6.2\",\"no_insurance:  6.3\",\"no_insurance:  6.5\",\"no_insurance:  6.6\",\"no_insurance:  6.6\",\"no_insurance:  6.7\",\"no_insurance:  6.7\",\"no_insurance:  6.8\",\"no_insurance:  6.9\",\"no_insurance:  6.9\",\"no_insurance:  6.9\",\"no_insurance:  7.1\",\"no_insurance:  7.2\",\"no_insurance:  7.3\",\"no_insurance:  7.4\",\"no_insurance:  7.6\",\"no_insurance:  7.6\",\"no_insurance:  7.7\",\"no_insurance:  7.7\",\"no_insurance:  7.7\",\"no_insurance:  7.8\",\"no_insurance:  7.8\",\"no_insurance:  7.9\",\"no_insurance:  8.0\",\"no_insurance:  8.0\",\"no_insurance:  8.2\",\"no_insurance:  8.2\",\"no_insurance:  8.3\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.5\",\"no_insurance:  8.5\",\"no_insurance:  8.6\",\"no_insurance:  8.6\",\"no_insurance:  8.6\",\"no_insurance:  8.7\",\"no_insurance:  8.7\",\"no_insurance:  8.8\",\"no_insurance:  8.8\",\"no_insurance:  8.8\",\"no_insurance:  8.9\",\"no_insurance:  8.9\",\"no_insurance:  8.9\",\"no_insurance:  8.9\",\"no_insurance:  9.0\",\"no_insurance:  9.0\",\"no_insurance:  9.1\",\"no_insurance:  9.1\",\"no_insurance:  9.1\",\"no_insurance:  9.2\",\"no_insurance:  9.2\",\"no_insurance:  9.3\",\"no_insurance:  9.3\",\"no_insurance:  9.3\",\"no_insurance:  9.5\",\"no_insurance:  9.5\",\"no_insurance:  9.6\",\"no_insurance:  9.6\",\"no_insurance:  9.6\",\"no_insurance:  9.6\",\"no_insurance:  9.7\",\"no_insurance:  9.9\",\"no_insurance: 10.1\",\"no_insurance: 10.1\",\"no_insurance: 10.1\",\"no_insurance: 10.2\",\"no_insurance: 10.2\",\"no_insurance: 10.3\",\"no_insurance: 10.3\",\"no_insurance: 10.4\",\"no_insurance: 10.4\",\"no_insurance: 10.5\",\"no_insurance: 10.6\",\"no_insurance: 10.7\",\"no_insurance: 10.7\",\"no_insurance: 10.8\",\"no_insurance: 10.8\",\"no_insurance: 10.8\",\"no_insurance: 10.9\",\"no_insurance: 11.0\",\"no_insurance: 11.1\",\"no_insurance: 11.1\",\"no_insurance: 11.1\",\"no_insurance: 11.2\",\"no_insurance: 11.3\",\"no_insurance: 11.4\",\"no_insurance: 11.5\",\"no_insurance: 11.5\",\"no_insurance: 11.5\",\"no_insurance: 11.5\",\"no_insurance: 11.5\",\"no_insurance: 11.6\",\"no_insurance: 11.6\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.8\",\"no_insurance: 11.9\",\"no_insurance: 11.9\",\"no_insurance: 12.0\",\"no_insurance: 12.0\",\"no_insurance: 12.1\",\"no_insurance: 12.1\",\"no_insurance: 12.2\",\"no_insurance: 12.2\",\"no_insurance: 12.3\",\"no_insurance: 12.3\",\"no_insurance: 12.5\",\"no_insurance: 12.5\",\"no_insurance: 12.6\",\"no_insurance: 12.7\",\"no_insurance: 12.8\",\"no_insurance: 13.0\",\"no_insurance: 13.0\",\"no_insurance: 13.0\",\"no_insurance: 13.2\",\"no_insurance: 13.2\",\"no_insurance: 13.3\",\"no_insurance: 13.3\",\"no_insurance: 13.3\",\"no_insurance: 13.3\",\"no_insurance: 13.4\",\"no_insurance: 13.5\",\"no_insurance: 13.6\",\"no_insurance: 13.8\",\"no_insurance: 13.8\",\"no_insurance: 13.8\",\"no_insurance: 13.9\",\"no_insurance: 13.9\",\"no_insurance: 13.9\",\"no_insurance: 13.9\",\"no_insurance: 14.1\",\"no_insurance: 14.1\",\"no_insurance: 14.2\",\"no_insurance: 14.2\",\"no_insurance: 14.5\",\"no_insurance: 14.5\",\"no_insurance: 14.5\",\"no_insurance: 14.6\",\"no_insurance: 14.6\",\"no_insurance: 14.7\",\"no_insurance: 14.7\",\"no_insurance: 14.7\",\"no_insurance: 15.0\",\"no_insurance: 15.2\",\"no_insurance: 15.3\",\"no_insurance: 15.4\",\"no_insurance: 15.4\",\"no_insurance: 15.6\",\"no_insurance: 15.6\",\"no_insurance: 15.6\",\"no_insurance: 15.6\",\"no_insurance: 15.7\",\"no_insurance: 15.7\",\"no_insurance: 15.8\",\"no_insurance: 15.9\",\"no_insurance: 16.0\",\"no_insurance: 16.0\",\"no_insurance: 16.2\",\"no_insurance: 16.2\",\"no_insurance: 16.3\",\"no_insurance: 16.4\",\"no_insurance: 16.4\",\"no_insurance: 16.6\",\"no_insurance: 16.8\",\"no_insurance: 16.8\",\"no_insurance: 16.9\",\"no_insurance: 17.0\",\"no_insurance: 17.1\",\"no_insurance: 17.2\",\"no_insurance: 17.5\",\"no_insurance: 17.6\",\"no_insurance: 17.8\",\"no_insurance: 18.0\",\"no_insurance: 18.1\",\"no_insurance: 18.2\",\"no_insurance: 18.3\",\"no_insurance: 18.4\",\"no_insurance: 18.9\",\"no_insurance: 19.2\",\"no_insurance: 19.5\",\"no_insurance: 20.0\",\"no_insurance: 20.4\",\"no_insurance: 21.0\",\"no_insurance: 21.5\",\"no_insurance: 23.8\",\"no_insurance: 24.4\",\"no_insurance: 30.2\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"(metro,1)\",\"legendgroup\":\"(metro,1)\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[3.2999999999999998,4,4.0999999999999996,4.7000000000000002,4.7999999999999998,5.2000000000000002,5.2999999999999998,5.2999999999999998,5.5,5.5,5.7000000000000002,5.9000000000000004,5.9000000000000004,6,6,6,6.0999999999999996,6.2000000000000002,6.2000000000000002,6.2000000000000002,6.2000000000000002,6.2000000000000002,6.2000000000000002,6.5,6.5999999999999996,6.7999999999999998,6.9000000000000004,6.9000000000000004,6.9000000000000004,7,7.2000000000000002,7.4000000000000004,7.4000000000000004,7.5999999999999996,7.5999999999999996,7.5999999999999996,7.7999999999999998,7.7999999999999998,7.9000000000000004,7.9000000000000004,8.0999999999999996,8.0999999999999996,8.1999999999999993,8.1999999999999993,8.1999999999999993,8.1999999999999993,8.3000000000000007,8.3000000000000007,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.4000000000000004,8.5,8.5,8.5,8.5999999999999996,8.5999999999999996,8.6999999999999993,8.6999999999999993,8.6999999999999993,8.6999999999999993,8.8000000000000007,8.8000000000000007,8.8000000000000007,8.8000000000000007,8.8000000000000007,8.9000000000000004,8.9000000000000004,9.0999999999999996,9.4000000000000004,9.4000000000000004,9.8000000000000007,9.8000000000000007,10,10,10.1,10.1,10.1,10.199999999999999,10.199999999999999,10.199999999999999,10.199999999999999,10.300000000000001,10.300000000000001,10.5,10.5,10.6,10.6,10.699999999999999,10.699999999999999,10.800000000000001,10.800000000000001,10.800000000000001,10.9,10.9,10.9,10.9,11,11.1,11.1,11.1,11.199999999999999,11.199999999999999,11.199999999999999,11.199999999999999,11.199999999999999,11.300000000000001,11.4,11.4,11.4,11.4,11.4,11.4,11.5,11.5,11.6,11.6,11.6,11.699999999999999,11.699999999999999,11.699999999999999,11.699999999999999,11.699999999999999,11.800000000000001,11.800000000000001,11.800000000000001,11.9,11.9,11.9,11.9,12,12,12,12.1,12.1,12.1,12.1,12.199999999999999,12.199999999999999,12.300000000000001,12.300000000000001,12.4,12.4,12.4,12.4,12.5,12.5,12.6,12.6,12.699999999999999,12.699999999999999,12.699999999999999,12.800000000000001,12.800000000000001,12.9,13,13,13,13,13.1,13.199999999999999,13.4,13.5,13.5,13.5,13.6,13.6,13.699999999999999,13.699999999999999,13.800000000000001,13.800000000000001,13.800000000000001,13.800000000000001,13.800000000000001,13.9,14,14,14.1,14.199999999999999,14.4,14.5,14.5,14.5,14.6,14.699999999999999,14.699999999999999,14.699999999999999,14.699999999999999,14.800000000000001,14.800000000000001,14.9,14.9,15,15,15,15.199999999999999,15.300000000000001,15.300000000000001,15.300000000000001,15.300000000000001,15.4,15.5,15.699999999999999,15.800000000000001,15.800000000000001,15.9,15.9,15.9,15.9,16,16,16.100000000000001,16.100000000000001,16.100000000000001,16.199999999999999,16.300000000000001,16.399999999999999,16.399999999999999,16.399999999999999,16.5,16.5,16.600000000000001,16.899999999999999,16.899999999999999,17,17.399999999999999,17.800000000000001,17.800000000000001,18,18.100000000000001,18.100000000000001,18.199999999999999,18.199999999999999,18.199999999999999,18.199999999999999,18.300000000000001,18.399999999999999,18.399999999999999,18.5,18.5,18.600000000000001,18.800000000000001,18.899999999999999,18.899999999999999,19.100000000000001,19.100000000000001,19.199999999999999,19.300000000000001,19.5,19.5,19.699999999999999,19.699999999999999,19.899999999999999,20.100000000000001,20.300000000000001,20.699999999999999,20.800000000000001,21,21,21.199999999999999,22.100000000000001,22.600000000000001,22.699999999999999,22.800000000000001,22.800000000000001,23.5,24.899999999999999,26.399999999999999,27.699999999999999,29.800000000000001,31.100000000000001,32.600000000000001,35.100000000000001,35.899999999999999],\"y\":[55.568045325614641,60.678385986176245,61.408434651970758,65.788726646737842,66.51877531253237,69.438969975710421,70.169018641504934,70.169018641504934,71.629115973093974,71.629115973093974,73.089213304683,74.549310636272025,74.549310636272025,75.279359302066538,75.279359302066538,75.279359302066538,76.009407967861051,76.739456633655578,76.739456633655578,76.739456633655578,76.739456633655578,76.739456633655578,76.739456633655578,78.929602631039103,79.65965129683363,81.119748628422656,81.849797294217183,81.849797294217183,81.849797294217183,82.579845960011681,84.039943291600707,85.500040623189747,85.500040623189747,86.960137954778773,86.960137954778773,86.960137954778773,88.420235286367799,88.420235286367799,89.150283952162312,89.150283952162312,90.610381283751337,90.610381283751337,91.340429949545864,91.340429949545864,91.340429949545864,91.340429949545864,92.070478615340377,92.070478615340377,92.80052728113489,92.80052728113489,92.80052728113489,92.80052728113489,93.530575946929403,93.530575946929403,93.530575946929403,94.260624612723916,94.260624612723916,94.990673278518429,94.990673278518429,94.990673278518429,94.990673278518429,95.720721944312942,95.720721944312942,95.720721944312942,95.720721944312942,95.720721944312942,96.450770610107455,96.450770610107455,97.91086794169648,100.10101393908003,100.10101393908003,103.0212086022581,103.0212086022581,104.48130593384711,104.48130593384711,105.21135459964162,105.21135459964162,105.21135459964162,105.94140326543614,105.94140326543614,105.94140326543614,105.94140326543614,106.67145193123066,106.67145193123066,108.13154926281969,108.13154926281969,108.8615979286142,108.8615979286142,109.59164659440872,109.59164659440872,110.32169526020324,110.32169526020324,110.32169526020324,111.05174392599776,111.05174392599776,111.05174392599776,111.05174392599776,111.78179259179227,112.51184125758678,112.51184125758678,112.51184125758678,113.24188992338129,113.24188992338129,113.24188992338129,113.24188992338129,113.24188992338129,113.97193858917581,114.70198725497032,114.70198725497032,114.70198725497032,114.70198725497032,114.70198725497032,114.70198725497032,115.43203592076483,115.43203592076483,116.16208458655935,116.16208458655935,116.16208458655935,116.89213325235386,116.89213325235386,116.89213325235386,116.89213325235386,116.89213325235386,117.62218191814839,117.62218191814839,117.62218191814839,118.3522305839429,118.3522305839429,118.3522305839429,118.3522305839429,119.08227924973741,119.08227924973741,119.08227924973741,119.81232791553192,119.81232791553192,119.81232791553192,119.81232791553192,120.54237658132644,120.54237658132644,121.27242524712096,121.27242524712096,122.00247391291548,122.00247391291548,122.00247391291548,122.00247391291548,122.73252257870999,122.73252257870999,123.4625712445045,123.4625712445045,124.19261991029902,124.19261991029902,124.19261991029902,124.92266857609353,124.92266857609353,125.65271724188804,126.38276590768255,126.38276590768255,126.38276590768255,126.38276590768255,127.11281457347707,127.84286323927158,129.30296057086062,130.03300923665512,130.03300923665512,130.03300923665512,130.76305790244965,130.76305790244965,131.49310656824417,131.49310656824417,132.2231552340387,132.2231552340387,132.2231552340387,132.2231552340387,132.2231552340387,132.9532038998332,133.6832525656277,133.6832525656277,134.41330123142222,135.14334989721672,136.60344722880575,137.33349589460028,137.33349589460028,137.33349589460028,138.0635445603948,138.7935932261893,138.7935932261893,138.7935932261893,138.7935932261893,139.52364189198383,139.52364189198383,140.25369055777833,140.25369055777833,140.98373922357285,140.98373922357285,140.98373922357285,142.44383655516188,143.17388522095638,143.17388522095638,143.17388522095638,143.17388522095638,143.90393388675091,144.63398255254543,146.09407988413443,146.82412854992896,146.82412854992896,147.55417721572348,147.55417721572348,147.55417721572348,147.55417721572348,148.28422588151801,148.28422588151801,149.01427454731254,149.01427454731254,149.01427454731254,149.74432321310701,150.47437187890154,151.20442054469606,151.20442054469606,151.20442054469606,151.93446921049059,151.93446921049059,152.66451787628509,154.85466387366861,154.85466387366861,155.58471253946314,158.50490720264119,161.42510186581927,161.42510186581927,162.8851991974083,163.61524786320282,163.61524786320282,164.34529652899732,164.34529652899732,164.34529652899732,164.34529652899732,165.07534519479185,165.80539386058635,165.80539386058635,166.53544252638088,166.53544252638088,167.2654911921754,168.72558852376443,169.45563718955893,169.45563718955893,170.91573452114798,170.91573452114798,171.64578318694248,172.37583185273701,173.83592918432603,173.83592918432603,175.29602651591506,175.29602651591506,176.75612384750409,178.21622117909311,179.67631851068214,182.59651317386019,183.32656183965472,184.78665917124374,184.78665917124374,186.24675650283277,192.81719449498343,196.46743782395598,197.1974864897505,197.927535155545,197.927535155545,203.03787581610661,213.25855713722981,224.20928712414752,233.69991977947623,249.03094176116105,258.52157441648973,269.47230440340746,287.7235210482703,293.5639103746264],\"text\":[\"no_insurance:  3.3\",\"no_insurance:  4.0\",\"no_insurance:  4.1\",\"no_insurance:  4.7\",\"no_insurance:  4.8\",\"no_insurance:  5.2\",\"no_insurance:  5.3\",\"no_insurance:  5.3\",\"no_insurance:  5.5\",\"no_insurance:  5.5\",\"no_insurance:  5.7\",\"no_insurance:  5.9\",\"no_insurance:  5.9\",\"no_insurance:  6.0\",\"no_insurance:  6.0\",\"no_insurance:  6.0\",\"no_insurance:  6.1\",\"no_insurance:  6.2\",\"no_insurance:  6.2\",\"no_insurance:  6.2\",\"no_insurance:  6.2\",\"no_insurance:  6.2\",\"no_insurance:  6.2\",\"no_insurance:  6.5\",\"no_insurance:  6.6\",\"no_insurance:  6.8\",\"no_insurance:  6.9\",\"no_insurance:  6.9\",\"no_insurance:  6.9\",\"no_insurance:  7.0\",\"no_insurance:  7.2\",\"no_insurance:  7.4\",\"no_insurance:  7.4\",\"no_insurance:  7.6\",\"no_insurance:  7.6\",\"no_insurance:  7.6\",\"no_insurance:  7.8\",\"no_insurance:  7.8\",\"no_insurance:  7.9\",\"no_insurance:  7.9\",\"no_insurance:  8.1\",\"no_insurance:  8.1\",\"no_insurance:  8.2\",\"no_insurance:  8.2\",\"no_insurance:  8.2\",\"no_insurance:  8.2\",\"no_insurance:  8.3\",\"no_insurance:  8.3\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.4\",\"no_insurance:  8.5\",\"no_insurance:  8.5\",\"no_insurance:  8.5\",\"no_insurance:  8.6\",\"no_insurance:  8.6\",\"no_insurance:  8.7\",\"no_insurance:  8.7\",\"no_insurance:  8.7\",\"no_insurance:  8.7\",\"no_insurance:  8.8\",\"no_insurance:  8.8\",\"no_insurance:  8.8\",\"no_insurance:  8.8\",\"no_insurance:  8.8\",\"no_insurance:  8.9\",\"no_insurance:  8.9\",\"no_insurance:  9.1\",\"no_insurance:  9.4\",\"no_insurance:  9.4\",\"no_insurance:  9.8\",\"no_insurance:  9.8\",\"no_insurance: 10.0\",\"no_insurance: 10.0\",\"no_insurance: 10.1\",\"no_insurance: 10.1\",\"no_insurance: 10.1\",\"no_insurance: 10.2\",\"no_insurance: 10.2\",\"no_insurance: 10.2\",\"no_insurance: 10.2\",\"no_insurance: 10.3\",\"no_insurance: 10.3\",\"no_insurance: 10.5\",\"no_insurance: 10.5\",\"no_insurance: 10.6\",\"no_insurance: 10.6\",\"no_insurance: 10.7\",\"no_insurance: 10.7\",\"no_insurance: 10.8\",\"no_insurance: 10.8\",\"no_insurance: 10.8\",\"no_insurance: 10.9\",\"no_insurance: 10.9\",\"no_insurance: 10.9\",\"no_insurance: 10.9\",\"no_insurance: 11.0\",\"no_insurance: 11.1\",\"no_insurance: 11.1\",\"no_insurance: 11.1\",\"no_insurance: 11.2\",\"no_insurance: 11.2\",\"no_insurance: 11.2\",\"no_insurance: 11.2\",\"no_insurance: 11.2\",\"no_insurance: 11.3\",\"no_insurance: 11.4\",\"no_insurance: 11.4\",\"no_insurance: 11.4\",\"no_insurance: 11.4\",\"no_insurance: 11.4\",\"no_insurance: 11.4\",\"no_insurance: 11.5\",\"no_insurance: 11.5\",\"no_insurance: 11.6\",\"no_insurance: 11.6\",\"no_insurance: 11.6\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.7\",\"no_insurance: 11.8\",\"no_insurance: 11.8\",\"no_insurance: 11.8\",\"no_insurance: 11.9\",\"no_insurance: 11.9\",\"no_insurance: 11.9\",\"no_insurance: 11.9\",\"no_insurance: 12.0\",\"no_insurance: 12.0\",\"no_insurance: 12.0\",\"no_insurance: 12.1\",\"no_insurance: 12.1\",\"no_insurance: 12.1\",\"no_insurance: 12.1\",\"no_insurance: 12.2\",\"no_insurance: 12.2\",\"no_insurance: 12.3\",\"no_insurance: 12.3\",\"no_insurance: 12.4\",\"no_insurance: 12.4\",\"no_insurance: 12.4\",\"no_insurance: 12.4\",\"no_insurance: 12.5\",\"no_insurance: 12.5\",\"no_insurance: 12.6\",\"no_insurance: 12.6\",\"no_insurance: 12.7\",\"no_insurance: 12.7\",\"no_insurance: 12.7\",\"no_insurance: 12.8\",\"no_insurance: 12.8\",\"no_insurance: 12.9\",\"no_insurance: 13.0\",\"no_insurance: 13.0\",\"no_insurance: 13.0\",\"no_insurance: 13.0\",\"no_insurance: 13.1\",\"no_insurance: 13.2\",\"no_insurance: 13.4\",\"no_insurance: 13.5\",\"no_insurance: 13.5\",\"no_insurance: 13.5\",\"no_insurance: 13.6\",\"no_insurance: 13.6\",\"no_insurance: 13.7\",\"no_insurance: 13.7\",\"no_insurance: 13.8\",\"no_insurance: 13.8\",\"no_insurance: 13.8\",\"no_insurance: 13.8\",\"no_insurance: 13.8\",\"no_insurance: 13.9\",\"no_insurance: 14.0\",\"no_insurance: 14.0\",\"no_insurance: 14.1\",\"no_insurance: 14.2\",\"no_insurance: 14.4\",\"no_insurance: 14.5\",\"no_insurance: 14.5\",\"no_insurance: 14.5\",\"no_insurance: 14.6\",\"no_insurance: 14.7\",\"no_insurance: 14.7\",\"no_insurance: 14.7\",\"no_insurance: 14.7\",\"no_insurance: 14.8\",\"no_insurance: 14.8\",\"no_insurance: 14.9\",\"no_insurance: 14.9\",\"no_insurance: 15.0\",\"no_insurance: 15.0\",\"no_insurance: 15.0\",\"no_insurance: 15.2\",\"no_insurance: 15.3\",\"no_insurance: 15.3\",\"no_insurance: 15.3\",\"no_insurance: 15.3\",\"no_insurance: 15.4\",\"no_insurance: 15.5\",\"no_insurance: 15.7\",\"no_insurance: 15.8\",\"no_insurance: 15.8\",\"no_insurance: 15.9\",\"no_insurance: 15.9\",\"no_insurance: 15.9\",\"no_insurance: 15.9\",\"no_insurance: 16.0\",\"no_insurance: 16.0\",\"no_insurance: 16.1\",\"no_insurance: 16.1\",\"no_insurance: 16.1\",\"no_insurance: 16.2\",\"no_insurance: 16.3\",\"no_insurance: 16.4\",\"no_insurance: 16.4\",\"no_insurance: 16.4\",\"no_insurance: 16.5\",\"no_insurance: 16.5\",\"no_insurance: 16.6\",\"no_insurance: 16.9\",\"no_insurance: 16.9\",\"no_insurance: 17.0\",\"no_insurance: 17.4\",\"no_insurance: 17.8\",\"no_insurance: 17.8\",\"no_insurance: 18.0\",\"no_insurance: 18.1\",\"no_insurance: 18.1\",\"no_insurance: 18.2\",\"no_insurance: 18.2\",\"no_insurance: 18.2\",\"no_insurance: 18.2\",\"no_insurance: 18.3\",\"no_insurance: 18.4\",\"no_insurance: 18.4\",\"no_insurance: 18.5\",\"no_insurance: 18.5\",\"no_insurance: 18.6\",\"no_insurance: 18.8\",\"no_insurance: 18.9\",\"no_insurance: 18.9\",\"no_insurance: 19.1\",\"no_insurance: 19.1\",\"no_insurance: 19.2\",\"no_insurance: 19.3\",\"no_insurance: 19.5\",\"no_insurance: 19.5\",\"no_insurance: 19.7\",\"no_insurance: 19.7\",\"no_insurance: 19.9\",\"no_insurance: 20.1\",\"no_insurance: 20.3\",\"no_insurance: 20.7\",\"no_insurance: 20.8\",\"no_insurance: 21.0\",\"no_insurance: 21.0\",\"no_insurance: 21.2\",\"no_insurance: 22.1\",\"no_insurance: 22.6\",\"no_insurance: 22.7\",\"no_insurance: 22.8\",\"no_insurance: 22.8\",\"no_insurance: 23.5\",\"no_insurance: 24.9\",\"no_insurance: 26.4\",\"no_insurance: 27.7\",\"no_insurance: 29.8\",\"no_insurance: 31.1\",\"no_insurance: 32.6\",\"no_insurance: 35.1\",\"no_insurance: 35.9\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"dash\"},\"hoveron\":\"points\",\"name\":\"(non-metro,1)\",\"legendgroup\":\"(non-metro,1)\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[5.0999999999999996,15.699999999999999,8.4000000000000004,3,16.800000000000001,14.699999999999999,12.1,13.9,10.800000000000001,7.2000000000000002,30.199999999999999,4.7999999999999998,10.699999999999999,4.7999999999999998,11.1,17.100000000000001,7.4000000000000004,6.7000000000000002,6.2999999999999998,11.699999999999999,7.7000000000000002,6.7999999999999998,9,18,10.1,13.800000000000001,6.9000000000000004,11.300000000000001,11.4,10.300000000000001,13.199999999999999,11.800000000000001,8.8000000000000007,16.600000000000001,11.1,12,14.199999999999999,14.6,5.9000000000000004,7.2999999999999998,7.0999999999999996,5.0999999999999996,7.5999999999999996,13.9,8,3.8999999999999999,18.300000000000001,21,7.7000000000000002,7.7999999999999998,6.9000000000000004,13,8.3000000000000007,16,13.800000000000001,9.6999999999999993,13.300000000000001,7.9000000000000004,17.5,14.6,9.5,10.300000000000001,9.5999999999999996,15.6,15.699999999999999,5.2000000000000002,8,8.5,5.5999999999999996,10.199999999999999,15.6,9.5,11.9,11.6,11,9,5.5999999999999996,11.9,12.300000000000001,11.699999999999999,9.0999999999999996,8.9000000000000004,14.1,11.5,7.5999999999999996,17.800000000000001,8.1999999999999993,10.9,13.199999999999999,16.399999999999999,14.5,18.399999999999999,8.4000000000000004,15.300000000000001,4.4000000000000004,14.5,8.5999999999999996,6.2000000000000002,3.5,13,10.199999999999999,16,9.5999999999999996,7.7000000000000002,4.2000000000000002,10.800000000000001,8.6999999999999993,11.5,13.6,16.300000000000001,4.4000000000000004,5.0999999999999996,17.600000000000001,9.9000000000000004,18.199999999999999,7.7999999999999998,13,10.800000000000001,17,10.4,9.5999999999999996,8.4000000000000004,5.2000000000000002,15.9,16.399999999999999,13.4,15.4,11.5,14.699999999999999,12.199999999999999,14.699999999999999,4.5999999999999996,8.5,5.2000000000000002,8.9000000000000004,20,3.5,6,15,19.5,16.800000000000001,9.1999999999999993,16.199999999999999,13.300000000000001,8.6999999999999993,5.2999999999999998,9.5999999999999996,6.9000000000000004,12.800000000000001,11.199999999999999,3.3999999999999999,8.9000000000000004,12.5,12.699999999999999,11.6,6.5999999999999996,14.199999999999999,11.699999999999999,16.199999999999999,10.5,11.5,17.199999999999999,8.5999999999999996,13.800000000000001,13.5,8.4000000000000004,9.3000000000000007,10.699999999999999,10.1,11.1,12.300000000000001,13.300000000000001,12.5,12.199999999999999,13.300000000000001,15.800000000000001,14.5,5.2999999999999998,4,12.1,14.1,16.899999999999999,9.0999999999999996,21.5,6.7000000000000002,9.3000000000000007,12.6,13.9,11.5,6.5,10.1,23.800000000000001,13.9,15.6,8.4000000000000004,8.4000000000000004,6.2000000000000002,8.5999999999999996,9.1999999999999993,20.399999999999999,12,8.8000000000000007,15.4,10.4,4.4000000000000004,15.199999999999999,5.2000000000000002,6.5999999999999996,8.8000000000000007,24.399999999999999,8.9000000000000004,15.6,5.7000000000000002,10.6,8.1999999999999993,9.0999999999999996,8.4000000000000004,9.3000000000000007,11.699999999999999,18.100000000000001,18.899999999999999,5.4000000000000004,11.699999999999999,19.199999999999999,8.4000000000000004,5.5999999999999996],\"y\":[47.439999999999998,9.1699999999999999,31.23,104.09,107.8,73.170000000000002,89.569999999999993,21.559999999999999,60.18,42.100000000000001,436,146.5,267.67000000000002,12.640000000000001,199.59999999999999,9.3599999999999994,47.299999999999997,11.41,109.03,35.140000000000001,28,58.600000000000001,3.7599999999999998,120.8,13.109999999999999,213.28999999999999,7.6900000000000004,75.25,254.5,35.82,124.76000000000001,146.5,167.43000000000001,296.38,7,57.780000000000001,84.439999999999998,48.799999999999997,35.18,18.59,49.119999999999997,23.620000000000001,23.23,194.38,100.45999999999999,114,23.940000000000001,7.25,25,56.710000000000001,178.09,2.6600000000000001,12.67,93.290000000000006,12,55.859999999999999,138.66999999999999,21.550000000000001,219.81999999999999,106.43000000000001,42.950000000000003,24.77,24.559999999999999,186.5,209.06999999999999,6.7400000000000002,113,17.109999999999999,8.8000000000000007,341.10000000000002,74,14.710000000000001,81.090000000000003,150.25,84.200000000000003,0,149.38,7.5,80.709999999999994,112.81999999999999,16.559999999999999,46.939999999999998,304.86000000000001,16.07,39.210000000000001,151,80,14.85,24.5,113,116.76000000000001,167.5,70.090000000000003,91.329999999999998,172.97,13.199999999999999,76.640000000000001,32.82,190.65000000000001,94.799999999999997,56.200000000000003,53.689999999999998,65.329999999999998,7.3499999999999996,25.359999999999999,61.890000000000001,238.06,30,54.219999999999999,244.56999999999999,25.710000000000001,32.189999999999998,192,51.619999999999997,286.62,97.5,21,63.5,229.40000000000001,24.5,8.2899999999999991,36.25,1.3799999999999999,7.9900000000000002,270.36000000000001,52.25,121.55,44,3.3199999999999998,20.5,14,25.75,8.4000000000000004,23.27,153.66999999999999,242.11000000000001,17.800000000000001,15.619999999999999,156.40000000000001,328.67000000000002,159,16.399999999999999,326.32999999999998,266.60000000000002,11.449999999999999,29.199999999999999,136.08000000000001,29.129999999999999,59.329999999999998,127.12,86.709999999999994,14.1,27.440000000000001,16.719999999999999,34.799999999999997,10.77,3.1600000000000001,191,23.5,166.80000000000001,14.67,108.25,22.75,14.5,29.440000000000001,63.640000000000001,12.789999999999999,27.829999999999998,31.260000000000002,35.880000000000003,78.5,35.670000000000002,270.75,13.199999999999999,10.119999999999999,218.86000000000001,386.70999999999998,74.379999999999995,108.81999999999999,184.81999999999999,14.23,113.33,14.199999999999999,176.59,20.25,47.170000000000002,85.379999999999995,366.70999999999998,162.19999999999999,35.25,72.049999999999997,33.469999999999999,12.779999999999999,12.24,72,46,65.530000000000001,44.939999999999998,151.88,184.80000000000001,4.2300000000000004,64.109999999999999,15.529999999999999,4.7300000000000004,21,127.62,12.890000000000001,58.880000000000003,133.44,226.25,14.960000000000001,20.75,148.25,10,77,14.609999999999999,21.289999999999999,162.19,12.5,111.33,343,39.840000000000003,24.710000000000001,204.25,3.9399999999999999,31],\"text\":[\"no_insurance:  5.1<br />dist_ssp:  47.44<br />wabasha county\",\"no_insurance: 15.7<br />dist_ssp:   9.17<br />santa fe county\",\"no_insurance:  8.4<br />dist_ssp:  31.23<br />cass county\",\"no_insurance:  3.0<br />dist_ssp: 104.09<br />berkshire county\",\"no_insurance: 16.8<br />dist_ssp: 107.80<br />webster county\",\"no_insurance: 14.7<br />dist_ssp:  73.17<br />darlington county\",\"no_insurance: 12.1<br />dist_ssp:  89.57<br />rogers county\",\"no_insurance: 13.9<br />dist_ssp:  21.56<br />mecklenburg county\",\"no_insurance: 10.8<br />dist_ssp:  60.18<br />lebanon county\",\"no_insurance:  7.2<br />dist_ssp:  42.10<br />york county\",\"no_insurance: 30.2<br />dist_ssp: 436.00<br />webb county\",\"no_insurance:  4.8<br />dist_ssp: 146.50<br />lincoln county\",\"no_insurance: 10.7<br />dist_ssp: 267.67<br />meade county\",\"no_insurance:  4.8<br />dist_ssp:  12.64<br />erie county\",\"no_insurance: 11.1<br />dist_ssp: 199.60<br />hale county\",\"no_insurance: 17.1<br />dist_ssp:   9.36<br />dekalb county\",\"no_insurance:  7.4<br />dist_ssp:  47.30<br />bay county\",\"no_insurance:  6.7<br />dist_ssp:  11.41<br />champaign county\",\"no_insurance:  6.3<br />dist_ssp: 109.03<br />polk county\",\"no_insurance: 11.7<br />dist_ssp:  35.14<br />dickson county\",\"no_insurance:  7.7<br />dist_ssp:  28.00<br />columbia county\",\"no_insurance:  6.8<br />dist_ssp:  58.60<br />allegany county\",\"no_insurance:  9.0<br />dist_ssp:   3.76<br />baltimore city\",\"no_insurance: 18.0<br />dist_ssp: 120.80<br />yuma county\",\"no_insurance: 10.1<br />dist_ssp:  13.11<br />sonoma county\",\"no_insurance: 13.8<br />dist_ssp: 213.29<br />liberty county\",\"no_insurance:  6.9<br />dist_ssp:   7.69<br />new castle county\",\"no_insurance: 11.3<br />dist_ssp:  75.25<br />harris county\",\"no_insurance: 11.4<br />dist_ssp: 254.50<br />carbon county\",\"no_insurance: 10.3<br />dist_ssp:  35.82<br />utah county\",\"no_insurance: 13.2<br />dist_ssp: 124.76<br />mobile county\",\"no_insurance: 11.8<br />dist_ssp: 146.50<br />baldwin county\",\"no_insurance:  8.8<br />dist_ssp: 167.43<br />harvey county\",\"no_insurance: 16.6<br />dist_ssp: 296.38<br />ellis county\",\"no_insurance: 11.1<br />dist_ssp:   7.00<br />washington county\",\"no_insurance: 12.0<br />dist_ssp:  57.78<br />christian county\",\"no_insurance: 14.2<br />dist_ssp:  84.44<br />jasper county\",\"no_insurance: 14.6<br />dist_ssp:  48.80<br />hamblen county\",\"no_insurance:  5.9<br />dist_ssp:  35.18<br />oconto county\",\"no_insurance:  7.3<br />dist_ssp:  18.59<br />clermont county\",\"no_insurance:  7.1<br />dist_ssp:  49.12<br />mille lacs county\",\"no_insurance:  5.1<br />dist_ssp:  23.62<br />scott county\",\"no_insurance:  7.6<br />dist_ssp:  23.23<br />fayette county\",\"no_insurance: 13.9<br />dist_ssp: 194.38<br />poinsett county\",\"no_insurance:  8.0<br />dist_ssp: 100.46<br />albemarle county\",\"no_insurance:  3.9<br />dist_ssp: 114.00<br />poquoson city\",\"no_insurance: 18.3<br />dist_ssp:  23.94<br />gwinnett county\",\"no_insurance: 21.0<br />dist_ssp:   7.25<br />wyandotte county\",\"no_insurance:  7.7<br />dist_ssp:  25.00<br />fayette county\",\"no_insurance:  7.8<br />dist_ssp:  56.71<br />daviess county\",\"no_insurance:  6.9<br />dist_ssp: 178.09<br />burleigh county\",\"no_insurance: 13.0<br />dist_ssp:   2.66<br />denver county\",\"no_insurance:  8.3<br />dist_ssp:  12.67<br />scott county\",\"no_insurance: 16.0<br />dist_ssp:  93.29<br />jackson county\",\"no_insurance: 13.8<br />dist_ssp:  12.00<br />carter county\",\"no_insurance:  9.7<br />dist_ssp:  55.86<br />campbell county\",\"no_insurance: 13.3<br />dist_ssp: 138.67<br />berkeley county\",\"no_insurance:  7.9<br />dist_ssp:  21.55<br />miami county\",\"no_insurance: 17.5<br />dist_ssp: 219.82<br />grayson county\",\"no_insurance: 14.6<br />dist_ssp: 106.43<br />norfolk city\",\"no_insurance:  9.5<br />dist_ssp:  42.95<br />franklin county\",\"no_insurance: 10.3<br />dist_ssp:  24.77<br />middlesex county\",\"no_insurance:  9.6<br />dist_ssp:  24.56<br />jefferson county\",\"no_insurance: 15.6<br />dist_ssp: 186.50<br />miller county\",\"no_insurance: 15.7<br />dist_ssp: 209.07<br />taylor county\",\"no_insurance:  5.2<br />dist_ssp:   6.74<br />monroe county\",\"no_insurance:  8.0<br />dist_ssp: 113.00<br />boone county\",\"no_insurance:  8.5<br />dist_ssp:  17.11<br />larimer county\",\"no_insurance:  5.6<br />dist_ssp:   8.80<br />outagamie county\",\"no_insurance: 10.2<br />dist_ssp: 341.10<br />coryell county\",\"no_insurance: 15.6<br />dist_ssp:  74.00<br />acadia parish\",\"no_insurance:  9.5<br />dist_ssp:  14.71<br />washington county\",\"no_insurance: 11.9<br />dist_ssp:  81.09<br />florence county\",\"no_insurance: 11.6<br />dist_ssp: 150.25<br />fairbanks north star borough\",\"no_insurance: 11.0<br />dist_ssp:  84.20<br />edgefield county\",\"no_insurance:  9.0<br />dist_ssp:   0.00<br />clark county\",\"no_insurance:  5.6<br />dist_ssp: 149.38<br />plymouth county\",\"no_insurance: 11.9<br />dist_ssp:   7.50<br />person county\",\"no_insurance: 12.3<br />dist_ssp:  80.71<br />kershaw county\",\"no_insurance: 11.7<br />dist_ssp: 112.82<br />faulkner county\",\"no_insurance:  9.1<br />dist_ssp:  16.56<br />clay county\",\"no_insurance:  8.9<br />dist_ssp:  46.94<br />lehigh county\",\"no_insurance: 14.1<br />dist_ssp: 304.86<br />brazos county\",\"no_insurance: 11.5<br />dist_ssp:  16.07<br />jackson county\",\"no_insurance:  7.6<br />dist_ssp:  39.21<br />suffolk county\",\"no_insurance: 17.8<br />dist_ssp: 151.00<br />newton county\",\"no_insurance:  8.2<br />dist_ssp:  80.00<br />king william county\",\"no_insurance: 10.9<br />dist_ssp:  14.85<br />wayne county\",\"no_insurance: 13.2<br />dist_ssp:  24.50<br />benton county\",\"no_insurance: 16.4<br />dist_ssp: 113.00<br />pulaski county\",\"no_insurance: 14.5<br />dist_ssp: 116.76<br />anchorage municipality\",\"no_insurance: 18.4<br />dist_ssp: 167.50<br />benton county\",\"no_insurance:  8.4<br />dist_ssp:  70.09<br />ulster county\",\"no_insurance: 15.3<br />dist_ssp:  91.33<br />walker county\",\"no_insurance:  4.4<br />dist_ssp: 172.97<br />suffolk county\",\"no_insurance: 14.5<br />dist_ssp:  13.20<br />caldwell county\",\"no_insurance:  8.6<br />dist_ssp:  76.64<br />sussex county\",\"no_insurance:  6.2<br />dist_ssp:  32.82<br />pierce county\",\"no_insurance:  3.5<br />dist_ssp: 190.65<br />essex county\",\"no_insurance: 13.0<br />dist_ssp:  94.80<br />greene county\",\"no_insurance: 10.2<br />dist_ssp:  56.20<br />spotsylvania county\",\"no_insurance: 16.0<br />dist_ssp:  53.69<br />palm beach county\",\"no_insurance:  9.6<br />dist_ssp:  65.33<br />pulaski county\",\"no_insurance:  7.7<br />dist_ssp:   7.35<br />kitsap county\",\"no_insurance:  4.2<br />dist_ssp:  25.36<br />wright county\",\"no_insurance: 10.8<br />dist_ssp:  61.89<br />polk county\",\"no_insurance:  8.7<br />dist_ssp: 238.06<br />york county\",\"no_insurance: 11.5<br />dist_ssp:  30.00<br />scott county\",\"no_insurance: 13.6<br />dist_ssp:  54.22<br />giles county\",\"no_insurance: 16.3<br />dist_ssp: 244.57<br />glynn county\",\"no_insurance:  4.4<br />dist_ssp:  25.71<br />charles county\",\"no_insurance:  5.1<br />dist_ssp:  32.19<br />butler county\",\"no_insurance: 17.6<br />dist_ssp: 192.00<br />hardin county\",\"no_insurance:  9.9<br />dist_ssp:  51.62<br />knox county\",\"no_insurance: 18.2<br />dist_ssp: 286.62<br />tarrant county\",\"no_insurance:  7.8<br />dist_ssp:  97.50<br />worcester county\",\"no_insurance: 13.0<br />dist_ssp:  21.00<br />davie county\",\"no_insurance: 10.8<br />dist_ssp:  63.50<br />pend oreille county\",\"no_insurance: 17.0<br />dist_ssp: 229.40<br />upshur county\",\"no_insurance: 10.4<br />dist_ssp:  24.50<br />benton county\",\"no_insurance:  9.6<br />dist_ssp:   8.29<br />greenup county\",\"no_insurance:  8.4<br />dist_ssp:  36.25<br />hardin county\",\"no_insurance:  5.2<br />dist_ssp:   1.38<br />district of columbia\",\"no_insurance: 15.9<br />dist_ssp:   7.99<br />los angeles county\",\"no_insurance: 16.4<br />dist_ssp: 270.36<br />wichita county\",\"no_insurance: 13.4<br />dist_ssp:  52.25<br />morgan county\",\"no_insurance: 15.4<br />dist_ssp: 121.55<br />washington county\",\"no_insurance: 11.5<br />dist_ssp:  44.00<br />macon county\",\"no_insurance: 14.7<br />dist_ssp:   3.32<br />st. louis city\",\"no_insurance: 12.2<br />dist_ssp:  20.50<br />iberville parish\",\"no_insurance: 14.7<br />dist_ssp:  14.00<br />hoke county\",\"no_insurance:  4.6<br />dist_ssp:  25.75<br />harford county\",\"no_insurance:  8.5<br />dist_ssp:   8.40<br />contra costa county\",\"no_insurance:  5.2<br />dist_ssp:  23.27<br />williamson county\",\"no_insurance:  8.9<br />dist_ssp: 153.67<br />autauga county\",\"no_insurance: 20.0<br />dist_ssp: 242.11<br />gregg county\",\"no_insurance:  3.5<br />dist_ssp:  17.80<br />nicollet county\",\"no_insurance:  6.0<br />dist_ssp:  15.62<br />hamilton county\",\"no_insurance: 15.0<br />dist_ssp: 156.40<br />lincoln county\",\"no_insurance: 19.5<br />dist_ssp: 328.67<br />somervell county\",\"no_insurance: 16.8<br />dist_ssp: 159.00<br />yazoo county\",\"no_insurance:  9.2<br />dist_ssp:  16.40<br />solano county\",\"no_insurance: 16.2<br />dist_ssp: 326.33<br />lampasas county\",\"no_insurance: 13.3<br />dist_ssp: 266.60<br />nassau county\",\"no_insurance:  8.7<br />dist_ssp:  11.45<br />kenosha county\",\"no_insurance:  5.3<br />dist_ssp:  29.20<br />madison county\",\"no_insurance:  9.6<br />dist_ssp: 136.08<br />providence county\",\"no_insurance:  6.9<br />dist_ssp:  29.13<br />lorain county\",\"no_insurance: 12.8<br />dist_ssp:  59.33<br />monroe county\",\"no_insurance: 11.2<br />dist_ssp: 127.12<br />blount county\",\"no_insurance:  3.4<br />dist_ssp:  86.71<br />bremer county\",\"no_insurance:  8.9<br />dist_ssp:  14.10<br />salem county\",\"no_insurance: 12.5<br />dist_ssp:  27.44<br />prince william county\",\"no_insurance: 12.7<br />dist_ssp:  16.72<br />mesa county\",\"no_insurance: 11.6<br />dist_ssp:  34.80<br />st. tammany parish\",\"no_insurance:  6.6<br />dist_ssp:  10.77<br />richmond county\",\"no_insurance: 14.2<br />dist_ssp:   3.16<br />orleans parish\",\"no_insurance: 11.7<br />dist_ssp: 191.00<br />effingham county\",\"no_insurance: 16.2<br />dist_ssp:  23.50<br />jones county\",\"no_insurance: 10.5<br />dist_ssp: 166.80<br />jefferson county\",\"no_insurance: 11.5<br />dist_ssp:  14.67<br />alexander county\",\"no_insurance: 17.2<br />dist_ssp: 108.25<br />okmulgee county\",\"no_insurance:  8.6<br />dist_ssp:  22.75<br />washington county\",\"no_insurance: 13.8<br />dist_ssp:  14.50<br />burke county\",\"no_insurance: 13.5<br />dist_ssp:  29.44<br />livingston parish\",\"no_insurance:  8.4<br />dist_ssp:  63.64<br />pike county\",\"no_insurance:  9.3<br />dist_ssp:  12.79<br />snohomish county\",\"no_insurance: 10.7<br />dist_ssp:  27.83<br />butte county\",\"no_insurance: 10.1<br />dist_ssp:  31.26<br />fairfield county\",\"no_insurance: 11.1<br />dist_ssp:  35.88<br />union county\",\"no_insurance: 12.3<br />dist_ssp:  78.50<br />nez perce county\",\"no_insurance: 13.3<br />dist_ssp:  35.67<br />kootenai county\",\"no_insurance: 12.5<br />dist_ssp: 270.75<br />baker county\",\"no_insurance: 12.2<br />dist_ssp:  13.20<br />valencia county\",\"no_insurance: 13.3<br />dist_ssp:  10.12<br />jackson county\",\"no_insurance: 15.8<br />dist_ssp: 218.86<br />gadsden county\",\"no_insurance: 14.5<br />dist_ssp: 386.71<br />guadalupe county\",\"no_insurance:  5.3<br />dist_ssp:  74.38<br />marshall county\",\"no_insurance:  4.0<br />dist_ssp: 108.82<br />warren county\",\"no_insurance: 12.1<br />dist_ssp: 184.82<br />houston county\",\"no_insurance: 14.1<br />dist_ssp:  14.23<br />rowan county\",\"no_insurance: 16.9<br />dist_ssp: 113.33<br />lee county\",\"no_insurance:  9.1<br />dist_ssp:  14.20<br />cowlitz county\",\"no_insurance: 21.5<br />dist_ssp: 176.59<br />jefferson county\",\"no_insurance:  6.7<br />dist_ssp:  20.25<br />lake county\",\"no_insurance:  9.3<br />dist_ssp:  47.17<br />fillmore county\",\"no_insurance: 12.6<br />dist_ssp:  85.38<br />randall county\",\"no_insurance: 13.9<br />dist_ssp: 366.71<br />comal county\",\"no_insurance: 11.5<br />dist_ssp: 162.20<br />henry county\",\"no_insurance:  6.5<br />dist_ssp:  35.25<br />putnam county\",\"no_insurance: 10.1<br />dist_ssp:  72.05<br />cochise county\",\"no_insurance: 23.8<br />dist_ssp:  33.47<br />el paso county\",\"no_insurance: 13.9<br />dist_ssp:  12.78<br />durham county\",\"no_insurance: 15.6<br />dist_ssp:  12.24<br />adams county\",\"no_insurance:  8.4<br />dist_ssp:  72.00<br />bedford county\",\"no_insurance:  8.4<br />dist_ssp:  46.00<br />winnebago county\",\"no_insurance:  6.2<br />dist_ssp:  65.53<br />polk county\",\"no_insurance:  8.6<br />dist_ssp:  44.94<br />fauquier county\",\"no_insurance:  9.2<br />dist_ssp: 151.88<br />butler county\",\"no_insurance: 20.4<br />dist_ssp: 184.80<br />jasper county\",\"no_insurance: 12.0<br />dist_ssp:   4.23<br />philadelphia county\",\"no_insurance:  8.8<br />dist_ssp:  64.11<br />berkeley county\",\"no_insurance: 15.4<br />dist_ssp:  15.53<br />cobb county\",\"no_insurance: 10.4<br />dist_ssp:   4.73<br />multnomah county\",\"no_insurance:  4.4<br />dist_ssp:  21.00<br />kewaunee county\",\"no_insurance: 15.2<br />dist_ssp: 127.62<br />highlands county\",\"no_insurance:  5.2<br />dist_ssp:  12.89<br />dakota county\",\"no_insurance:  6.6<br />dist_ssp:  58.88<br />dutchess county\",\"no_insurance:  8.8<br />dist_ssp: 133.44<br />elmore county\",\"no_insurance: 24.4<br />dist_ssp: 226.25<br />brantley county\",\"no_insurance:  8.9<br />dist_ssp:  14.96<br />westchester county\",\"no_insurance: 15.6<br />dist_ssp:  20.75<br />douglas county\",\"no_insurance:  5.7<br />dist_ssp: 148.25<br />mills county\",\"no_insurance: 10.6<br />dist_ssp:  10.00<br />west baton rouge parish\",\"no_insurance:  8.2<br />dist_ssp:  77.00<br />henderson county\",\"no_insurance:  9.1<br />dist_ssp:  14.61<br />montgomery county\",\"no_insurance:  8.4<br />dist_ssp:  21.29<br />madison county\",\"no_insurance:  9.3<br />dist_ssp: 162.19<br />lancaster county\",\"no_insurance: 11.7<br />dist_ssp:  12.50<br />brown county\",\"no_insurance: 18.1<br />dist_ssp: 111.33<br />perry county\",\"no_insurance: 18.9<br />dist_ssp: 343.00<br />falls county\",\"no_insurance:  5.4<br />dist_ssp:  39.84<br />st. louis county\",\"no_insurance: 11.7<br />dist_ssp:  24.71<br />madison county\",\"no_insurance: 19.2<br />dist_ssp: 204.25<br />brooks county\",\"no_insurance:  8.4<br />dist_ssp:   3.94<br />alameda county\",\"no_insurance:  5.6<br />dist_ssp:  31.00<br />chisago county\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(230,159,0,0.4)\",\"opacity\":1,\"size\":7.559055118110237,\"symbol\":\"circle\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(230,159,0,0.4)\"}},\"hoveron\":\"points\",\"name\":\"(metro,1)\",\"legendgroup\":\"(metro,1)\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[18.5,15.9,12.4,18.600000000000001,14.800000000000001,11.199999999999999,6.7999999999999998,5.9000000000000004,18.399999999999999,11.699999999999999,12.699999999999999,16.399999999999999,14.4,11.199999999999999,18.199999999999999,12,8.5,12.199999999999999,19.699999999999999,11.6,16.199999999999999,8.8000000000000007,10.800000000000001,35.100000000000001,14.199999999999999,16.899999999999999,14.699999999999999,20.100000000000001,10.6,12.5,29.800000000000001,4.0999999999999996,16.300000000000001,16.100000000000001,8.3000000000000007,9.0999999999999996,5.2000000000000002,6,14.699999999999999,13.800000000000001,4,11.699999999999999,11.800000000000001,9.4000000000000004,4.7999999999999998,22.800000000000001,12.1,5.5,7.5999999999999996,10.9,14,18.300000000000001,12.1,15.9,13.699999999999999,10,6,11.9,35.899999999999999,16.399999999999999,13,6.2000000000000002,7.4000000000000004,11.199999999999999,8.6999999999999993,15.300000000000001,8.6999999999999993,18.899999999999999,10.9,21.199999999999999,11.4,8.5,10.199999999999999,7.9000000000000004,6.5,8.1999999999999993,6.9000000000000004,16,9.4000000000000004,6.2000000000000002,8.4000000000000004,26.399999999999999,18.199999999999999,11.9,5.9000000000000004,10,15,8.5999999999999996,13.800000000000001,14.5,6.2000000000000002,17,16.100000000000001,19.699999999999999,4.7000000000000002,13.800000000000001,11.300000000000001,6.0999999999999996,12.4,11.800000000000001,8.6999999999999993,7,15.300000000000001,15.300000000000001,12.1,16.100000000000001,7.4000000000000004,6.5999999999999996,14.5,18.899999999999999,19.100000000000001,19.5,11.9,8.1999999999999993,13.6,11.4,10.9,10.300000000000001,16,5.2999999999999998,7.2000000000000002,8.4000000000000004,10.1,15.5,11.5,10.800000000000001,18.399999999999999,15,10.199999999999999,6.2000000000000002,13.5,11.699999999999999,7.9000000000000004,15.4,10.800000000000001,11.6,15.9,14.800000000000001,9.8000000000000007,16.899999999999999,12.800000000000001,7.5999999999999996,5.7000000000000002,3.2999999999999998,11.4,21,12,22.800000000000001,10.5,22.100000000000001,18.800000000000001,13.800000000000001,12.300000000000001,12.9,17.800000000000001,7.5999999999999996,15.9,8.1999999999999993,9.8000000000000007,12.699999999999999,6.2000000000000002,8.5,16.600000000000001,19.199999999999999,8.6999999999999993,18.5,18.100000000000001,15.699999999999999,13,10.699999999999999,8.3000000000000007,13.5,18,13,11.199999999999999,19.899999999999999,13.699999999999999,11.1,11.1,10.6,19.300000000000001,12,13.9,22.699999999999999,24.899999999999999,6.2000000000000002,19.100000000000001,18.199999999999999,11.4,22.600000000000001,10.1,14.1,5.5,8.9000000000000004,11.6,10.699999999999999,12.4,15.199999999999999,8.8000000000000007,11.699999999999999,12.1,6.9000000000000004,13.4,19.5,11.4,12.199999999999999,14.6,14,6,18.199999999999999,14.699999999999999,11.1,11.9,8.0999999999999996,8.5999999999999996,21,12.4,23.5,11.699999999999999,18.100000000000001,14.699999999999999,13.800000000000001,10.1,12.300000000000001,12.699999999999999,11.4,15.800000000000001,32.600000000000001,20.800000000000001,15,7.7999999999999998,12.5,16.5,13.199999999999999,13.1,16.399999999999999,8.8000000000000007,8.4000000000000004,12.6,6.9000000000000004,8.9000000000000004,10.5,31.100000000000001,10.199999999999999,12.6,13,8.8000000000000007,20.300000000000001,10.300000000000001,8.8000000000000007,8.0999999999999996,20.699999999999999,14.9,14.9,15.800000000000001,15.300000000000001,17.800000000000001,11.199999999999999,11,11.800000000000001,7.7999999999999998,13.5,16.5,10.9,12.800000000000001,14.5,8.1999999999999993,27.699999999999999,5.2999999999999998,10.199999999999999,8.4000000000000004,13.6,17.399999999999999,11.5],\"y\":[125,77.200000000000003,42.140000000000001,49.219999999999999,141,81.5,68.439999999999998,39.880000000000003,185,21.5,163.15000000000001,214.33000000000001,29.859999999999999,39.5,313,109.38,21,22.43,155.75,126.89,77.379999999999995,300,71.709999999999994,510,28,197.88,173.83000000000001,205.5,40.5,41.619999999999997,84.329999999999998,210,169.5,44.450000000000003,116.33,73.829999999999998,165.88,67.590000000000003,64,43,46,71.620000000000005,162.59999999999999,66.25,149.12,247.75,91.170000000000002,50.5,95.480000000000004,55.140000000000001,30.710000000000001,44.5,18.559999999999999,160.19999999999999,88.5,43.170000000000002,172.75,95.569999999999993,170.66999999999999,120.59999999999999,150,155.78,37.75,85.25,50.93,42.329999999999998,145.40000000000001,235.5,40.880000000000003,116.33,169.75,88,28.870000000000001,63.090000000000003,58.060000000000002,51.469999999999999,95,40.710000000000001,223.66999999999999,29.5,69,71.329999999999998,214,25.670000000000002,21.399999999999999,48.880000000000003,77.170000000000002,245.28999999999999,19.5,80,58.329999999999998,108,186.12,325.80000000000001,88.299999999999997,186.63999999999999,37.43,202.28999999999999,53.859999999999999,244.62,71.5,23.210000000000001,68.329999999999998,209.5,35.810000000000002,229.88999999999999,116,197.66999999999999,75.140000000000001,295.5,41.600000000000001,155,102.12,25.550000000000001,41.859999999999999,58.829999999999998,266.19999999999999,104.86,96.530000000000001,59.670000000000002,99.25,44.799999999999997,36.25,227,23,202.77000000000001,30.670000000000002,173.12,177.83000000000001,55.170000000000002,31.399999999999999,107.56999999999999,262,115.78,123.67,146.19999999999999,55.329999999999998,388.5,21,70.5,122.38,60.850000000000001,38.549999999999997,151.81999999999999,71,456,175.25,291,28.620000000000001,168.5,206.75,119.59999999999999,54,37.600000000000001,318,72.069999999999993,180.5,72.170000000000002,177.5,159.5,128.75,315.54000000000002,181.5,188.66999999999999,182.12,193.5,53.399999999999999,82.5,90.170000000000002,95.400000000000006,29.780000000000001,93.299999999999997,103,47.270000000000003,35.590000000000003,141,210,130.5,32.670000000000002,253.12,200.19999999999999,265,62,150,106.33,81.180000000000007,199.19999999999999,289.62,302.92000000000002,386.5,57.780000000000001,113.2,44,271.67000000000002,68.829999999999998,46.109999999999999,72,204.33000000000001,46.5,205.5,28.859999999999999,15,73.75,124.75,38.829999999999998,51.200000000000003,339.39999999999998,38.329999999999998,58.950000000000003,168.5,148,81,343.94,22.620000000000001,116.29000000000001,54,120.56,487,221,30.289999999999999,197.5,212.75,51.329999999999998,226.71000000000001,32.600000000000001,11,342,49.670000000000002,77,213.75,27.199999999999999,71.329999999999998,138.75,173.22,79.670000000000002,212,35.079999999999998,177.16999999999999,267.25,29.559999999999999,155.28999999999999,38.5,330,21.329999999999998,6,127.25,196.80000000000001,83.170000000000002,90.5,224.43000000000001,102.40000000000001,339,188.13999999999999,131.40000000000001,55.789999999999999,99.75,180.40000000000001,99.230000000000004,237.33000000000001,54.25,197.56999999999999,159.5,216.43000000000001,147,43.170000000000002,39.140000000000001,47.770000000000003,460.60000000000002,224.28999999999999,158.44,88.670000000000002,73,313.5,190],\"text\":[\"no_insurance: 18.5<br />dist_ssp: 125.00<br />johnson county\",\"no_insurance: 15.9<br />dist_ssp:  77.20<br />iron county\",\"no_insurance: 12.4<br />dist_ssp:  42.14<br />kosciusko county\",\"no_insurance: 18.6<br />dist_ssp:  49.22<br />delaware county\",\"no_insurance: 14.8<br />dist_ssp: 141.00<br />scurry county\",\"no_insurance: 11.2<br />dist_ssp:  81.50<br />jefferson county\",\"no_insurance:  6.8<br />dist_ssp:  68.44<br />lee county\",\"no_insurance:  5.9<br />dist_ssp:  39.88<br />montgomery county\",\"no_insurance: 18.4<br />dist_ssp: 185.00<br />pontotoc county\",\"no_insurance: 11.7<br />dist_ssp:  21.50<br />granville county\",\"no_insurance: 12.7<br />dist_ssp: 163.15<br />lawrence county\",\"no_insurance: 16.4<br />dist_ssp: 214.33<br />greer county\",\"no_insurance: 14.4<br />dist_ssp:  29.86<br />hart county\",\"no_insurance: 11.2<br />dist_ssp:  39.50<br />decatur county\",\"no_insurance: 18.2<br />dist_ssp: 313.00<br />gillespie county\",\"no_insurance: 12.0<br />dist_ssp: 109.38<br />buena vista county\",\"no_insurance:  8.5<br />dist_ssp:  21.00<br />lenawee county\",\"no_insurance: 12.2<br />dist_ssp:  22.43<br />clinton county\",\"no_insurance: 19.7<br />dist_ssp: 155.75<br />calhoun county\",\"no_insurance: 11.6<br />dist_ssp: 126.89<br />vernon parish\",\"no_insurance: 16.2<br />dist_ssp:  77.38<br />lawrence county\",\"no_insurance:  8.8<br />dist_ssp: 300.00<br />garfield county\",\"no_insurance: 10.8<br />dist_ssp:  71.71<br />hardy county\",\"no_insurance: 35.1<br />dist_ssp: 510.00<br />starr county\",\"no_insurance: 14.2<br />dist_ssp:  28.00<br />switzerland county\",\"no_insurance: 16.9<br />dist_ssp: 197.88<br />thomas county\",\"no_insurance: 14.7<br />dist_ssp: 173.83<br />bulloch county\",\"no_insurance: 20.1<br />dist_ssp: 205.50<br />wayne county\",\"no_insurance: 10.6<br />dist_ssp:  40.50<br />logan county\",\"no_insurance: 12.5<br />dist_ssp:  41.62<br />henry county\",\"no_insurance: 29.8<br />dist_ssp:  84.33<br />hendry county\",\"no_insurance:  4.1<br />dist_ssp: 210.00<br />scott county\",\"no_insurance: 16.3<br />dist_ssp: 169.50<br />woodruff county\",\"no_insurance: 16.1<br />dist_ssp:  44.45<br />ashe county\",\"no_insurance:  8.3<br />dist_ssp: 116.33<br />page county\",\"no_insurance:  9.1<br />dist_ssp:  73.83<br />mccormick county\",\"no_insurance:  5.2<br />dist_ssp: 165.88<br />addison county\",\"no_insurance:  6.0<br />dist_ssp:  67.59<br />litchfield county\",\"no_insurance: 14.7<br />dist_ssp:  64.00<br />lewis county\",\"no_insurance: 13.8<br />dist_ssp:  43.00<br />assumption parish\",\"no_insurance:  4.0<br />dist_ssp:  46.00<br />putnam county\",\"no_insurance: 11.7<br />dist_ssp:  71.62<br />pope county\",\"no_insurance: 11.8<br />dist_ssp: 162.60<br />greene county\",\"no_insurance:  9.4<br />dist_ssp:  66.25<br />morgan county\",\"no_insurance:  4.8<br />dist_ssp: 149.12<br />bennington county\",\"no_insurance: 22.8<br />dist_ssp: 247.75<br />val verde county\",\"no_insurance: 12.1<br />dist_ssp:  91.17<br />wayne county\",\"no_insurance:  5.5<br />dist_ssp:  50.50<br />auglaize county\",\"no_insurance:  7.6<br />dist_ssp:  95.48<br />huntingdon county\",\"no_insurance: 10.9<br />dist_ssp:  55.14<br />union county\",\"no_insurance: 14.0<br />dist_ssp:  30.71<br />otero county\",\"no_insurance: 18.3<br />dist_ssp:  44.50<br />sevier county\",\"no_insurance: 12.1<br />dist_ssp:  18.56<br />lawrence county\",\"no_insurance: 15.9<br />dist_ssp: 160.20<br />morehouse parish\",\"no_insurance: 13.7<br />dist_ssp:  88.50<br />pitkin county\",\"no_insurance: 10.0<br />dist_ssp:  43.17<br />curry county\",\"no_insurance:  6.0<br />dist_ssp: 172.75<br />mcpherson county\",\"no_insurance: 11.9<br />dist_ssp:  95.57<br />jefferson davis parish\",\"no_insurance: 35.9<br />dist_ssp: 170.67<br />presidio county\",\"no_insurance: 16.4<br />dist_ssp: 120.60<br />camden county\",\"no_insurance: 13.0<br />dist_ssp: 150.00<br />lake county\",\"no_insurance:  6.2<br />dist_ssp: 155.78<br />windham county\",\"no_insurance:  7.4<br />dist_ssp:  37.75<br />edgar county\",\"no_insurance: 11.2<br />dist_ssp:  85.25<br />decatur county\",\"no_insurance:  8.7<br />dist_ssp:  50.93<br />tuolumne county\",\"no_insurance: 15.3<br />dist_ssp:  42.33<br />washington county\",\"no_insurance:  8.7<br />dist_ssp: 145.40<br />franklin county\",\"no_insurance: 18.9<br />dist_ssp: 235.50<br />rains county\",\"no_insurance: 10.9<br />dist_ssp:  40.88<br />knox county\",\"no_insurance: 21.2<br />dist_ssp: 116.33<br />caldwell parish\",\"no_insurance: 11.4<br />dist_ssp: 169.75<br />cowley county\",\"no_insurance:  8.5<br />dist_ssp:  88.00<br />clearfield county\",\"no_insurance: 10.2<br />dist_ssp:  28.87<br />susquehanna county\",\"no_insurance:  7.9<br />dist_ssp:  63.09<br />buchanan county\",\"no_insurance:  6.5<br />dist_ssp:  58.06<br />dorchester county\",\"no_insurance:  8.2<br />dist_ssp:  51.47<br />somerset county\",\"no_insurance:  6.9<br />dist_ssp:  95.00<br />richardson county\",\"no_insurance: 16.0<br />dist_ssp:  40.71<br />delta county\",\"no_insurance:  9.4<br />dist_ssp: 223.67<br />montgomery county\",\"no_insurance:  6.2<br />dist_ssp:  29.50<br />jefferson county\",\"no_insurance:  8.4<br />dist_ssp:  69.00<br />ashland county\",\"no_insurance: 26.4<br />dist_ssp:  71.33<br />concordia parish\",\"no_insurance: 18.2<br />dist_ssp: 214.00<br />sumter county\",\"no_insurance: 11.9<br />dist_ssp:  25.67<br />carroll county\",\"no_insurance:  5.9<br />dist_ssp:  21.40<br />cortland county\",\"no_insurance: 10.0<br />dist_ssp:  48.88<br />miami county\",\"no_insurance: 15.0<br />dist_ssp:  77.17<br />lyon county\",\"no_insurance:  8.6<br />dist_ssp: 245.29<br />antelope county\",\"no_insurance: 13.8<br />dist_ssp:  19.50<br />yancey county\",\"no_insurance: 14.5<br />dist_ssp:  80.00<br />louisa county\",\"no_insurance:  6.2<br />dist_ssp:  58.33<br />cumberland county\",\"no_insurance: 17.0<br />dist_ssp: 108.00<br />douglas county\",\"no_insurance: 16.1<br />dist_ssp: 186.12<br />tyler county\",\"no_insurance: 19.7<br />dist_ssp: 325.80<br />hill county\",\"no_insurance:  4.7<br />dist_ssp:  88.30<br />douglas county\",\"no_insurance: 13.8<br />dist_ssp: 186.64<br />mississippi county\",\"no_insurance: 11.3<br />dist_ssp:  37.43<br />highland county\",\"no_insurance:  6.1<br />dist_ssp: 202.29<br />orange county\",\"no_insurance: 12.4<br />dist_ssp:  53.86<br />putnam county\",\"no_insurance: 11.8<br />dist_ssp: 244.62<br />blaine county\",\"no_insurance:  8.7<br />dist_ssp:  71.50<br />lawrence county\",\"no_insurance:  7.0<br />dist_ssp:  23.21<br />ottawa county\",\"no_insurance: 15.3<br />dist_ssp:  68.33<br />shoshone county\",\"no_insurance: 15.3<br />dist_ssp: 209.50<br />clay county\",\"no_insurance: 12.1<br />dist_ssp:  35.81<br />harlan county\",\"no_insurance: 16.1<br />dist_ssp: 229.89<br />coahoma county\",\"no_insurance:  7.4<br />dist_ssp: 116.00<br />rock county\",\"no_insurance:  6.6<br />dist_ssp: 197.67<br />mitchell county\",\"no_insurance: 14.5<br />dist_ssp:  75.14<br />pettis county\",\"no_insurance: 18.9<br />dist_ssp: 295.50<br />jack county\",\"no_insurance: 19.1<br />dist_ssp:  41.60<br />todd county\",\"no_insurance: 19.5<br />dist_ssp: 155.00<br />ben hill county\",\"no_insurance: 11.9<br />dist_ssp: 102.12<br />jackson county\",\"no_insurance:  8.2<br />dist_ssp:  25.55<br />trempealeau county\",\"no_insurance: 13.6<br />dist_ssp:  41.86<br />bertie county\",\"no_insurance: 11.4<br />dist_ssp:  58.83<br />grayson county\",\"no_insurance: 10.9<br />dist_ssp: 266.20<br />harlan county\",\"no_insurance: 10.3<br />dist_ssp: 104.86<br />phelps county\",\"no_insurance: 16.0<br />dist_ssp:  96.53<br />dekalb county\",\"no_insurance:  5.3<br />dist_ssp:  59.67<br />cottonwood county\",\"no_insurance:  7.2<br />dist_ssp:  99.25<br />marshall county\",\"no_insurance:  8.4<br />dist_ssp:  44.80<br />greene county\",\"no_insurance: 10.1<br />dist_ssp:  36.25<br />jackson county\",\"no_insurance: 15.5<br />dist_ssp: 227.00<br />ketchikan gateway borough\",\"no_insurance: 11.5<br />dist_ssp:  23.00<br />simpson county\",\"no_insurance: 10.8<br />dist_ssp: 202.77<br />reno county\",\"no_insurance: 18.4<br />dist_ssp:  30.67<br />cherokee county\",\"no_insurance: 15.0<br />dist_ssp: 173.12<br />twin falls county\",\"no_insurance: 10.2<br />dist_ssp: 177.83<br />noble county\",\"no_insurance:  6.2<br />dist_ssp:  55.17<br />meeker county\",\"no_insurance: 13.5<br />dist_ssp:  31.40<br />scotland county\",\"no_insurance: 11.7<br />dist_ssp: 107.57<br />stone county\",\"no_insurance:  7.9<br />dist_ssp: 262.00<br />pawnee county\",\"no_insurance: 15.4<br />dist_ssp: 115.78<br />marshall county\",\"no_insurance: 10.8<br />dist_ssp: 123.67<br />macon county\",\"no_insurance: 11.6<br />dist_ssp: 146.20<br />elk county\",\"no_insurance: 15.9<br />dist_ssp:  55.33<br />pearl river county\",\"no_insurance: 14.8<br />dist_ssp: 388.50<br />dewitt county\",\"no_insurance:  9.8<br />dist_ssp:  21.00<br />owsley county\",\"no_insurance: 16.9<br />dist_ssp:  70.50<br />perry county\",\"no_insurance: 12.8<br />dist_ssp: 122.38<br />decatur county\",\"no_insurance:  7.6<br />dist_ssp:  60.85<br />tama county\",\"no_insurance:  5.7<br />dist_ssp:  38.55<br />shelby county\",\"no_insurance:  3.3<br />dist_ssp: 151.82<br />carroll county\",\"no_insurance: 11.4<br />dist_ssp:  71.00<br />lake county\",\"no_insurance: 21.0<br />dist_ssp: 456.00<br />jim wells county\",\"no_insurance: 12.0<br />dist_ssp: 175.25<br />dundy county\",\"no_insurance: 22.8<br />dist_ssp: 291.00<br />kinney county\",\"no_insurance: 10.5<br />dist_ssp:  28.62<br />summit county\",\"no_insurance: 22.1<br />dist_ssp: 168.50<br />sabine county\",\"no_insurance: 18.8<br />dist_ssp: 206.75<br />pierce county\",\"no_insurance: 13.8<br />dist_ssp: 119.60<br />cleburne county\",\"no_insurance: 12.3<br />dist_ssp:  54.00<br />galax city\",\"no_insurance: 12.9<br />dist_ssp:  37.60<br />la plata county\",\"no_insurance: 17.8<br />dist_ssp: 318.00<br />llano county\",\"no_insurance:  7.6<br />dist_ssp:  72.07<br />fayette county\",\"no_insurance: 15.9<br />dist_ssp: 180.50<br />kay county\",\"no_insurance:  8.2<br />dist_ssp:  72.17<br />gasconade county\",\"no_insurance:  9.8<br />dist_ssp: 177.50<br />luce county\",\"no_insurance: 12.7<br />dist_ssp: 159.50<br />payne county\",\"no_insurance:  6.2<br />dist_ssp: 128.75<br />boone county\",\"no_insurance:  8.5<br />dist_ssp: 315.54<br />kennebec county\",\"no_insurance: 16.6<br />dist_ssp: 181.50<br />humboldt county\",\"no_insurance: 19.2<br />dist_ssp: 188.67<br />holmes county\",\"no_insurance:  8.7<br />dist_ssp: 182.12<br />beadle county\",\"no_insurance: 18.5<br />dist_ssp: 193.50<br />seminole county\",\"no_insurance: 18.1<br />dist_ssp:  53.40<br />hyde county\",\"no_insurance: 15.7<br />dist_ssp:  82.50<br />uinta county\",\"no_insurance: 13.0<br />dist_ssp:  90.17<br />silver bow county\",\"no_insurance: 10.7<br />dist_ssp:  95.40<br />wilkinson county\",\"no_insurance:  8.3<br />dist_ssp:  29.78<br />nelson county\",\"no_insurance: 13.5<br />dist_ssp:  93.30<br />juniata county\",\"no_insurance: 18.0<br />dist_ssp: 103.00<br />accomack county\",\"no_insurance: 13.0<br />dist_ssp:  47.27<br />wayne county\",\"no_insurance: 11.2<br />dist_ssp:  35.59<br />wyoming county\",\"no_insurance: 19.9<br />dist_ssp: 141.00<br />randolph county\",\"no_insurance: 13.7<br />dist_ssp: 210.00<br />finney county\",\"no_insurance: 11.1<br />dist_ssp: 130.50<br />fulton county\",\"no_insurance: 11.1<br />dist_ssp:  32.67<br />martin county\",\"no_insurance: 10.6<br />dist_ssp: 253.12<br />barber county\",\"no_insurance: 19.3<br />dist_ssp: 200.20<br />decatur county\",\"no_insurance: 12.0<br />dist_ssp: 265.00<br />woods county\",\"no_insurance: 13.9<br />dist_ssp:  62.00<br />troup county\",\"no_insurance: 22.7<br />dist_ssp: 150.00<br />kodiak island borough\",\"no_insurance: 24.9<br />dist_ssp: 106.33<br />dallam county\",\"no_insurance:  6.2<br />dist_ssp:  81.18<br />jasper county\",\"no_insurance: 19.1<br />dist_ssp: 199.20<br />conecuh county\",\"no_insurance: 18.2<br />dist_ssp: 289.62<br />leon county\",\"no_insurance: 11.4<br />dist_ssp: 302.92<br />lincoln county\",\"no_insurance: 22.6<br />dist_ssp: 386.50<br />gonzales county\",\"no_insurance: 10.1<br />dist_ssp:  57.78<br />logan county\",\"no_insurance: 14.1<br />dist_ssp: 113.20<br />nye county\",\"no_insurance:  5.5<br />dist_ssp:  44.00<br />henry county\",\"no_insurance:  8.9<br />dist_ssp: 271.67<br />kiowa county\",\"no_insurance: 11.6<br />dist_ssp:  68.83<br />mcminn county\",\"no_insurance: 10.7<br />dist_ssp:  46.11<br />monroe county\",\"no_insurance: 12.4<br />dist_ssp:  72.00<br />osceola county\",\"no_insurance: 15.2<br />dist_ssp: 204.33<br />wilcox county\",\"no_insurance:  8.8<br />dist_ssp:  46.50<br />muskingum county\",\"no_insurance: 11.7<br />dist_ssp: 205.50<br />dodge county\",\"no_insurance: 12.1<br />dist_ssp:  28.86<br />greene county\",\"no_insurance:  6.9<br />dist_ssp:  15.00<br />pleasants county\",\"no_insurance: 13.4<br />dist_ssp:  73.75<br />benton county\",\"no_insurance: 19.5<br />dist_ssp: 124.75<br />moore county\",\"no_insurance: 11.4<br />dist_ssp:  38.83<br />steuben county\",\"no_insurance: 12.2<br />dist_ssp:  51.20<br />fulton county\",\"no_insurance: 14.6<br />dist_ssp: 339.40<br />lee county\",\"no_insurance: 14.0<br />dist_ssp:  38.33<br />white county\",\"no_insurance:  6.0<br />dist_ssp:  58.95<br />otter tail county\",\"no_insurance: 18.2<br />dist_ssp: 168.50<br />jeff davis county\",\"no_insurance: 14.7<br />dist_ssp: 148.00<br />deuel county\",\"no_insurance: 11.1<br />dist_ssp:  81.00<br />marion county\",\"no_insurance: 11.9<br />dist_ssp: 343.94<br />waldo county\",\"no_insurance:  8.1<br />dist_ssp:  22.62<br />sierra county\",\"no_insurance:  8.6<br />dist_ssp: 116.29<br />st. lawrence county\",\"no_insurance: 21.0<br />dist_ssp:  54.00<br />lamb county\",\"no_insurance: 12.4<br />dist_ssp: 120.56<br />miller county\",\"no_insurance: 23.5<br />dist_ssp: 487.00<br />brooks county\",\"no_insurance: 11.7<br />dist_ssp: 221.00<br />colfax county\",\"no_insurance: 18.1<br />dist_ssp:  30.29<br />avery county\",\"no_insurance: 14.7<br />dist_ssp: 197.50<br />st. francis county\",\"no_insurance: 13.8<br />dist_ssp: 212.75<br />kemper county\",\"no_insurance: 10.1<br />dist_ssp:  51.33<br />caroline county\",\"no_insurance: 12.3<br />dist_ssp: 226.71<br />harper county\",\"no_insurance: 12.7<br />dist_ssp:  32.60<br />johnson county\",\"no_insurance: 11.4<br />dist_ssp:  11.00<br />kittitas county\",\"no_insurance: 15.8<br />dist_ssp: 342.00<br />burnet county\",\"no_insurance: 32.6<br />dist_ssp:  49.67<br />gaines county\",\"no_insurance: 20.8<br />dist_ssp:  77.00<br />dawson county\",\"no_insurance: 15.0<br />dist_ssp: 213.75<br />beckham county\",\"no_insurance:  7.8<br />dist_ssp:  27.20<br />dunn county\",\"no_insurance: 12.5<br />dist_ssp:  71.33<br />gladwin county\",\"no_insurance: 16.5<br />dist_ssp: 138.75<br />bamberg county\",\"no_insurance: 13.2<br />dist_ssp: 173.22<br />bingham county\",\"no_insurance: 13.1<br />dist_ssp:  79.67<br />lincoln county\",\"no_insurance: 16.4<br />dist_ssp: 212.00<br />leflore county\",\"no_insurance:  8.8<br />dist_ssp:  35.08<br />ohio county\",\"no_insurance:  8.4<br />dist_ssp: 177.17<br />fayette county\",\"no_insurance: 12.6<br />dist_ssp: 267.25<br />edwards county\",\"no_insurance:  6.9<br />dist_ssp:  29.56<br />morgan county\",\"no_insurance:  8.9<br />dist_ssp: 155.29<br />houghton county\",\"no_insurance: 10.5<br />dist_ssp:  38.50<br />crook county\",\"no_insurance: 31.1<br />dist_ssp: 330.00<br />maverick county\",\"no_insurance: 10.2<br />dist_ssp:  21.33<br />clay county\",\"no_insurance: 12.6<br />dist_ssp:   6.00<br />carter county\",\"no_insurance: 13.0<br />dist_ssp: 127.25<br />morrill county\",\"no_insurance:  8.8<br />dist_ssp: 196.80<br />burt county\",\"no_insurance: 20.3<br />dist_ssp:  83.17<br />hale county\",\"no_insurance: 10.3<br />dist_ssp:  90.50<br />allen county\",\"no_insurance:  8.8<br />dist_ssp: 224.43<br />russell county\",\"no_insurance:  8.1<br />dist_ssp: 102.40<br />chippewa county\",\"no_insurance: 20.7<br />dist_ssp: 339.00<br />bosque county\",\"no_insurance: 14.9<br />dist_ssp: 188.14<br />sheridan county\",\"no_insurance: 14.9<br />dist_ssp: 131.40<br />wilcox county\",\"no_insurance: 15.8<br />dist_ssp:  55.79<br />columbus county\",\"no_insurance: 15.3<br />dist_ssp:  99.75<br />woodson county\",\"no_insurance: 17.8<br />dist_ssp: 180.40<br />nolan county\",\"no_insurance: 11.2<br />dist_ssp:  99.23<br />union county\",\"no_insurance: 11.0<br />dist_ssp: 237.33<br />campbell county\",\"no_insurance: 11.8<br />dist_ssp:  54.25<br />sanilac county\",\"no_insurance:  7.8<br />dist_ssp: 197.57<br />jewell county\",\"no_insurance: 13.5<br />dist_ssp: 159.50<br />lauderdale county\",\"no_insurance: 16.5<br />dist_ssp: 216.43<br />blaine county\",\"no_insurance: 10.9<br />dist_ssp: 147.00<br />morton county\",\"no_insurance: 12.8<br />dist_ssp:  43.17<br />russell county\",\"no_insurance: 14.5<br />dist_ssp:  39.14<br />patrick county\",\"no_insurance:  8.2<br />dist_ssp:  47.77<br />gratiot county\",\"no_insurance: 27.7<br />dist_ssp: 460.60<br />duval county\",\"no_insurance:  5.3<br />dist_ssp: 224.29<br />caledonia county\",\"no_insurance: 10.2<br />dist_ssp: 158.44<br />gallatin county\",\"no_insurance:  8.4<br />dist_ssp:  88.67<br />northumberland county\",\"no_insurance: 13.6<br />dist_ssp:  73.00<br />livingston county\",\"no_insurance: 17.4<br />dist_ssp: 313.50<br />hamilton county\",\"no_insurance: 11.5<br />dist_ssp: 190.00<br />lincoln county\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,158,115,0.4)\",\"opacity\":1,\"size\":7.559055118110237,\"symbol\":\"circle\",\"line\":{\"width\":1.8897637795275593,\"color\":\"rgba(0,158,115,0.4)\"}},\"hoveron\":\"points\",\"name\":\"(non-metro,1)\",\"legendgroup\":\"(non-metro,1)\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":26.228310502283108,\"r\":7.3059360730593621,\"b\":40.182648401826498,\"l\":43.105022831050235},\"plot_bgcolor\":\"rgba(255,255,255,1)\",\"paper_bgcolor\":\"rgba(255,255,255,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[1.355,37.545000000000002],\"tickmode\":\"array\",\"ticktext\":[\"10\",\"20\",\"30\"],\"tickvals\":[10,20.000000000000004,30],\"categoryorder\":\"array\",\"categoryarray\":[\"10\",\"20\",\"30\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.66417600664176002,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176002,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"County percent uninsured\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-25.5,535.5],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"100\",\"200\",\"300\",\"400\",\"500\"],\"tickvals\":[0,100,200,300,400,500],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"100\",\"200\",\"300\",\"400\",\"500\"],\"nticks\":null,\"ticks\":\"outside\",\"tickcolor\":\"rgba(51,51,51,1)\",\"ticklen\":3.6529680365296811,\"tickwidth\":0.66417600664176002,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.68949771689498},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176002,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Miles to nearest syringe program\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":\"transparent\",\"line\":{\"color\":\"rgba(51,51,51,1)\",\"width\":0.66417600664176002,\"linetype\":\"solid\"},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255,255,255,1)\",\"bordercolor\":\"transparent\",\"borderwidth\":1.8897637795275593,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.68949771689498},\"title\":{\"text\":\"Regression line<br />(predicted values)<br />County\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.611872146118724}}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"ba74558caaf7\":{\"x\":{},\"y\":{},\"linetype\":{},\"type\":\"scatter\"},\"ba7462c6a02\":{\"x\":{},\"y\":{},\"text\":{},\"colour\":{}}},\"cur_data\":\"ba74558caaf7\",\"visdat\":{\"ba74558caaf7\":[\"function (y) \",\"x\"],\"ba7462c6a02\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\nInteractive regression model `lm9.2` with percent uninsured and metro\n:::\n\n*** \n\nThis is an experiment with interactive graphic using the `ggplotly()` function from the {**plotly**) package. This is my first try. There is still something wrong with the legend. I have to go into more detail, especially reading [Interactive Web-Based Data Visualization With R, Plotly, and Shiny](https://plotly-r.com/) [@sievert2020].\n\n\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n### Using the multiple regression model\n\n:::::{.my-theorem}\n:::{.my-theorem-header}\n:::::: {#thm-chap09-apply-model}\n: Applying multiple regression model `lm9.2`\n::::::\n:::\n::::{.my-theorem-container}\n\nI am going to use as an example Miami county (Indiana) with exactly 10% of their residents not insured. This conforms to the book's example. For a metro county I am using Sonoma county (California) with a slight different uninsured population of 10.1%.\n\n\n\n$$\n\\begin{align*}\n\\text{Distance to SSP} = \\text{Intercept} &+ \\text{SlopeV1} \\times \\text{ValueV1} + \\\\\n&+ \\text{SlopeV2} \\times \\text{ValueV2} \\\\\n\\end{align*}\n$$ {#eq-chap09-formula-multiple-regression}\n\n$$\n\\begin{align*}\n\\text{For Miami (IN) to SSP} &= 3.42 + 7.3 * 10 + 28.05 * 1 = 104.48\\\\\n\\text{For Sonoma (CA) to SSP} &= 3.42 + 7.3 * 10.1 + 28.05 * 0 = 77.15 \\\\\n\\end{align*}\n$$ {#eq-chap09-example-multiple-regression}\n::::\n:::::\n\nLet's now check these two values with the real data:\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-check-values-computed-manually}\n: Compute the values for Miami and Sonoma county\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-check-values-computed-manually}\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl9.2_check <-  broom::augment(\n    lm9.2,\n    interval = c(\"prediction\")\n    ) |> \n    dplyr::bind_cols(distance_ssp_clean[, 1:2]) |> \n    dplyr::relocate(county, state) |> \n    dplyr::select(1:9) |> \n    dplyr::filter(\n        county == \"miami county\" & state == \"IN\" |\n        county == \"sonoma county\" & state == \"CA\") |> \n    dplyr::arrange(no_insurance)\n\nprint.data.frame(tbl9.2_check, digits = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>          county state dist_ssp no_insurance     metro  .fitted   .lower  .upper\n#> 1  miami county    IN    48.88         10.0 non-metro 104.4813 -62.6779 271.640\n#> 2 sonoma county    CA    13.11         10.1     metro  77.1589 -90.0093 244.327\n#>     .resid\n#> 1 -55.6013\n#> 2 -64.0489\n```\n\n\n:::\n:::\n\n\nCompute `lm9.2` model values for Miami county (IN) and Sonoma county (CA)\n:::\n\nOur values calculated manually (104.48 and 77.15) match the values in `.fitted` column! We also see that the real values (48.88 and 13.11) are very far from our predicted values but inside the insanely huge 95% predicted intervals.\n\nIf we add the values in the column `.resid` to our predicted values in `.fitted` we will get the real distances to the nearest Syringe Services Program (SSP). For example: 104.4813 - 55.50131 = 48.97999.\n\n::::\n:::::\n\n\n\n## Experiments\n\n### Using {**broom**} {#sec-chap09-broom-exeriments}\n\n{**broom**} converts untidy output into tidy tibbles. This is important whenever you want to combine results from multiple model (or tests). I have {**broom**} already used to compare results from the normality tests (<a class='glossary' title='The Shapiro-Wilk test is a statistical test to determine or confirm whether a variable has a normal distribution; it is sensitive to small deviations from normality and not useful for sample sizes above 5,000 because it will nearly always find non-normality. (SwR, Glossary)'>Shapiro-Wilk</a> and <a class='glossary' title='The Anderson-Darling Goodness of Fit Test (AD-Test) is a measure of how well your data fits a specified distribution. It’s commonly used as a test for normality. (Statistics How-To)'>Anderson-Darling</a>), and homogeneity tests (<a class='glossary' title='Levene’s test is a statistical test to determine whether observed data meet the homogeneity of variances assumption; Levene’s test is used to test this assumption for t-tests and analysis of variance. (SwR, Glossary)'>Levene</a> and <a class='glossary' title='The Fligner-Killeen test is a non-parametric test for homogeneity of group variances based on ranks. It is useful when the data is non-normal or when there are outliers. (Real Statistics Using Excel)'>Fligner-Killeen</a>. In the first case (normality) both tests result in `htest` objects. I could therefore bind as different rows in a new tibble dataframe (see: @tbl-chap09-eda-test-normality). In the second case (homogeneity) I got with `htest` and `anova` two different objects and had to work around the differences manually before I could bind them into the same tibble (See: @tbl-chap09-eda-test-homogeneity). \n\nAt that time I didn't know that I should have used only `broom::tidy()` and not improvise with `broom:::glance.htest()`. The real advantage of glance can be seen when it is applied to a linear model. \n\n::: {.callout-important #imp-chap09-diff-broom-tidy-glance}\n##### Three verbs in {**broom**} to make it convenient to interact with model objects\n\n- `broom::tidy()` **summarizes** information about **model components**\n- `broom::glance()` **reports** information about the **entire model**\n- `broom::augment()` **adds information** about observations to a dataset\n:::\n\n\n:::::{.my-experiment}\n:::{.my-experiment-header}\n:::::: {#def-chap09-using-broom}\n: How to use {**broom**}?\n::::::\n:::\n::::{.my-experiment-container}\n\n::: {.panel-tabset}\n\n###### tidy()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-broom-tidy}\n: Using `broom::tidy()` to compare different normality tests\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-broom-tidy}\n\n::: {.cell}\n\n```{.r .cell-code}\n(test_shapiro = stats::shapiro.test(distance_ssp_clean$dist_ssp))\n(test_ad = nortest::ad.test(distance_ssp_clean$dist_ssp))\n\ntest_compare <- \n    dplyr::bind_rows(\n        broom::tidy(test_shapiro),\n        broom::tidy(test_ad)\n    )\ntest_compare\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tShapiro-Wilk normality test\n#> \n#> data:  distance_ssp_clean$dist_ssp\n#> W = 0.87419, p-value < 2.2e-16\n#> \n#> \n#> \tAnderson-Darling normality test\n#> \n#> data:  distance_ssp_clean$dist_ssp\n#> A = 17.995, p-value < 2.2e-16\n#> \n#> # A tibble: 2 × 3\n#>   statistic  p.value method                         \n#>       <dbl>    <dbl> <chr>                          \n#> 1     0.874 1.10e-19 Shapiro-Wilk normality test    \n#> 2    18.0   3.7 e-24 Anderson-Darling normality test\n```\n\n\n:::\n:::\n\n    \nCompare Shapiro-Wilk with Anderson-Darling normality test\n:::\n\n***\n\nEven the details differ both tests result show a tiny p-value < .001 and support therefore the same decision to reject the Null.\n\nIt is of interest that the p-value for each test reported individually is the same and does not conform with the value in the `htest` object. It is with 2.22e-16 --- as my internet research had turned out ([How should tiny 𝑝\n-values be reported? (and why does R put a minimum on 2.22e-16?)](https://stats.stackexchange.com/questions/78839/how-should-tiny-p-values-be-reported-and-why-does-r-put-a-minimum-on-2-22e-1)) \"a value below which you can be quite confident the value will be pretty numerically meaningless - in that any smaller value isn't likely to be an accurate calculation of the value we were attempting to compute\". \n\nAnd even more important from the same author:\n\n> But *statistical* meaning will have been lost far earlier. Note that p-values depend on assumptions, and the further out into the extreme tail you go the more heavily the true p-value (rather than the nominal value we calculate) will be affected by the mistaken assumptions, in some cases even when they're only a little bit wrong. [@glenb2013]\n\nAs a result of this discussion: \n\nThe `broom::tidy()` version reports the value inside the `htest`object, showing that they are different and that Shapiro-Wilk is the more conservative test. But **statistically** it has no relevance because the report according to the recommendation of the APA style guide is: **Do not use any value smaller than p < 0.001** [@jaap2013].\n\n::::\n:::::\n\n\n\n###### glance()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-broom-glance}\n: Using `broom::glance()` to report information about the entire model\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-broom-glance}    \n\n::: {.cell}\n\n```{.r .cell-code}\nlm9.2\nbase::summary(lm9.2)\nprint(broom::glance(lm9.2), width = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> stats::lm(formula = dist_ssp ~ no_insurance + metro, data = distance_ssp_clean)\n#> \n#> Coefficients:\n#>    (Intercept)    no_insurance  metronon-metro  \n#>          3.424           7.300          28.052  \n#> \n#> \n#> Call:\n#> stats::lm(formula = dist_ssp ~ no_insurance + metro, data = distance_ssp_clean)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -219.80  -60.07  -18.76   48.33  283.96 \n#> \n#> Coefficients:\n#>                Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)      3.4240    10.3621   0.330 0.741212    \n#> no_insurance     7.3005     0.7775   9.389  < 2e-16 ***\n#> metronon-metro  28.0525     7.7615   3.614 0.000332 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 84.89 on 497 degrees of freedom\n#> Multiple R-squared:  0.1915,\tAdjusted R-squared:  0.1883 \n#> F-statistic: 58.88 on 2 and 497 DF,  p-value: < 2.2e-16\n#> \n#> # A tibble: 1 × 12\n#>   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n#>       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n#> 1     0.192         0.188  84.9      58.9 1.13e-23     2 -2929. 5865. 5882.\n#>   deviance df.residual  nobs\n#>      <dbl>       <int> <int>\n#> 1 3581712.         497   500\n```\n\n\n:::\n:::\n\n\nUsing `broom::glance()` to report additional information about the entire model\n:::\n\n***\n\nI have put together three types of model output:\n\n1. The first call is just printing the model: `lm9.2`.\n2. The second call summarizes more information in a convenient format: `base::summary(lm9.2)``\n3. The third part of @lst-chap09-broom-glance finally shows the output generated with `broom::glance(lm9.2)`. It adds some important information for evaluation of the model quality and for model comparison. Some of these parameters (logLik, AIC, BIC and deviance) We haven't not learned so far in this book. \n\n***\n\n**logLik: log-likelihood value**\n\n> The log-likelihood value of a regression model is a way to measure the goodness of fit for a model. The higher the value of the log-likelihood, the better a model fits a dataset.\n\n>  The **log-likelihood value** for a given model can range from negative infinity to positive infinity. The actual log-likelihood value for a given model is mostly meaningless, but **it’s useful for comparing two or more models**. [@zach2021]\n\n***\n\n**AIC: Akaike information criterion**\n\n> Akaike information criterion (AIC) is a metric that is used to compare the fit of different regression models.\n\n> There is no value for AIC that can be considered “good” or “bad” because we simply use AIC as a way to compare regression models. The model with the lowest AIC offers the best fit. The absolute value of the AIC value is not important. [@zach2021a]\n\n***\n\n**BIC: Bayesian Information Criterion**\n\n> The Bayesian Information Criterion (BIC) is an index used in Bayesian statistics **to choose between two or more alternative models**. The BIC is also known as the Schwarz information criterion (abrv. SIC) or the Schwarz-Bayesian information criteria.\n\n> Comparing models with the Bayesian information criterion simply involves **calculating the BIC for each model**. The model with the lowest BIC is considered the best, and can be written BIC* (or SIC* if you use that name and abbreviation). [@glenn2018]\n\n***\n\n**Deviance**\n\n> in statistics, a measure of the goodness of fit between a smaller hierarchical model and a fuller model that has all of the same parameters plus more. If the deviance reveals a significant difference, then the larger model is needed. If the deviance is not significant, then the smaller, more parsimonious model is retained as more appropriate. (https://dictionary.apa.org/deviance)\n\n\n\n::::\n:::::\n\n###### augment()\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap09-broom-augment}\n: Using broom::augment() to add information about observations to a dataset\n::::::\n:::\n::::{.my-r-code-container}\n::: {#lst-chap09-broom-augment}\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl9.2_aug <-  broom::augment(\n    lm9.2,\n    se_fit = TRUE,\n    interval = c(\"prediction\")\n    ) |> \n    dplyr::bind_cols(distance_ssp_clean[, 1:2]) |> \n    dplyr::relocate(county, state)\n\n\n\nsave_data_file(\"chap09\", tbl9.2_aug, \"tbl9.2_aug.rds\")\n\nprint(tbl9.2_aug, width = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 500 × 14\n#>    county           state dist_ssp no_insurance metro     .fitted    .lower\n#>    <chr>            <fct>    <dbl>        <dbl> <fct>       <dbl>     <dbl>\n#>  1 wabasha county   MN       47.4           5.1 metro        40.7 -127.    \n#>  2 johnson county   GA      125            18.5 non-metro   167.    -0.770 \n#>  3 iron county      MO       77.2          15.9 non-metro   148.   -19.6   \n#>  4 kosciusko county IN       42.1          12.4 non-metro   122.   -45.1   \n#>  5 delaware county  OK       49.2          18.6 non-metro   167.    -0.0478\n#>  6 scurry county    TX      141            14.8 non-metro   140.   -27.6   \n#>  7 jefferson county MS       81.5          11.2 non-metro   113.   -53.9   \n#>  8 lee county       IA       68.4           6.8 non-metro    81.1  -86.2   \n#>  9 santa fe county  NM        9.17         15.7 metro       118.   -49.3   \n#> 10 cass county      MO       31.2           8.4 metro        64.7 -102.    \n#>    .upper .se.fit  .resid    .hat .sigma     .cooksd .std.resid\n#>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>       <dbl>      <dbl>\n#>  1   208.    7.36    6.78 0.00752   85.0 0.0000162       0.0802\n#>  2   334.    6.67  -41.5  0.00617   85.0 0.000499       -0.491 \n#>  3   315.    5.60  -70.4  0.00435   84.9 0.00100        -0.831 \n#>  4   289.    5.15  -79.9  0.00368   84.9 0.00109        -0.942 \n#>  5   335.    6.72 -118.   0.00627   84.8 0.00409        -1.39  \n#>  6   307.    5.31    1.48 0.00392   85.0 0.000000398     0.0174\n#>  7   280.    5.32  -31.7  0.00393   85.0 0.000184       -0.375 \n#>  8   248.    7.05  -12.7  0.00689   85.0 0.0000520      -0.150 \n#>  9   285.    6.65 -109.   0.00614   84.8 0.00341        -1.29  \n#> 10   232.    6.04  -33.5  0.00507   85.0 0.000266       -0.396 \n#> # ℹ 490 more rows\n```\n\n\n:::\n:::\n\n\nUsing broom::augment() to add information about observations to a dataset\n:::\n\nWith `broom::augment()` we got those diagnostic values that we have calculated individually for the `lm9.1` model in previous sections of this chapter:\n\n- Residuals and fitted values (columns `.resid` and `.fitted`): See @lst-chap09-regression-with-residuals.\n- Standardized residuals (column `.std.resid`): See (@lst-chap09-diagnostics-standardize-residuals).\n- Cook’s Distance (column `.cooksd`): See @lst-chap09-diagnostics-cooks-d.\n- Leverage (column `.hat`): See @lst-chap09-diagnostics-leverage\n- Sigma, here as column `.sigma` for the \"estimated residual standard deviation when corresponding observation is dropped from model\". (Where's the `.sigma` equivalent in this chapter?)\n\nAdditionally there is the option to include:\n\n- Standard errors of fitted values (column `.se.fit`): (Where's the `.se.fit` equivalent in this chapter?)\n- Confidence intervals (columns `.lower` and `.upper`) or alternative predicted intervals: See @lst-chap09-compute-confint or @lst-chap09-predict-all-values. Here I have used `interval = prediction`.\n\n\n\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\n***\n\n\n## Exercises (empty)\n\n## Glossary\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Adjusted-R2 </td>\n   <td style=\"text-align:left;\"> Adjusted R-squared is a measure of model fit for ordinary least squares linear regression that penalizes the R-squared, or percentage of variance explained, for the number of variables in the model (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> amfAR </td>\n   <td style=\"text-align:left;\"> amfAR, the Foundation for AIDS Research, known until 2005 as the American Foundation for AIDS Research, is an international nonprofit organization dedicated to the support of AIDS research, HIV prevention, treatment education, and the advocacy of AIDS-related public policy. (&lt;a href=\"https://en.wikipedia.org/wiki/AmfAR\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Anderson-Darling </td>\n   <td style=\"text-align:left;\"> The Anderson-Darling Goodness of Fit Test (AD-Test) is a measure of how well your data fits a specified distribution. It’s commonly used as a test for normality. (&lt;a href=\"https://www.statisticshowto.com/anderson-darling-test/\"&gt;Statistics How-To&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ANOVA </td>\n   <td style=\"text-align:left;\"> Analysis of variance is a statistical method used to compare means across groups to determine whether there is a statistically significant difference among the means; typically used when there are three or more means to compare. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Breusch-Pagan </td>\n   <td style=\"text-align:left;\"> Breusch-Pagan is a statistical test for determining whether variance is constant, which is used to test the assumption of homoscedasticity; Breusch-Pagan relies on the [chi-squared] distribution and is used during assumption checking for [homoscedasticity] in [linear regression]. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cook’s D </td>\n   <td style=\"text-align:left;\"> Cook’s distance (often abbreviated Cook’s D) is used in Regression Analysis to find influential outliers in a set of predictor variables. IIt is a way to identify points that negatively affect the regression model. ([Statistics How To](https://www.statisticshowto.com/cooks-distance/)) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Correlation </td>\n   <td style=\"text-align:left;\"> Correlation coefficients are a standardized measure of how two variables are related, or co-vary. They are used to measure how strong a relationship is between two variables. There are several types of correlation coefficient, but the most popular is Pearson’s. Pearson’s correlation (also called Pearson’s R) is a correlation coefficient commonly used in linear regression. ([Statistics How To](https://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/)) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Degrees of Freedom </td>\n   <td style=\"text-align:left;\"> Degree of Freedom (df) is the number of pieces of information that are allowed to vary in computing a statistic before the remaining pieces of information are known; degrees of freedom are often used as parameters for distributions (e.g., chi-squared, F). (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Deterministic </td>\n   <td style=\"text-align:left;\"> A deterministic equation, or model, has one precise value for y for each value of x. (SwR, Chap09) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Diagnostics </td>\n   <td style=\"text-align:left;\"> Diagnostics in linear and logistic regression are a set of tests to identify outliers and influential values among the observations. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Durbin-Watson </td>\n   <td style=\"text-align:left;\"> Durbin-Watson test is a statistical test that is used to check the assumption of independent residuals in linear regression; a Durbin-Watson statistic of 2 indicates that the residuals are independent. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ExDA </td>\n   <td style=\"text-align:left;\"> Explorative Data Analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling and thereby contrasts traditional hypothesis testing. (&lt;a href=\"https://en.wikipedia.org/wiki/Exploratory_data_analysis\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> F-Statistic </td>\n   <td style=\"text-align:left;\"> F-statistic is a test statistic comparing explained and unexplained variance in [ANOVA] and linear regression. The F-statistic is a ratio where the variation between the groups is compared to the variation within the groups. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Fligner </td>\n   <td style=\"text-align:left;\"> The Fligner-Killeen test is a non-parametric test for homogeneity of group variances based on ranks. It is useful when the data is non-normal or when there are outliers. (&lt;a href=\"https://real-statistics.com/one-way-analysis-of-variance-anova/homogeneity-variances/fligner-killeen-test/\"&gt;Real Statistics Using Excel&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Homoscedasticity </td>\n   <td style=\"text-align:left;\"> Homoscedasticity is [homogeneity of variances], contrast is [Heteroscedasticity]. Homoscedasticity is an assumption of correlation and linear regression that requires that the variance of y be constant across all the values of x; visually, this assumption would show points along a fit line between x and y being evenly spread on either side of the line for the full range of the relationship. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Influential Observation </td>\n   <td style=\"text-align:left;\"> An influential observation is an observation that changes the slope of a regression line. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Intercept </td>\n   <td style=\"text-align:left;\"> The intercept is the value of the dependent variables if all independent variables have the value zero. (&lt;a href=\"https://link.springer.com/referenceworkentry/10.1007/978-94-007-0753-5_1486\"&gt;Intercept, Slope in Regression&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Levene </td>\n   <td style=\"text-align:left;\"> Levene’s test is a statistical test to determine whether observed data meet the homogeneity of variances assumption; Levene’s test is used to test this assumption for t-tests and analysis of variance. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Linearity </td>\n   <td style=\"text-align:left;\"> Linearity is the assumption of some statistical models that requires the outcome, or transformed outcome, to have a linear relationship with numeric predictors, where linear relationships are relationships that are evenly distributed around a line. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mean Square </td>\n   <td style=\"text-align:left;\"> Mean square is the mean of the squared differences between two values; mean squares are used to compute the F-statistic in analysis of variance and linear regression. (Swr, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model-fit </td>\n   <td style=\"text-align:left;\"> Model fit means how well the model captures the relationship in the observed data. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OLS </td>\n   <td style=\"text-align:left;\"> Ordinary least square regression (OLS) is a method of estimating a linear regression model that finds the regression line by minimizing the squared differences between each data point and the regression line. (Swr; Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> One-sample </td>\n   <td style=\"text-align:left;\"> One-sample t-test, also known as the single-parameter t-test or single-sample t-test, is an inferential statistical test comparing the mean of a numeric variable to a population or hypothesized mean. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Outliers </td>\n   <td style=\"text-align:left;\"> Outliers are observations with unusual values. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p-value </td>\n   <td style=\"text-align:left;\"> The p-value is the probability that the test statistic is at least as big as it is under the null hypothesis (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Pearson </td>\n   <td style=\"text-align:left;\"> Pearson’s r is a statistic that indicates the strength and direction of the relationship between two numeric variables that meet certain assumptions. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q-Q-Plot </td>\n   <td style=\"text-align:left;\"> A quantile-quantile plot is a visualization of data using probabilities to show how closely a variable follows a normal distribution. (SwR, Glossary) This plot is made up of points below which a certain percentage of the observations fall. On the x-axis are normally distributed values with a mean of 0 and a standard deviation of 1. On the y-axis are the observations from the data. If the data are normally distributed, the values will form a diagonal line through the graph. (SwR, chapter 6) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R-squared </td>\n   <td style=\"text-align:left;\"> R-squared is the percent of variance in a numeric variable that is explained by one or more other variables; the r-squared is also known as the coefficient of determination and is used as a measure of model fit in linear regression and an effect size in correlation analyses. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Residually </td>\n   <td style=\"text-align:left;\"> Residuals are the differences between the observed values and the predicted values. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Shapiro-Wilk </td>\n   <td style=\"text-align:left;\"> The Shapiro-Wilk test is a statistical test to determine or confirm whether a variable has a normal distribution; it is sensitive to small deviations from normality and not useful for sample sizes above 5,000 because it will nearly always find non-normality. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Simple Linear Regression </td>\n   <td style=\"text-align:left;\"> Simple does not mean easy; instead, it is the term used for a statistical model used to predict or explain a continuous outcome by a single predictor. (SwR, Glossary, Chap09) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Slope </td>\n   <td style=\"text-align:left;\"> The slope is the increase in the dependent variable when the independent variable increases with one unit and all other independent variables remain the same. (&lt;a href=\"https://link.springer.com/referenceworkentry/10.1007/978-94-007-0753-5_1486\"&gt;Intercept, Slope in Regression&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Spearman </td>\n   <td style=\"text-align:left;\"> Spearman’s rho a statistical test used to examine the strength, direction, and significance of the relationship between two numeric variables when they do not meet the assumptions for [Pearson]’s r. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SSP </td>\n   <td style=\"text-align:left;\"> SSP stands for Syringe Services Program (SwR) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Standardized Residuals </td>\n   <td style=\"text-align:left;\"> Standardized residuals are the standardized differences between observed and expected values in a chi-squared analysis; a large standardized residual indicates that the observed and expected values were very different. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> T-Statistic </td>\n   <td style=\"text-align:left;\"> The T-Statistic is used in a T test when you are deciding if you should support or reject the null hypothesis. It’s very similar to a Z-score and you use it in the same way: find a cut off point, find your t score, and compare the two. You use the t statistic when you have a small sample size, or if you don’t know the population standard deviation. (&lt;a href=\"https://www.statisticshowto.com/t-statistic/\"&gt;Statistics How-To&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> T-Test </td>\n   <td style=\"text-align:left;\"> A t-test is a type of statistical analysis used to compare the averages of two groups and determine whether the differences between them are more likely to arise from random chance. (&lt;a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Wald </td>\n   <td style=\"text-align:left;\"> Wald test is the statistical test for comparing the value of the coefficient in linear or logistic regression to the hypothesized value of zero; the form is similar to a one-sample t-test, although some Wald tests use a t-statistic and others use a z-statistic as the test statistic. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Z-score </td>\n   <td style=\"text-align:left;\"> A z-score (also called a standard score) gives you an idea of how far from the mean a data point is. But more technically it’s a measure of how many standard deviations below or above the population mean a raw score is. (&lt;a href=\"https://www.statisticshowto.com/probability-and-statistics/z-score/#Whatisazscore\"&gt;StatisticsHowTo&lt;/a&gt;) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n## Session Info {.unnumbered}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\nSession Info\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.3.3 (2024-02-29)\n#>  os       macOS Sonoma 14.4.1\n#>  system   x86_64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Europe/Vienna\n#>  date     2024-04-20\n#>  pandoc   3.1.13 @ /usr/local/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  package      * version    date (UTC) lib source\n#>  abind          1.4-5      2016-07-21 [1] CRAN (R 4.3.0)\n#>  backports      1.4.1      2021-12-13 [1] CRAN (R 4.3.0)\n#>  base64enc      0.1-3      2015-07-28 [1] CRAN (R 4.3.0)\n#>  broom          1.0.5      2023-06-09 [1] CRAN (R 4.3.0)\n#>  bslib          0.7.0      2024-03-29 [1] CRAN (R 4.3.2)\n#>  cachem         1.0.8      2023-05-01 [1] CRAN (R 4.3.0)\n#>  car            3.1-2      2023-03-30 [1] CRAN (R 4.3.0)\n#>  carData        3.0-5      2022-01-06 [1] CRAN (R 4.3.0)\n#>  class          7.3-22     2023-05-03 [2] CRAN (R 4.3.3)\n#>  cli            3.6.2      2023-12-11 [1] CRAN (R 4.3.0)\n#>  colorspace     2.1-1      2024-01-03 [1] R-Forge (R 4.3.2)\n#>  commonmark     1.9.1      2024-01-30 [1] CRAN (R 4.3.2)\n#>  crosstalk      1.2.1      2023-11-23 [1] CRAN (R 4.3.0)\n#>  curl           5.2.1      2024-03-01 [1] CRAN (R 4.3.2)\n#>  data.table     1.15.4     2024-03-30 [1] CRAN (R 4.3.2)\n#>  DBI            1.2.2      2024-02-16 [1] CRAN (R 4.3.2)\n#>  digest         0.6.35     2024-03-11 [1] CRAN (R 4.3.2)\n#>  dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.3.0)\n#>  DT             0.32       2024-02-19 [1] CRAN (R 4.3.2)\n#>  e1071          1.7-14     2023-12-06 [1] CRAN (R 4.3.0)\n#>  evaluate       0.23       2023-11-01 [1] CRAN (R 4.3.0)\n#>  fansi          1.0.6      2023-12-08 [1] CRAN (R 4.3.0)\n#>  farver         2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n#>  fastmap        1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n#>  forcats        1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n#>  generics       0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n#>  GGally         2.2.1      2024-02-14 [1] CRAN (R 4.3.2)\n#>  ggokabeito     0.1.0      2021-10-18 [1] CRAN (R 4.3.0)\n#>  ggplot2        3.5.0      2024-02-23 [1] CRAN (R 4.3.2)\n#>  ggstats        0.5.1      2023-11-21 [1] CRAN (R 4.3.0)\n#>  glossary     * 1.0.0.9000 2023-08-12 [1] Github (debruine/glossary@819e329)\n#>  glue           1.7.0      2024-01-09 [1] CRAN (R 4.3.0)\n#>  gridExtra      2.3        2017-09-09 [1] CRAN (R 4.3.0)\n#>  gtable         0.3.4      2023-08-21 [1] CRAN (R 4.3.0)\n#>  haven          2.5.4      2023-11-30 [1] CRAN (R 4.3.2)\n#>  here           1.0.1      2020-12-13 [1] CRAN (R 4.3.0)\n#>  highr          0.10       2022-12-22 [1] CRAN (R 4.3.0)\n#>  hms            1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n#>  htmltools      0.5.8      2024-03-25 [1] CRAN (R 4.3.2)\n#>  htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.3.0)\n#>  httr           1.4.7      2023-08-15 [1] CRAN (R 4.3.0)\n#>  jquerylib      0.1.4      2021-04-26 [1] CRAN (R 4.3.0)\n#>  jsonlite       1.8.8      2023-12-04 [1] CRAN (R 4.3.0)\n#>  kableExtra     1.4.0      2024-01-24 [1] CRAN (R 4.3.2)\n#>  knitr          1.45       2023-10-30 [1] CRAN (R 4.3.0)\n#>  labeling       0.4.3      2023-08-29 [1] CRAN (R 4.3.0)\n#>  labelled       2.12.0     2023-06-21 [1] CRAN (R 4.3.0)\n#>  lattice        0.22-6     2024-03-20 [2] CRAN (R 4.3.2)\n#>  lazyeval       0.2.2      2019-03-15 [1] CRAN (R 4.3.0)\n#>  lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.3.0)\n#>  lmtest         0.9-40     2022-03-21 [1] CRAN (R 4.3.0)\n#>  magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n#>  markdown       1.12       2023-12-06 [1] CRAN (R 4.3.0)\n#>  Matrix         1.6-5      2024-01-11 [1] CRAN (R 4.3.0)\n#>  mgcv           1.9-1      2023-12-21 [1] CRAN (R 4.3.0)\n#>  mitools        2.4        2019-04-26 [1] CRAN (R 4.3.0)\n#>  munsell        0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n#>  nlme           3.1-164    2023-11-27 [1] CRAN (R 4.3.2)\n#>  nortest        1.0-4      2015-07-30 [1] CRAN (R 4.3.0)\n#>  patchwork      1.2.0      2024-01-08 [1] CRAN (R 4.3.0)\n#>  pillar         1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n#>  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n#>  plotly         4.10.4     2024-01-13 [1] CRAN (R 4.3.0)\n#>  plyr           1.8.9      2023-10-02 [1] CRAN (R 4.3.0)\n#>  proxy          0.4-27     2022-06-09 [1] CRAN (R 4.3.0)\n#>  purrr          1.0.2      2023-08-10 [1] CRAN (R 4.3.0)\n#>  R6             2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n#>  RColorBrewer   1.1-3      2022-04-03 [1] CRAN (R 4.3.0)\n#>  Rcpp           1.0.12     2024-01-09 [1] CRAN (R 4.3.0)\n#>  repr           1.1.7      2024-03-22 [1] CRAN (R 4.3.3)\n#>  rlang          1.1.3      2024-01-10 [1] CRAN (R 4.3.0)\n#>  rmarkdown      2.26       2024-03-05 [1] CRAN (R 4.3.2)\n#>  rprojroot      2.0.4      2023-11-05 [1] CRAN (R 4.3.0)\n#>  rstudioapi     0.16.0     2024-03-24 [1] CRAN (R 4.3.2)\n#>  rversions      2.1.2      2022-08-31 [1] CRAN (R 4.3.0)\n#>  sass           0.4.9      2024-03-15 [1] CRAN (R 4.3.3)\n#>  scales         1.3.0      2023-11-28 [1] CRAN (R 4.3.2)\n#>  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n#>  skimr          2.1.5      2022-12-23 [1] CRAN (R 4.3.0)\n#>  stringi        1.8.3      2023-12-11 [1] CRAN (R 4.3.0)\n#>  stringr        1.5.1      2023-11-14 [1] CRAN (R 4.3.0)\n#>  survey         4.4-2      2024-03-20 [1] CRAN (R 4.3.2)\n#>  survival       3.5-8      2024-02-14 [2] CRAN (R 4.3.3)\n#>  svglite        2.1.3      2023-12-08 [1] CRAN (R 4.3.0)\n#>  systemfonts    1.0.6      2024-03-07 [1] CRAN (R 4.3.2)\n#>  tableone       0.13.2     2022-04-15 [1] CRAN (R 4.3.0)\n#>  tibble         3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n#>  tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n#>  tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.3.2)\n#>  utf8           1.2.4      2023-10-22 [1] CRAN (R 4.3.0)\n#>  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n#>  viridisLite    0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n#>  withr          3.0.0      2024-01-16 [1] CRAN (R 4.3.0)\n#>  xfun           0.43       2024-03-25 [1] CRAN (R 4.3.2)\n#>  xml2           1.3.6      2023-12-04 [1] CRAN (R 4.3.0)\n#>  yaml           2.3.8      2023-12-11 [1] CRAN (R 4.3.0)\n#>  zoo            1.8-12     2023-04-13 [1] CRAN (R 4.3.0)\n#> \n#>  [1] /Library/Frameworks/R.framework/Versions/4.3-x86_64/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/htmltools-fill-0.5.8/fill.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/datatables-binding-0.32/datatables.js\"></script>\n<script src=\"site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"site_libs/nouislider-7.0.10/jquery.nouislider.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/nouislider-7.0.10/jquery.nouislider.min.js\"></script>\n<link href=\"site_libs/selectize-0.12.0/selectize.bootstrap3.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/selectize-0.12.0/selectize.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}