{
  "hash": "827ea12865b844c848a1797158c9b0ac",
  "result": {
    "engine": "knitr",
    "markdown": "# Analysis of variance {#sec-chap07}\n\n\n\n\n\n## Achievements to unlock\n\n::: my-objectives\n::: my-objectives-header\nObjectives\n:::\n\n::: my-objectives-container\n**SwR Achievements**\n\n- **Achievement 1**: Exploring the data using graphics and descriptive statistics {@sec-chap07-achievement1}\n- **Achievement 2**: Understanding and conducting one-way ANOVA {#sec-chap07-achievement2}\n- **Achievement 3**: Choosing and using post hoc tests and contrasts {@sec-chap07-achievement3}\n- **Achievement 4**: Computing and interpreting effect sizes for ANOVA {@sec-chap07-achievement4}\n- **Achievement 5**: Testing ANOVA assumptions {@sec-chap07-achievement5}\n- **Achievement 6**: Choosing and using alternative tests when ANOVA assumptions are not met {@sec-chap07-achievement6}\n- **Achievement 7**: Understanding and conducting two-way ANOVA {@sec-chap07-achievement7}\n\n:::\n:::\n\n<a class='glossary' title='Analysis of variance is a statistical method used to compare means across groups to determine whether there is a statistically significant difference among the means; typically used when there are three or more means to compare. (SwR, Glossary)'>ANOVA</a> is the statistical method used for comparing means across three or more groups. \n\n- Like the <a class='glossary' title='Student t-test is a statistical test used to test whether the difference between the response of two groups is statistically significant or not. (Wikipedia)'>t-test</a>, ANOVA has underlying assumptions.\n- Similar to <a class='glossary' title='Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary)'>chi-squared</a>, ANOVA is an <a class='glossary' title='An omnibus is a statistical test that identifies that there is some relationship going on between variables, but not what that relationship is. (SwR, Glossary)'>omnibus</a> test.\n- Instead of using <a class='glossary' title='Standardized residuals are the standardized differences between observed and expected values in a chi-squared analysis; a large standardized residual indicates that the observed and expected values were very different. (SwR, Glossary)'>standardized residuals</a>, ANOVA uses planned contrasts and post hoc tests.\n- Instead of <a class='glossary' title='Cramér’s V is an effect size to determine the strength of the relationship between two categorical variables; often reported with the results of a chi-squared. (SwR, Glossary)'>Cramér’s V</a> or <a class='glossary' title='Odds is usually defined in statistics as the probability an event will occur divided by the probability that it will not occur. An odds ratio (OR) is a measure of association between a certain property A and a second property B in a population. Specifically, it tells you how the presence or absence of property A has an effect on the presence or absence of property B. (Statistics How To). An odds ratio is a ratio of two ratios. They quantify the strength of the relationship between two conditions. They indicate how likely an outcome is to occur in one context relative to another. (Statistics by Jim)'>odds ratios</a> for chi-squared and <a class='glossary' title='Cohen’s d is a standardized effect size for measuring the difference between two group means. It is frequently used to compare a treatment to a control group. It can be a suitable effect size to include with t-test and ANOVA results. (Statistics by Jim)'>Cohen’s d</a> for t-tests, $η^2$ and $ω^2$ are often reported as <a class='glossary' title='Effect size is a measure of the strength of a relationship; effect sizes are important in inferential statistics in order to determine and communicate whether a statistically significant result has practical importance. (SwR, Glossary)'>effect sizes</a> for ANOVA.\n\n\n## The technical difficulties problem (empty)\n\n## Resources & Chapter Outline\n\n### Data, codebook, and R packages {#sec-chap04-data-codebook-packages}\n\n::: my-resource\n::: my-resource-header\nData, codebook, and R packages for learning about descriptive statistics\n:::\n\n::: my-resource-container\n\n**Data**\n\n\nTwo options:\n\n1. Download the `gss2018.rda` data set from <https://edge.sagepub.com/harris1e>.\n2. Use {**gssr**} to download the year 2018.\n\n(As a direct download with the {**gssr**} package results in labelled data with different column names and the necessary transformation will not gain any additional knowledge for me, I will take the `gss2018.rda` data set from the book.)\n\n**Codebook**\n\nTwo options:\n\n1. Access variable documentation (not a full codebook) on the GSS Data Explorer website at <https://gssdataexplorer.norc.org/> \n2. Use the help pages from {**gssr**} package.\n\n\n**Packages**\n\n1. Packages used with this chapter (sorted alphabetically)\n\n-   {**tidyverse**}: @pak-tidyverse (Hadley Wickham)\n-   {**car**): @pak-car (John Fox)\n-   {**dunn.test**} @pak-dunn.test (Alexis Dinno) (https://www.rdocumentation.org/packages/dunn.test/)\n\n    \n2. My additional packages (sorted alphabetically)\n\n\n\n:::\n:::\n\n\n\n### Get data {#sec-chap07-get-data}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap07-get-gss2018-book}\n: Get book GSS data set `gss2018.rda` and save it as `gss_2018.rds`\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n## run only once (manually) ####################\n## load \"GSS\" data.frame into memory\nbase::load(\"data/chap07/gss2018.rda\")\n\ngss_2018 <- GSS\nsave_data_file(\"chap07\", gss_2018, \"gss_2018.rds\")\n```\n:::\n\n\n(*For this R code chunk is no output available*)\n::::\n:::::\n\n\n### Show raw data {#sec-chap07-show-data}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap07-show-gss-2018-data}\n: Show summary for some `gss_2018` data\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2018 <- base::readRDS(\"data/chap07/gss_2018.rds\")\ngss_2018 |> \n    dplyr::select(c(\"USETECH\", \"HAPPY\", \"SEX\", \"AGE\", \"DEGREE\")) |> \n    base::summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>     USETECH           HAPPY            SEX             AGE       \n#>  Min.   : -1.00   Min.   :1.000   Min.   :1.000   Min.   :18.00  \n#>  1st Qu.: -1.00   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:34.00  \n#>  Median : 10.00   Median :2.000   Median :2.000   Median :48.00  \n#>  Mean   : 48.09   Mean   :1.855   Mean   :1.552   Mean   :49.13  \n#>  3rd Qu.: 80.00   3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:63.00  \n#>  Max.   :999.00   Max.   :8.000   Max.   :2.000   Max.   :99.00  \n#>      DEGREE     \n#>  Min.   :0.000  \n#>  1st Qu.:1.000  \n#>  Median :1.000  \n#>  Mean   :1.684  \n#>  3rd Qu.:3.000  \n#>  Max.   :4.000\n```\n\n\n:::\n:::\n\n***\n\n- **USETECH**: During a typical week, about what percentage of your total time at work would you normally spend using different types of electronic technologies (such as computers, tablets, smart phones, cash registers, scanners, GPS devices, robotic devices, and so on)?\n- **HAPPY**: Taken all together, how would you say things are these days -- would you say that you are very happy, pretty happy, or not too happy?\n- **SEX**: Respondent’s sex\n- **AGE**: Respondent’s age\n- **DEGREE**: Respondent’s highest degree\n- \n::::\n:::::\n\n:::::{.my-procedure}\n:::{.my-procedure-header}\n:::::: {#prp-chap07-gss-procedure}\n: To get the full information for a variable in GSS\n::::::\n:::\n::::{.my-procedure-container}\n1. Go to <https://gssdataexplorer.norc.org/>\n2. In the box \"Access and Analyze GSS Data\" click on the \"SEARCH VARIABLES\" button.\n3. Click at \"Select specific years\", choose \"2018\" and confirm by pressing the \"Apply\"-button.\n4. Input the name of the variable \"USETECH\" into the field and confirm with <enter>.\n5. Open \"Associated questions\" by clicking the `>` symbol or by pressing the \"Show Expanded View\"-button.\n6. Click on the green variable name in the result list to get more detailed information about the variable.\n7. In contrast to the result in the book we get a slightly different coding scheme: We got four (not three) values outside the logical range of 0 to 100: -97, -98, -99, -100.\n\n![Screenshot of GSS Data Explorer 2018 USETECH variable values outside logical range](img/chap07/gss-usetech-codes-min.png){#fig-gss-usetech-codebook\nfig-alt=\"Table of the first 10 lines of GSS Data Explorer 2018 USETECH variable values\"\nfig-align=\"center\"}\n\n::::\n:::::\n\n:::::{.my-important}\n:::{.my-important-header}\nRecoding data exactly as in the book\n:::\n::::{.my-important-container}\nAs we are going to use the data set from the book and not the current data set as it is today (2024-03-25) saved at the GSS website, we will for instance USETECH recode -1, 998 and 999 as missing data in our data frame (and not the current values).  \n\nGenerally: There is nothing new for me in recoding the data. So I will apply all the necessary recoding in the next subsection in only one R code chunk.\n::::\n:::::\n\n\n\n### Recode data {#sec-chap07-recode-data}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap07-recode-gss2018}\n: Clean `gss_2018` data\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2018 <- base::readRDS(\"data/chap07/gss_2018.rds\")\n\ngss_2018_clean <- gss_2018 |> \n    dplyr::select(c(\"USETECH\", \"HAPPY\", \"SEX\", \"AGE\", \"DEGREE\")) |> \n    dplyr::mutate(USETECH = dplyr::na_if(x = USETECH, y = -1)) |> \n    dplyr::mutate(USETECH = dplyr::na_if(x = USETECH, y = 998)) |>\n    dplyr::mutate(USETECH = dplyr::na_if(x = USETECH, y = 999)) |>\n    dplyr::mutate(AGE = dplyr::na_if(x = AGE, y = 98)) |>\n    dplyr::mutate(AGE = dplyr::na_if(x = AGE, y = 99)) |>\n    dplyr::mutate(DEGREE = dplyr::na_if(x = DEGREE, y = 8)) |>\n    dplyr::mutate(DEGREE = dplyr::na_if(x = DEGREE, y = 9)) |>\n    dplyr::mutate(HAPPY = dplyr::na_if(x = HAPPY, y = 8)) |>\n    dplyr::mutate(HAPPY = dplyr::na_if(x = HAPPY, y = 9)) |>\n    dplyr::mutate(HAPPY = dplyr::na_if(x = HAPPY, y = 0)) |> \n    \n    dplyr::mutate(SEX = forcats::as_factor(SEX)) |> \n    dplyr::mutate(DEGREE = forcats::as_factor(DEGREE)) |> \n    dplyr::mutate(HAPPY = forcats::as_factor(HAPPY)) |> \n    \n    dplyr::mutate(SEX = forcats::fct_recode(SEX, \n                                            male = \"1\", \n                                            female = \"2\")) |> \n    dplyr::mutate(DEGREE = forcats::fct_recode(DEGREE, \n                                            \"< high school\" = \"0\", \n                                            \"high school\" = \"1\",\n                                            \"junior college\" = \"2\",\n                                            \"bachelor\" = \"3\",\n                                            \"graduate\" = \"4\")) |> \n    dplyr::mutate(HAPPY = forcats::fct_recode(HAPPY, \n                                        \"very happy\" = \"1\",\n                                        \"pretty happy\" = \"2\",\n                                        \"not too happy\" = \"3\"))\n\nsave_data_file(\"chap07\", gss_2018_clean, \"gss_2018_clean.rds\")\n\nbase::summary(gss_2018_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>     USETECH                 HAPPY          SEX            AGE       \n#>  Min.   :  0.00   very happy   : 701   male  :1051   Min.   :18.00  \n#>  1st Qu.: 15.00   pretty happy :1304   female:1294   1st Qu.:34.00  \n#>  Median : 60.00   not too happy: 336                 Median :48.00  \n#>  Mean   : 55.15   NA's         :   4                 Mean   :48.98  \n#>  3rd Qu.: 90.00                                      3rd Qu.:63.00  \n#>  Max.   :100.00                                      Max.   :89.00  \n#>  NA's   :936                                         NA's   :7      \n#>             DEGREE    \n#>  < high school : 262  \n#>  high school   :1175  \n#>  junior college: 196  \n#>  bachelor      : 465  \n#>  graduate      : 247  \n#>                       \n#> \n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n\n## Achievement 1: Descriptive statistics {#sec-chap07-achievement1}\n\nThe work in this section is done in @sec-chap07-get-data, @sec-chap07-show-data and @sec-chap07-recode-data.\n\n### Explorative Data Analysis (EDA)\n\n**Question to explore**: Do people with higher educational degrees use technology at work more than people with lower degree?\n\n:::::{.my-example}\n:::{.my-example-header}\n:::::: {#exm-chap07-eda}\n: Explorative Data Analysis (EDA)\n::::::\n:::\n::::{.my-example-container}\n\n::: {.panel-tabset}\n\n###### mean / sd\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap07-usetech-mean-sd}\n: Mean and standard deviation of technology use by respondent’s highest degree\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_2018_clean <- base::readRDS(\"data/chap07/gss_2018_clean.rds\")\n\nusetech_degree <- gss_2018_clean |> \n    tidyr::drop_na(USETECH, DEGREE) |>\n    dplyr::group_by(DEGREE) |> \n    dplyr::summarize(mean_usetech = mean(USETECH),\n                     sd_usetech = sd(USETECH))\nusetech_degree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 5 × 3\n#>   DEGREE         mean_usetech sd_usetech\n#>   <fct>                 <dbl>      <dbl>\n#> 1 < high school          24.8       36.2\n#> 2 high school            49.6       38.6\n#> 3 junior college         62.4       35.2\n#> 4 bachelor               67.9       32.1\n#> 5 graduate               68.7       30.2\n```\n\n\n:::\n:::\n\n***\nIt seems that we could affirm our question. With higher degree the value of the mean (representing the percentage of technology usage) is rising. But we have a big standard deviation, especially in the lowest degree group ($sd \\approx 1.5 mean$). This could indicate that we have not a normal distribution because of high <a class='glossary' title='Kurtosis is a measure of how many observations are in the tails of a distribution; distributions that look bell-shaped, but have a lot of observations in the tails (platykurtic) or very few observations in the tails (leptokurtic) (SwR, Glossary)'>kurtosis</a>, e.g. we could have more observations in the tails than a normal distribution would have (<a class='glossary' title='Platykurtic is a distribution of a numeric variable that has more observations in the tails than a normal distribution would have; platykurtic distributions often look flatter than a normal distribution. (SwR, Glossary)'>platykurtic</a>).\n\n::::\n:::::\n\n\n###### replicate Figure 7.4\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap07-replicate-7-4}\n: Distribution of work time spent using technology by educational attainment\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_gss_2018 <- gss_2018_clean |> \n  tidyr::drop_na(USETECH) |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = DEGREE,\n          y = USETECH\n          )\n      ) +\n  ggplot2::geom_jitter(\n      ggplot2::aes(color = DEGREE), alpha = .6\n      ) +\n  ggplot2::geom_boxplot(\n      ggplot2::aes(fill = DEGREE), alpha = .4\n      ) +\n  ggplot2::scale_fill_brewer(\n      palette = \"Spectral\", \n      guide = \"none\"\n      ) +\n  ggplot2::scale_color_brewer(\n      palette = \"Spectral\", \n      guide = \"none\") +\n  ggplot2::theme_bw() +\n  ggplot2::labs(\n      x = \"Highest educational attainment\", \n      y = \"Percent of time spent using technology\"\n      )\n\ngg_gss_2018\n```\n\n::: {.cell-output-display}\n![Distribution of work time spent using technology by educational attainment, using palette 'Spectral' of brewer scales](07-analysis-of-variance_files/figure-html/fig-replicate-7-4-1.png){#fig-replicate-7-4 width=672}\n:::\n:::\n\n***\n\nHarris uses with this graph (Figure 7.4 in her book) the color schemes from [ColorBrewer](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3). See for more details the [color palettes of RColorBrewer](https://renenyffenegger.ch/notes/development/languages/R/packages/RColorBrewer/index) and the [screenshot](https://renenyffenegger.ch/notes/development/languages/R/packages/tmaptools/index#r-tmaptools-palette_explorer) of the `tmaptools::palette_explorer()` function. \n\nBut the chosen color palette is not appropriate for people with color vision deficiency (<a class='glossary' title='Color vision deficiency (CVD) or color blindness (also spelled colour blindness) includes a wide range of causes and conditions and is actually quite complex. It’s a condition characterized by an inability or difficulty in perceiving and differentiating certain colors due to abnormalities in the three color-sensing pigments of the cones in the retina. (EnChroma)'>CVD</a>). Mainly the yellow color is problematic as can be demonstrated with the following plot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolorblindr::cvd_grid(gg_gss_2018)\n```\n\n::: {.cell-output-display}\n![](07-analysis-of-variance_files/figure-html/fig-check-colorblind-save-gss_2018-plot-1.png){#fig-check-colorblind-save-gss_2018-plot width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n###### better colors\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-chap07-techuse-dist}\n: Distribution of work time spent using technology by educational attainment (colorblind save)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\ngg2_gss_2018 <- gss_2018_clean |> \n  tidyr::drop_na(USETECH) |> \n  ggplot2::ggplot(\n      ggplot2::aes(\n          x = DEGREE,\n          y = USETECH\n          )\n      ) +\n  ggplot2::geom_jitter(\n      ggplot2::aes(color = DEGREE), alpha = .6\n      ) +\n  ggplot2::geom_boxplot(\n      ggplot2::aes(fill = DEGREE), alpha = .4\n      ) + \n  ggokabeito::scale_color_okabe_ito(guide = \"none\") +\n  ggokabeito::scale_fill_okabe_ito(guide = \"none\") +\n  # ggplot2::scale_fill_brewer(\n  #     palette = \"Spectral\", \n  #     guide = \"none\"\n  #     ) +\n  # ggplot2::scale_color_brewer(\n  #     palette = \"Spectral\", \n  #     guide = \"none\") +\n  ggplot2::theme_bw() +\n  ggplot2::labs(\n      x = \"Highest educational attainment\", \n      y = \"Percent of time spent using technology\"\n      )\n\ngg2_gss_2018\n```\n\n::: {.cell-output-display}\n![Distribution of work time spent using technology by educational attainment, using the color save palette 'Okabe-Ito'](07-analysis-of-variance_files/figure-html/chap07-techuse-dist-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncolorblindr::cvd_grid(gg2_gss_2018)\n```\n\n::: {.cell-output-display}\n![Distribution of work time spent using technology by educational attainment, using the color save palette 'Okabe-Ito'](07-analysis-of-variance_files/figure-html/chap07-techuse-dist-2.png){width=672}\n:::\n:::\n\n\n***\n\nAlthough the color palette \"Okabe-Ito\" is also using a kind of yellow the result is much better in all CVD variants. Compare it with @fig-check-colorblind-save-gss_2018-plot.\n::::\n:::::\n\n\n:::\n\n::::\n:::::\n\nWhat we can see with the graph is that there are many observation at the bottom and at the top of the range of the variable `USETECH`.  \n\n- Many people in the first two categories had selected 0% of their time at work is spent using technology (<a class='glossary' title='A floor effect happens when a variable has many observations that take the lowest value of the variable, which can indicate that the range of values was insufficient to capture the true variability of the data. (SwR, Glossary)'>Floor effect</a>).\n- For all but the first category, there were a lot of people who selected 100% of their time at work is spent using technology (<a class='glossary' title='A ceiling effect happens when many observations are at the highest possible value for a variable. (SwR, Glossary)'>Ceiling effect</a>).\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nWATCH OUT! ANOVA with floor and ceiling effect\n:::\n::::{.my-watch-out-container}\n\nWhen there are floor or ceiling effects, this often means that the variation in a measure is limited by its range. Since ANOVA is an analysis of variance, which examines central tendency and variation together, the limitations of floor and ceiling effects can result in not finding differences when there are differences.\n\nSometimes floor or ceiling effects are hints that the range of the variable is not chosen correctly. But this does not apply in our case, because the range of using technology from 0 to 100% is as wide as it can be. Besides I believe these extreme values do not relate to the true value of technology use in work. I think that today there is almost no work without some sort of technology support. On the other hand it is no very likely that 100% (every second of work) of technology use is realistic.\n::::\n:::::\n\n## Achievement 2: Conducting one-way ANOVA {#sec-chap07-achievement2}\n\n\n\n## Exercises (empty)\n\n## Packages introduced in this chapter (empty)\n\n### dunn.test\n\n:::::{.my-resource}\n:::{.my-resource-header}\ndunn.test: Dunn's Test of Multiple Comparisons Using Rank Sums \n:::\n::::{.my-resource-container}\n\n***\n\n::: {#pak-dunn.test}\n\n***\n\n{**dunn.test**}: [Dunn's Test of Multiple Comparisons Using Rank Sums](https://cran.r-project.org/package=dunn.test) [@dunn.test]\n\nComputes Dunn's test [@dunn1964] for stochastic dominance and reports the results among multiple pairwise comparisons after a Kruskal-Wallis test for stochastic dominance among k groups [@kruskal1952. The interpretation of stochastic dominance requires an assumption that the CDF of one group does not cross the CDF of the other. \n\n{**dunn.test**} makes k(k-1)/2 multiple pairwise comparisons based on Dunn's z-test-statistic approximations to the actual rank statistics. The null hypothesis for each pairwise comparison is that the probability of observing a randomly selected value from the first group that is larger than a randomly selected value from the second group equals one half; this null hypothesis corresponds to that of the <a class='glossary' title='Mann-Whitney U test, also called Wilcoxon rank sum test, is an alternative for comparing a numeric or ordinal variable across two groups when the independent-samples t-test assumption of normality is not met. (SwR, Glossary)'>Wilcoxon-Mann-Whitney rank-sum test</a>. Like the rank-sum test, if the data can be assumed to be continuous, and the distributions are assumed identical except for a difference in location, Dunn's test may be understood as a test for median difference. {**dunn.test**} accounts for tied ranks.\n\n{**dunn.test**}: Dunn's Test of Multiple Comparisons Using Rank Sums\n:::\n\n***\n::::\n:::::\n\n\n## Glossary\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> ANOVA </td>\n   <td style=\"text-align:left;\"> Analysis of variance is a statistical method used to compare means across groups to determine whether there is a statistically significant difference among the means; typically used when there are three or more means to compare. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Ceiling </td>\n   <td style=\"text-align:left;\"> A ceiling effect happens when many observations are at the highest possible value for a variable. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Chi-squared </td>\n   <td style=\"text-align:left;\"> Chi-squared is the test statistic following the chi-squared probability distribution; the chi-squared test statistic is used in inferential tests, including examining the association between two categorical variables and determining statistical significance for a logistic regression model. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cohen’s d </td>\n   <td style=\"text-align:left;\"> Cohen’s d is a standardized effect size for measuring the difference between two group means. It is frequently used to compare a treatment to a control group. It can be a suitable effect size to include with t-test and ANOVA results. (&lt;a href= \"https://statisticsbyjim.com/basics/cohens-d/\"&gt;Statistics by Jim&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cramér’s V </td>\n   <td style=\"text-align:left;\"> Cramér’s V is an effect size to determine the strength of the relationship between two categorical variables; often reported with the results of a chi-squared. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> CVD </td>\n   <td style=\"text-align:left;\"> Color vision deficiency (CVD) or color blindness (also spelled colour blindness) includes a wide range of causes and conditions and is actually quite complex. It's a condition characterized by an inability or difficulty in perceiving and differentiating certain colors due to abnormalities in the three color-sensing pigments of the cones in the retina. (&lt;a href=\"https://enchroma.com/pages/types-of-color-blindness\"&gt;EnChroma&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Effect Size </td>\n   <td style=\"text-align:left;\"> Effect size is a measure of the strength of a relationship; effect sizes are important in inferential statistics in order to determine and communicate whether a statistically significant result has practical importance. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Floor </td>\n   <td style=\"text-align:left;\"> A floor effect happens when a variable has many observations that take the lowest value of the variable, which can indicate that the range of values was insufficient to capture the true variability of the data. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Kurtosis </td>\n   <td style=\"text-align:left;\"> Kurtosis is a measure of how many observations are in the tails of a distribution; distributions that look bell-shaped, but have a lot of observations in the tails (platykurtic) or very few observations in the tails (leptokurtic) (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mann-Whitney </td>\n   <td style=\"text-align:left;\"> Mann-Whitney U test, also called Wilcoxon rank sum test, is an alternative for comparing a numeric or ordinal variable across two groups when the independent-samples t-test assumption of normality is not met. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Odds Ratio </td>\n   <td style=\"text-align:left;\"> Odds is usually defined in statistics as the probability an event will occur divided by the probability that it will not occur. An odds ratio (OR) is a measure of association between a certain property A and a second property B in a population. Specifically, it tells you how the presence or absence of property A has an effect on the presence or absence of property B. (&lt;a href=\"https://www.statisticshowto.com/probability-and-statistics/probability-main-index/odds-ratio/\"&gt;Statistics How To&lt;/a&gt;). An odds ratio is a ratio of two ratios. They quantify the strength of the relationship between two conditions. They indicate how likely an outcome is to occur in one context relative to another. (&lt;a href=\"https://statisticsbyjim.com/probability/odds-ratio/\"&gt;Statistics by Jim&lt;/a&gt;) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Omnibus </td>\n   <td style=\"text-align:left;\"> An omnibus is a statistical test that identifies that there is some relationship going on between variables, but not what that relationship is. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Platykurtic </td>\n   <td style=\"text-align:left;\"> Platykurtic is a distribution of a numeric variable that has more observations in the tails than a normal distribution would have; platykurtic distributions often look flatter than a normal distribution. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Standardized Residuals </td>\n   <td style=\"text-align:left;\"> Standardized residuals are the standardized differences between observed and expected values in a chi-squared analysis; a large standardized residual indicates that the observed and expected values were very different. (SwR, Glossary) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Student </td>\n   <td style=\"text-align:left;\"> Student t-test is a statistical test used to test whether the difference between the response of two groups is statistically significant or not. (&lt;a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\"&gt;Wikipedia&lt;/a&gt;) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n## Session Info {.unnumbered}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\nSession Info\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> ─ Session info ───────────────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.3.3 (2024-02-29)\n#>  os       macOS Sonoma 14.3.1\n#>  system   x86_64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Europe/Vienna\n#>  date     2024-03-25\n#>  pandoc   3.1.12.3 @ /usr/local/bin/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────────────────────────\n#>  package      * version    date (UTC) lib source\n#>  cli            3.6.2      2023-12-11 [1] CRAN (R 4.3.0)\n#>  colorblindr    0.1.0      2024-02-14 [1] Github (clauswilke/colorblindr@90d64f8)\n#>  colorspace     2.1-1      2024-01-03 [1] R-Forge (R 4.3.2)\n#>  commonmark     1.9.1      2024-01-30 [1] CRAN (R 4.3.2)\n#>  cowplot        1.1.3.9000 2024-02-14 [1] Github (wilkelab/cowplot@e1334a2)\n#>  curl           5.2.1      2024-03-01 [1] CRAN (R 4.3.2)\n#>  digest         0.6.35     2024-03-11 [1] CRAN (R 4.3.2)\n#>  dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.3.0)\n#>  evaluate       0.23       2023-11-01 [1] CRAN (R 4.3.0)\n#>  fansi          1.0.6      2023-12-08 [1] CRAN (R 4.3.0)\n#>  farver         2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n#>  fastmap        1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n#>  generics       0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n#>  ggokabeito     0.1.0      2021-10-18 [1] CRAN (R 4.3.0)\n#>  ggplot2        3.5.0      2024-02-23 [1] CRAN (R 4.3.2)\n#>  glossary     * 1.0.0.9000 2023-08-12 [1] Github (debruine/glossary@819e329)\n#>  glue           1.7.0      2024-01-09 [1] CRAN (R 4.3.0)\n#>  gtable         0.3.4      2023-08-21 [1] CRAN (R 4.3.0)\n#>  highr          0.10       2022-12-22 [1] CRAN (R 4.3.0)\n#>  htmltools      0.5.7      2023-11-03 [1] CRAN (R 4.3.0)\n#>  htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.3.0)\n#>  jsonlite       1.8.8      2023-12-04 [1] CRAN (R 4.3.0)\n#>  kableExtra     1.4.0      2024-01-24 [1] CRAN (R 4.3.2)\n#>  knitr          1.45       2023-10-30 [1] CRAN (R 4.3.0)\n#>  labeling       0.4.3      2023-08-29 [1] CRAN (R 4.3.0)\n#>  lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.3.0)\n#>  magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n#>  markdown       1.12       2023-12-06 [1] CRAN (R 4.3.0)\n#>  munsell        0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n#>  pillar         1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n#>  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n#>  purrr          1.0.2      2023-08-10 [1] CRAN (R 4.3.0)\n#>  R6             2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n#>  RColorBrewer   1.1-3      2022-04-03 [1] CRAN (R 4.3.0)\n#>  rlang          1.1.3      2024-01-10 [1] CRAN (R 4.3.0)\n#>  rmarkdown      2.26       2024-03-05 [1] CRAN (R 4.3.2)\n#>  rstudioapi     0.15.0     2023-07-07 [1] CRAN (R 4.3.0)\n#>  rversions      2.1.2      2022-08-31 [1] CRAN (R 4.3.0)\n#>  scales         1.3.0      2023-11-28 [1] CRAN (R 4.3.2)\n#>  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n#>  stringi        1.8.3      2023-12-11 [1] CRAN (R 4.3.0)\n#>  stringr        1.5.1      2023-11-14 [1] CRAN (R 4.3.0)\n#>  svglite        2.1.3      2023-12-08 [1] CRAN (R 4.3.0)\n#>  systemfonts    1.0.6      2024-03-07 [1] CRAN (R 4.3.2)\n#>  tibble         3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n#>  tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n#>  tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.3.2)\n#>  utf8           1.2.4      2023-10-22 [1] CRAN (R 4.3.0)\n#>  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n#>  viridisLite    0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n#>  withr          3.0.0      2024-01-16 [1] CRAN (R 4.3.0)\n#>  xfun           0.42       2024-02-08 [1] CRAN (R 4.3.2)\n#>  xml2           1.3.6      2023-12-04 [1] CRAN (R 4.3.0)\n#>  yaml           2.3.8      2023-12-11 [1] CRAN (R 4.3.0)\n#> \n#>  [1] /Library/Frameworks/R.framework/Versions/4.3-x86_64/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}